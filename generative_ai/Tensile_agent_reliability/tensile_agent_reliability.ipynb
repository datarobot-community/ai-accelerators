{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Tensile: Enhancing agent reliability through automated test synthesis\n",
    "\n",
    "## Summary\n",
    "\n",
    "Tensile is DataRobot's proprietary test-driven development framework designed to systematically improve the reliability, task performance, and policy adherence of AI agents. It aims to move agent development beyond \"vibe coding\" by providing a quantitative, repeatable way to diagnose and remediate errors in complex, multi-turn agentic workflows. The framework operates through a three-step **Enhanced Agent Improvement Cycle** that begins by instrumenting an agent to record its execution trajectories.\n",
    "\n",
    "The core of Tensile lies in its ability to identify **testable moments**—specific points in a recorded trajectory where an agent either succeeded or failed (e.g., making a hallucinated tool call or violating a safety policy). Once identified, these moments are synthesized into short, reproducible tests that can be replayed to quantify performance improvements. Remediation is then achieved through several methods, including manual system prompt or tool updates, and **Contextual Hints**—surgically accurate messages injected at runtime to steer agent behavior.\n",
    "\n",
    "This accelerator walks through:\n",
    "\n",
    "1. Instrumenting an agent for trajectory logging\n",
    "2. Running the full analysis pipeline\n",
    "3. Evaluating testable moments\n",
    "4. Replaying trajectories\n",
    "5. Configuration with the DataRobot LLM Gateway\n",
    "6. Clustering (exploration app and hint injector)\n",
    "7. The Trajectory Analyzer workflow for iterative improvement\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.13 (recommended)\n",
    "- [uv](https://docs.astral.sh/uv/) for environment and dependency management\n",
    "- A Tensile installation (e.g. from source: `uv pip install -e .` in the Tensile repo)\n",
    "- A `config.yaml` (copy from `config.yaml.sample` and fill in credentials)\n",
    "- For DataRobot LLM Gateway: API token and endpoint URL for your region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quickstart",
   "metadata": {},
   "source": [
    "## Quickstart\n",
    "\n",
    "From the Tensile project root:\n",
    "\n",
    "```bash\n",
    "uv venv --python 3.13\n",
    "uv sync; pre-commit install\n",
    "uv pip install -e .\n",
    "cp config.yaml.sample config.yaml   # Fill in credentials\n",
    "tensile   # Show help\n",
    "```\n",
    "\n",
    "Trajectories are logged to `<trajectory_dir>/<subdir>` as defined in `config.yaml`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import dependencies and load environment variables. Ensure your Tensile environment is activated and `config.yaml` is configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import httpx\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Credentials for LLM (e.g. DataRobot API token when using LLM Gateway)\n",
    "api_key = os.getenv(\"DATAROBOT_API_TOKEN\", \"\")\n",
    "endpoint_url = os.getenv(\"DATAROBOT_LLM_GATEWAY_URL\", \"https://app.datarobot.com/api/v2/genai/llmgw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrument",
   "metadata": {},
   "source": [
    "## 1. Instrument an agent for trajectory logging\n",
    "\n",
    "Use `TrajectoryLogger` as an httpx transport wrapper so that every agent run is recorded. Then pass the resulting `http_client` into your OpenAI-compatible client (e.g. DataRobot LLM Gateway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrument-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell only if Tensile is installed (e.g. uv pip install -e . in Tensile repo)\n",
    "from tensile.logging import TrajectoryLogger\n",
    "\n",
    "http_client = httpx.AsyncClient(\n",
    "    transport=TrajectoryLogger(\n",
    "        httpx.AsyncHTTPTransport(),\n",
    "        trajectory_subdir=\"my_agent\",  # or None for default subdir\n",
    "    )\n",
    ")\n",
    "\n",
    "client = AsyncOpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=f\"{endpoint_url}/v1\",\n",
    "    http_client=http_client,\n",
    ")\n",
    "\n",
    "# Use client for chat completions; trajectories will be logged to\n",
    "# <trajectory_dir>/my_agent/ as defined in config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyze",
   "metadata": {},
   "source": [
    "## 2. Run the full analysis pipeline\n",
    "\n",
    "After running your agent and generating trajectory files, analyze a trajectory to identify testable moments and produce hints. Outputs are written to `analysis_output/` by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyze-cmd",
   "metadata": {},
   "source": [
    "**CLI (run in terminal):**\n",
    "\n",
    "```bash\n",
    "tensile analyze trajectories/taco/sde-implement-raft-in-go.jsonl\n",
    "```\n",
    "\n",
    "Replace the path with your own trajectory file (e.g. under `<trajectory_dir>/<subdir>/`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-moments",
   "metadata": {},
   "source": [
    "## 3. Evaluate testable moments\n",
    "\n",
    "Run specific testable moments multiple times to measure consistency and regression.\n",
    "\n",
    "**CLI:**\n",
    "\n",
    "```bash\n",
    "tensile test <moment_path> -n 10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "replay",
   "metadata": {},
   "source": [
    "## 4. Replay trajectories\n",
    "\n",
    "Replay each step in a trajectory multiple times to collect new LLM responses for comparison with the original. This helps identify flukes (unlikely actions that disappear on replay) and understand how changes (e.g. system prompt updates) affect agent behavior.\n",
    "\n",
    "**CLI examples:**\n",
    "\n",
    "```bash\n",
    "# Basic replay (1 replay per step)\n",
    "tensile replay <trajectory_file> [output_path]\n",
    "\n",
    "# Replay each step multiple times\n",
    "tensile replay <trajectory_file> --num-replays 5\n",
    "\n",
    "# Control concurrency (default: 5)\n",
    "tensile replay <trajectory_file> --num-replays 3 --max-concurrency 10\n",
    "\n",
    "# Replay with a new system prompt\n",
    "tensile replay <trajectory_file> --num-replays 3 --system-prompt-path <system_prompt_path_txt>\n",
    "```\n",
    "\n",
    "If `output_path` is omitted, output is written to `<trajectory_file>.replay.jsonl`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "### LLM configuration with DataRobot LLM Gateway\n",
    "\n",
    "To use the DataRobot LLM Gateway with Tensile, add the following to your `config.yaml`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-yaml",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# config.yaml\n",
    "llm:\n",
    "  name: \"vertex_ai/gemini-3-pro-preview\"   # or another model of your choice\n",
    "  api_base: \"https://app.datarobot.com/api/v2/genai/llmgw\"\n",
    "  api_key: <your datarobot api token>\n",
    "```\n",
    "\n",
    "Other OpenAI-compatible endpoints can be configured the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clustering",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "### Clustering app\n",
    "\n",
    "Tensile includes a Dash app to explore and cluster analysis outputs and messages.\n",
    "\n",
    "**Start the app (from Tensile project):**\n",
    "\n",
    "```bash\n",
    "task apps:clustering\n",
    "```\n",
    "\n",
    "Install dev dependencies if needed: `task dev-env` (or with uv: install the `dev` dependency group).\n",
    "\n",
    "### Clustering-based hint injector\n",
    "\n",
    "Use the clustering-based hint injector to surface past analyses and successful answers inside live LLM calls. Wrap your httpx transport with `ClusteringHintInjector` and point it at your Tensile outputs (`analysis_output/` and `trajectories/` by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clustering-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: wire ClusteringHintInjector for an async OpenAI-compatible client\n",
    "# Requires Tensile installed and sentence-transformers for embeddings\n",
    "\n",
    "from tensile.logging.hint_injector import (\n",
    "    ClusteringHintConfig,\n",
    "    ClusteringHintInjector,\n",
    "    InMemoryReportStore,\n",
    "    SentenceTransformersEmbeddingBackend,\n",
    ")\n",
    "\n",
    "base_transport = httpx.AsyncHTTPTransport()\n",
    "embedding_backend = SentenceTransformersEmbeddingBackend(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    ")\n",
    "report_store = InMemoryReportStore()\n",
    "config = ClusteringHintConfig(\n",
    "    analysis_dirs=[Path(\"analysis_output\")],\n",
    "    trajectories_dirs=[Path(\"trajectories\")],\n",
    ")\n",
    "\n",
    "hinting_transport = ClusteringHintInjector(\n",
    "    base_transport,\n",
    "    embedding_backend=embedding_backend,\n",
    "    report_store=report_store,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "http_client = httpx.AsyncClient(transport=hinting_transport)\n",
    "client = AsyncOpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=f\"{endpoint_url}/v1\",\n",
    "    http_client=http_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trajectory-analyzer",
   "metadata": {},
   "source": [
    "## Trajectory Analyzer workflow\n",
    "\n",
    "End-to-end loop for iterative agent improvement using programmatic hints and trajectory analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trajectory-steps",
   "metadata": {},
   "source": [
    "1. **Instrument** the agent with `ProgrammaticHintInjector` and `TrajectoryLogger` (start with `hint_file_path=None` until you have a hint file).\n",
    "2. **Run the agent** to generate a trajectory.\n",
    "3. **Run** `tensile analyze <trajectory_path>`; copy the resulting `hints.json`, updated system prompt, and/or tool definitions back into your agent.\n",
    "4. Set `hint_file_path` to the `hints.json` file and **rerun** the agent to produce a new trajectory.\n",
    "5. **Re-analyze** with `tensile analyze <new_traj_path> --hints-file <path_to_hints.json>`.\n",
    "6. **Repeat** until behavior converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trajectory-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensile.logging import TrajectoryLogger\n",
    "from tensile.logging.hint_injector.programmatic_hint_injector import ProgrammaticHintInjector\n",
    "\n",
    "http_client = httpx.AsyncClient(\n",
    "    transport=ProgrammaticHintInjector(\n",
    "        wrapped=TrajectoryLogger(\n",
    "            wrapped=httpx.AsyncHTTPTransport(),\n",
    "            trajectory_subdir=\"my_agent\",\n",
    "        ),\n",
    "        hint_file_path=None,  # Set to path to hints.json after first analysis\n",
    "    )\n",
    ")\n",
    "\n",
    "client = AsyncOpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=f\"{endpoint_url}/v1\",\n",
    "    http_client=http_client,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
