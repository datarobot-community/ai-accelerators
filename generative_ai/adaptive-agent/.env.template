# Your DataRobot API token.
# Refer to https://docs.datarobot.com/en/docs/api/api-quickstart/index.html#configure-your-environment for help.
DATAROBOT_API_TOKEN=

# The URL of your DataRobot instance API.
DATAROBOT_ENDPOINT=https://app.datarobot.com/api/v2

# Local endpoint for agent component
AGENT_PORT=8842

# The Pulumi stack name to use for this project.
PULUMI_STACK_NAME=agent-application-dev

# If empty, a blank passphrase will be used
PULUMI_CONFIG_PASSPHRASE=123

# Skip Pulumi update check to prevent issues with rate limiting
PULUMI_SKIP_UPDATE_CHECK=1

# If empty, a new use case will be created
DATAROBOT_DEFAULT_USE_CASE=

# If empty, a new execution environment will be created for each agent using the docker_context folder
DATAROBOT_DEFAULT_EXECUTION_ENVIRONMENT="[DataRobot] Python 3.11 GenAI Agents"

# If empty, the latest version of the execution environment will be used
# DATAROBOT_DEFAULT_EXECUTION_ENVIRONMENT_VERSION_ID="69417fa8b1ce07076dca7611"

# If empty, a new execution environment will be created for each agent using the docker_context folder
DATAROBOT_DEFAULT_MCP_EXECUTION_ENVIRONMENT="[DataRobot] Python 3.11 GenAI Agents"

# If empty, the latest version of the execution environment will be used
# DATAROBOT_DEFAULT_MCP_EXECUTION_ENVIRONMENT_VERSION_ID="69417fa8b1ce07076dca7611"

# Required: Random string for Web application security. We recommend a long password generated securely such as:
# `python -c "import os, binascii; print(binascii.hexlify(os.urandom(64)).decode('utf-8'))"`
SESSION_SECRET_KEY=

# OAuth configurtion: See README instructions for getting Google and Box OAuth Apps
# GOOGLE_CLIENT_ID=
# GOOGLE_CLIENT_SECRET=

# BOX_CLIENT_ID=
# BOX_CLIENT_SECRET=

# The URI of the database to use for the application. The default value is a SQLite database in the .data folder.
# DATABASE_URI=sqlite+aiosqlite:///.data/database.sqlite

# LLM Configuration:
# Agent templates support multiple flexible LLM options including:
# - LLM Gateway Direct (default)
# - External LLM
# - Already Deployed Text Generation model in DataRobot
#
# You can edit the LLM configuration by manually changing which configuration is
# active (recommended option).
# Simply run `ln -sf ../configurations/<chosen_configuration> llm.py`
# from the `infra/infra` folder
#
# If you want to do it dynamically however, you can also set it as a configuration value with:
# INFRA_ENABLE_LLM=<chosen_configuration>
# from the list of options in the infra/configurations/llm folder
# Here are some examples of each of those configuration using the dynamic option described above:

# If you want to use the LLM Gateway direct (default)
# INFRA_ENABLE_LLM=gateway_direct.py

# If you want to choose an existing LLM Deployment in DataRobot
# uncomment and configure these:
# TEXTGEN_DEPLOYMENT_ID=<your_deployment_id>
# INFRA_ENABLE_LLM=deployed_llm.py

# If you want to configure an LLM with an external LLM provider
# like Azure, Bedrock, Anthropic, or VertexAI (or all 4). Here we provide
# an Azure AI example, see:
# https://docs.datarobot.com/en/docs/gen-ai/playground-tools/deploy-llm.html
# for details on other providers and details:
# INFRA_ENABLE_LLM=blueprint_with_external_llm.py
# LLM_DEFAULT_MODEL="azure/gpt-5-mini-2025-08-07"
# OPENAI_API_VERSION='2024-08-01-preview'
# OPENAI_API_BASE='https://<your_custom_endpoint>.openai.azure.com'
# OPENAI_API_DEPLOYMENT_ID='<your deployment_id>'
# OPENAI_API_KEY='<your_api_key>'

# =============================================================================
# ADAPTIVE AGENT DEMO SETTINGS
# =============================================================================
# Main model for complex responses (used when thinking/reasoning mode is active)
MAIN_MODEL=datarobot/azure/gpt-4o

# Fast model for simple responses (used in normal mode)
FAST_MODEL=datarobot/azure/gpt-4o-mini

# Reflection model for correction detection
REFLECTION_MODEL=datarobot/azure/gpt-4o-mini

# Enable adaptive model switching based on conversation analysis
ENABLE_ADAPTIVE_THINKING=true

# =============================================================================
# MCP server configurations
MCP_SERVER_PORT=9000
APP_LOG_LEVEL=CRITICAL

# For local testing only: uncomment and set MCP_DEPLOYMENT_ID to the target deployment ID.
#MCP_DEPLOYMENT_ID=

# For local testing only: To test using external MCP server (not necessarily DataRobot), uncomment
# and set EXTERNAL_MCP_URL to the MCP endpoint (for example: https://example.com/mcp).
# Note: For external MCP Servers DataRobot bearer tokens and OAuth context will not be forwarded.
# To send custom headers, set EXTERNAL_MCP_HEADERS to a JSON string.
#EXTERNAL_MCP_URL=
#EXTERNAL_MCP_HEADERS=

# External MCP transport: "sse" or "streamable-http" (default).
#EXTERNAL_MCP_TRANSPORT=

# Set "true" to enable registration of datarobot deployments tagged as "tool"
MCP_SERVER_REGISTER_DYNAMIC_TOOLS_ON_STARTUP=false
