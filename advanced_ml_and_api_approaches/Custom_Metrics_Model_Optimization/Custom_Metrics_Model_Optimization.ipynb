{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc8c4f5-788d-40c7-9ff8-5ab102a81e53",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "# Optimize custom model metrics with hyperparameter tuning\n",
    "\n",
    "Author: Zeeshan Arif and Oleksandr Ruppelt\n",
    "\n",
    "Version date: December 2025\n",
    "\n",
    "This notebook demonstrates how to improve DataRobot models using custom loss functions and advanced hyperparameter tuning.\n",
    "\n",
    "In many real-world business problems, standard metrics like RMSE or Accuracy do not fully represent the true business cost. For example, in CLV prediction, overpredicting loss-making customers or underpredicting high-value customers can directly impact revenue and retention strategy. Similarly, classification models often need custom objectives such as maximizing recall at specific thresholds or minimizing false negatives.\n",
    "\n",
    "By creating a custom metric and tuning models using that metric, you ensure the model is optimized for business value, not just statistical performance. This approach is essential when:\n",
    "\n",
    "- Business costs are not symmetrical (over-prediction and under-prediction have different impacts)\n",
    "- False negatives and false positives carry different risk levels \n",
    "- Revenue-driven metrics matter more than standard ML scores\n",
    "- Domain rules must be incorporated into optimization\n",
    "\n",
    "## What this notebook does\n",
    "\n",
    "- Connects to your DataRobot project\n",
    "- Supports both classification (binary & multiclass) and regression projects\n",
    "- Selects top-performing models from the leaderboard for optimization\n",
    "- Uses Bayesian optimization (HyperOpt) to find better hyperparameters\n",
    "- Evaluates models using your custom loss function and tunes the models with hyperparameters\n",
    "- Provides a comparison of original vs. optimized performance\n",
    "\n",
    "### Project validation rule\n",
    "\n",
    "This notebook requires the DataRobot project to be created with Cross-Validation (CV) as the validation method. This is because the tuning logic evaluates models using cross-validation predictions (excluding holdout).\n",
    "\n",
    "## How HyperOpt works\n",
    "\n",
    "HyperOpt is a Bayesian optimization framework that efficiently searches the hyperparameter space. It uses Tree-structured Parzen Estimators (TPE) to model the performance landscape. Instead of random or grid search, it learns from past evaluations to suggest better hyperparameter combinations. This leads to faster convergence and better model performance with fewer iterations.\n",
    "\n",
    "## How to use\n",
    "\n",
    "1. **Download the notebook**  \n",
    "   Clone or download the notebook from your repository or workspace.\n",
    "\n",
    "2. **Create a codespace (optional but recommended)**  \n",
    "   Create codespace inside DataRobot and upload this notebook.\n",
    "\n",
    "3. **Install required libraries**  \n",
    "   All dependencies are listed in the `requirements.txt` file. Run the following command in a terminal or a notebook cell:\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "   Alternatively, a `pip install` cell is already provided in the notebook, simply run that cell.\n",
    "\n",
    "4. **Update the configuration section**  \n",
    "   Set your `PROJECT_ID`, `DR_API_TOKEN`, `DR_ENDPOINT`, and `FALLBACK_TRAINING_PATH` as needed.\n",
    "\n",
    "5. **Run all cells sequentially**  \n",
    "   Execute each cell from top to bottom to ensure proper initialization and execution.\n",
    "\n",
    "6. **Review results**  \n",
    "   Compare original vs optimized model performance in the final output table and visualizations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714e3c04-440b-4d70-8671-7bc804a99b64",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "# Install & import required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37afdeb4",
   "metadata": {
    "datarobot": {
     "execution_time_millis": null
    }
   },
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99efc31",
   "metadata": {
    "datarobot": {
     "execution_time_millis": 11384
    }
   },
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install datetime\n",
    "!pip install warnings\n",
    "!pip install time\n",
    "!pip install tqdm\n",
    "!pip install itertools\n",
    "!pip install plotly\n",
    "!pip install graphviz\n",
    "!pip install seaborn\n",
    "!pip install datarobot\n",
    "!pip install scikit-learn\n",
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbee1fe-4040-4737-9edf-dc023170da81",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a75f9fa-753f-4411-b4b1-bc3b5cdd825f",
   "metadata": {
    "collapsed": true,
    "datarobot": {
     "disable_run": false,
     "execution_time_millis": 5,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "name": "First cell"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************** All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from itertools import product\n",
    "import os\n",
    "import time\n",
    "\n",
    "# DataRobot\n",
    "import datarobot as dr\n",
    "import graphviz\n",
    "\n",
    "# Optimization and ML metrics\n",
    "from hyperopt import fmin, hp, STATUS_OK, tpe, Trials\n",
    "\n",
    "# Visualization\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    precision_score,\n",
    "    r2_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----- Set display options\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", 50)\n",
    "sns.set_style(\"whitegrid\")\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "print(\"***************** All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99043d5a-2b4e-45b0-9249-a3450865965f",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "## Custom metrics library\n",
    "\n",
    "This cell defines a set of custom evaluation metrics for both classification and regression tasks. These metrics can be used to assess model performance beyond standard metrics like accuracy or RMSE. Define your custom metrics below.\n",
    "\n",
    "### Binary classification metrics\n",
    "\n",
    "- `my_cost_score`: Simplified version of `my_cost` returning only the cost value.\n",
    "\n",
    "### Regression metrics\n",
    "\n",
    "- `clv_asymmetry_loss`: A custom asymmetric loss function designed for Customer Lifetime Value (CLV) prediction. It penalizes:\n",
    "  - Overprediction of negative CLV (risk of overspending) with a configurable `over_penalty`\n",
    "  - Underprediction of positive CLV (missed revenue) with a configurable `under_penalty`\n",
    "  - This allows for business-aware tuning of regression models.\n",
    "\n",
    "Custom metrics are especially powerful when standard metrics fail to capture business impactâ€”use them to align model performance with real-world outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42d9a64a-2e50-45d0-8761-c9efc0cde600",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 6,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>  Custom Metrics Library loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# CUSTOM METRICS LIBRARY\n",
    "# ===============================================================\n",
    "# You can define your own metrics directly in this cell.\n",
    "\n",
    "\n",
    "# -------------------- Binary classification metrics --------------------\n",
    "\n",
    "\n",
    "def my_cost(y_true, y_pred_proba):\n",
    "    \"\"\"\n",
    "    Calculates a custom cost metric based on True Negative Rate (TNR) at the highest threshold\n",
    "    that achieves 100% recall.\n",
    "\n",
    "    This function iterates over thresholds from 0.00 to 0.99 to find the one that:\n",
    "    - Achieves perfect recall (i.e., all positive samples are correctly identified)\n",
    "    - Maximizes the true negative rate (TNR) among those thresholds\n",
    "\n",
    "    The cost is defined as: cost = 1 - best TNR\"\"\"\n",
    "\n",
    "    thresholds = np.arange(0.00, 1.0, 0.01)\n",
    "    best_tnr = -1\n",
    "    best_thresh = None\n",
    "    best_recall = None\n",
    "    best_tn = best_fp = best_fn = best_tp = 0\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "\n",
    "        if recall >= 1.0:  # Only consider thresholds that give 100% recall\n",
    "            tnr = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "            if tnr > best_tnr:\n",
    "                best_tnr = tnr\n",
    "                best_thresh = threshold\n",
    "                best_recall = recall\n",
    "                best_tn, best_fp, best_fn, best_tp = tn, fp, fn, tp\n",
    "\n",
    "    if best_tnr == -1:\n",
    "        cost = 1.0\n",
    "        best_thresh = 0.0\n",
    "        best_tnr = 0.0\n",
    "        best_recall = 0.0\n",
    "        best_tn = best_fp = best_fn = best_tp = 0\n",
    "    else:\n",
    "        cost = 1 - best_tnr\n",
    "\n",
    "    return cost, best_thresh, best_recall, best_tnr, best_tn, best_fp, best_fn, best_tp\n",
    "\n",
    "\n",
    "def my_cost_score(y_true, y_pred_proba):\n",
    "    cost, *_ = my_cost(y_true, y_pred_proba)\n",
    "    return cost\n",
    "\n",
    "\n",
    "# -------------------- Regression metrics --------------------\n",
    "def clv_asymmetry_loss(y_true, y_pred, over_penalty=2.0, under_penalty=3.0):\n",
    "    \"\"\"\n",
    "    Custom asymmetric loss for CLV:\n",
    "    - Overpredicting negative CLV is risky (over_penalty)\n",
    "    - Underpredicting positive CLV misses revenue (under_penalty)\n",
    "    \"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    diff = y_pred - y_true\n",
    "    penalty = np.where(\n",
    "        (y_true < 0) & (diff > 0),\n",
    "        over_penalty * np.abs(diff),  # risky overpredict\n",
    "        np.where((y_true > 0) & (diff < 0), under_penalty * np.abs(diff), np.abs(diff)),\n",
    "    )\n",
    "    return np.mean(penalty)\n",
    "\n",
    "\n",
    "print(f\">>>  Custom Metrics Library loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b8feb5-0b87-4c1d-860c-dda043b3fb68",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "# Helper functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a143307-b882-4bd8-8a3e-dfad4dc12de4",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "## DataRobot helper and universal tuning functions\n",
    "\n",
    "Below are some of the DataRobot API features used in this notebook.\n",
    "\n",
    "- Hyperparameter utilities: Extract and format tunable parameters from DataRobot blueprints using `parameters_to_df()` and `get_current_hyperparams()`.\n",
    "- Project type detection: Automatically identify if a project is binary, multiclass, or regression with `detect_project_type()`.\n",
    "- Training data and predictions: Fetch training data and predictions with fallback support using `get_training_data()` and `get_or_request_training_predictions()`.\n",
    "- Search space retrieval: Dynamically assign hyperparameter search spaces based on model names using `get_search_space()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f363d98d-a420-490b-ab3e-18f050921a88",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 8,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# ***************************************************************************************************\n",
    "#  DataRobot Helper and Universal Tuning Functions  (Supports both Classification and Regression)\n",
    "# ***************************************************************************************************\n",
    "\n",
    "\n",
    "def parameters_to_df(params, keep_duplicates=False):\n",
    "    \"\"\"\n",
    "    Return tunable parameters for all blueprint steps from a given modeling blueprint.\n",
    "    \"\"\"\n",
    "    params = params[\"tuning_parameters\"]\n",
    "    dat_param = pd.DataFrame.from_dict(params)\n",
    "    dat_param = pd.concat(\n",
    "        [dat_param, dat_param[\"constraints\"].apply(lambda x: constraints_unfold(x))],\n",
    "        axis=1,\n",
    "    )\n",
    "    dat_param.drop(columns=[\"constraints\"], inplace=True)\n",
    "    dat_param[\"parameter_name_type\"] = dat_param[\"parameter_name\"] + \"_\" + dat_param[\"param_type\"]\n",
    "    res = dat_param[\n",
    "        [\n",
    "            \"task_name\",\n",
    "            \"parameter_name\",\n",
    "            \"parameter_name_type\",\n",
    "            \"current_value\",\n",
    "            \"default_value\",\n",
    "            \"param_type\",\n",
    "            \"supports_grid_search\",\n",
    "            \"min\",\n",
    "            \"max\",\n",
    "            \"values\",\n",
    "            \"parameter_id\",\n",
    "        ]\n",
    "    ].sort_values(\"parameter_name_type\")\n",
    "    if keep_duplicates is not None:\n",
    "        res.drop_duplicates(subset=\"parameter_name_type\", keep=keep_duplicates, inplace=True)\n",
    "    return res.reset_index(drop=True).sort_values(by=\"task_name\")\n",
    "\n",
    "\n",
    "# ***************************************************************************************************\n",
    "\n",
    "\n",
    "def get_or_request_training_predictions(\n",
    "    model: dr.Model, data_subset: dr.enums.DATA_SUBSET\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns the training predictions for a given model and data subset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        training_prediction_job: dr.Job = model.request_training_predictions(\n",
    "            data_subset=data_subset\n",
    "        )\n",
    "        training_prediction_job.wait_for_completion()\n",
    "        training_predictions = training_prediction_job.get_result_when_complete()\n",
    "    except dr.errors.ClientError as e:\n",
    "        if e.status_code == 422:\n",
    "            training_predictions = [\n",
    "                tp\n",
    "                for tp in dr.TrainingPredictions.list(model.project_id)\n",
    "                if tp.data_subset == data_subset and tp.model_id == model.id\n",
    "            ][0]\n",
    "        else:\n",
    "            raise e\n",
    "    return training_predictions.get_all_as_dataframe()\n",
    "\n",
    "\n",
    "# ***************************************************************************************************\n",
    "\n",
    "\n",
    "def constraints_unfold(c_dict):\n",
    "    \"\"\"\n",
    "    Unfold nested JSON constraints from parameter tuning.\n",
    "    \"\"\"\n",
    "    ser_ = pd.Series(list(c_dict.values())[0])\n",
    "    ser_[\"param_type\"] = list(c_dict.keys())[0]\n",
    "    return ser_\n",
    "\n",
    "\n",
    "# ***************************************************************************************************\n",
    "\n",
    "\n",
    "def get_current_hyperparams(model, task_filter=None):\n",
    "    \"\"\"\n",
    "    Fetch current hyperparameter details for a given model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tunable_params = model.get_advanced_tuning_parameters()\n",
    "        params_df = parameters_to_df(tunable_params, keep_duplicates=\"first\")\n",
    "\n",
    "        params_df.columns = [c.lower().strip() for c in params_df.columns]\n",
    "        cols_to_keep = [\n",
    "            \"task_name\",\n",
    "            \"parameter_name\",\n",
    "            \"parameter_name_type\",\n",
    "            \"current_value\",\n",
    "            \"default_value\",\n",
    "            \"param_type\",\n",
    "            \"min\",\n",
    "            \"max\",\n",
    "        ]\n",
    "        params_df = params_df[[c for c in cols_to_keep if c in params_df.columns]]\n",
    "        return params_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\">>>>>>>>>>>>>> Error fetching params for model {model.id}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "# ***************************************************************************************************\n",
    "\n",
    "\n",
    "def get_search_space(model_name):\n",
    "    \"\"\"\n",
    "    Return search space for a given model name.\n",
    "    (Keep as it is; fallback if not found.)\n",
    "    \"\"\"\n",
    "    for key in SEARCH_SPACES.keys():\n",
    "        if key.lower() in model_name.lower():\n",
    "            print(f\" Search space found for model: {key}\")\n",
    "            return SEARCH_SPACES[key]\n",
    "\n",
    "    print(f\" Using default search space for model: {model_name}\")\n",
    "    return {\n",
    "        \"n_estimators\": hp.quniform(\"n_estimators\", 100, 500, 50),\n",
    "        \"max_depth\": hp.quniform(\"max_depth\", 3, 10, 1),\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.3),\n",
    "    }\n",
    "\n",
    "\n",
    "# ***************************************************************************************************\n",
    "# Universal Metric Function (New)\n",
    "# ***************************************************************************************************\n",
    "\n",
    "# ***************************************************************************************************\n",
    "# Detect Project Type\n",
    "# ***************************************************************************************************\n",
    "\n",
    "\n",
    "def detect_project_type(proj):\n",
    "    \"\"\"Detects if project is binary, multiclass, or regression.\"\"\"\n",
    "    if proj.target_type in [\"Binary\"]:\n",
    "        return \"binary\"\n",
    "    elif proj.target_type in [\"Regression\"]:\n",
    "        return \"regression\"\n",
    "    else:\n",
    "        return \"multiclass\"\n",
    "\n",
    "\n",
    "# ***************************************************************************************************\n",
    "# Get Training Data Helper\n",
    "# ***************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1902c804-9eda-49ae-b6a7-dcdc77e21edf",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "# Optimization logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df171859-04e6-45a0-86f7-2d25c76ec6d5",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "## `tune_and_compare_model()` \n",
    "\n",
    "This function performs custom metric-based hyperparameter tuning using HyperOpt for DataRobot models.\n",
    "\n",
    "### What it does\n",
    "\n",
    "- Supports only binary classification and regression projects.\n",
    "- Uses user-defined global variables:\n",
    "  - `USER_CUSTOM_METRIC`, `METRIC_FUNCTION`, `METRIC_DIRECTION`, `METRIC_INPUT_TYPE`.\n",
    "\n",
    "### Key steps\n",
    "\n",
    "- Helper: `detect_prob_col()`  \n",
    "  Identifies the correct probability column for binary classification predictions.\n",
    "\n",
    "- Helper: `get_output()`  \n",
    "  Formats model predictions based on project type and metric input (label or probability).\n",
    "\n",
    "- Load training data  \n",
    "  Uses `get_training_data()` and extracts project metadata like target name and type.\n",
    "\n",
    "- Validate metric configuration  \n",
    "  Prints the selected custom metric name, function, direction, and input type.\n",
    "\n",
    "- Evaluate base model  \n",
    "  Fetches training predictions for the base model and computes the baseline metric score.\n",
    "\n",
    "- Define `objective()` function  \n",
    "  - Starts a tuning session on the base model.\n",
    "  - Applies parameter values from HyperOpt.\n",
    "  - Trains a new model and evaluates it using the custom metric.\n",
    "  - Computes performance delta vs. base model.\n",
    "  - Returns results to HyperOpt.\n",
    "\n",
    "- Run HyperOpt  \n",
    "  Executes Bayesian optimization (`tpe.suggest`) over the defined search space for `max_evals` trials.\n",
    "\n",
    "- Build final comparison table  \n",
    "  - Aggregates all trials and their metrics.\n",
    "  - Adds the base model as trial 0.\n",
    "  - Sorts models by metric (ascending or descending based on `METRIC_DIRECTION`).\n",
    "  - Returns a final DataFrame comparing all tuned models.\n",
    "\n",
    "Use this function to automate model tuning with domain-specific metrics and compare improvements over the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da90b5b6-0d58-4ba1-a801-831204a85096",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 12,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## new one :\n",
    "\n",
    "\n",
    "# **************************************************************************************************\n",
    "def tune_and_compare_model(proj, base_model_id, search_space, max_evals, fallback_path=None):\n",
    "    \"\"\"\n",
    "    Universal model tuning function (classification + regression) using HyperOpt.\n",
    "\n",
    "    Performs custom metric-based hyperparameter optimization,\n",
    "    evaluates the base model and tuned models, and returns a clean comparison table.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Columns:\n",
    "            trial, model_id, model_name, type, USER_CUSTOM_METRIC, delta, status, + tuned parameters\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # ðŸ”¹ ------------Loading training data and project info\n",
    "    # -------------------------------------------------------------\n",
    "    train_df = get_training_data(proj, fallback_path=fallback_path)\n",
    "    target_name = proj.target\n",
    "    project_type = detect_project_type(proj)\n",
    "\n",
    "    if project_type not in [\"binary\", \"regression\"]:\n",
    "        raise RuntimeError(f\"XX Unsupported project type: {project_type}\")\n",
    "\n",
    "    print(f\"1. Training data shape: {train_df.shape}\")\n",
    "    print(f\"2. Target variable: {target_name}\")\n",
    "    print(f\"3. Project Type: {project_type}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    if \"row_id\" not in train_df.columns:\n",
    "        train_df = train_df.reset_index().rename(columns={\"index\": \"row_id\"})\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # ðŸ”¹ Base model & metric setup\n",
    "    # -------------------------------------------------------------\n",
    "    base_model = dr.Model.get(proj.id, base_model_id)\n",
    "    print(f\"XX Starting tuning for: {base_model.model_type} | ID: {base_model_id}\")\n",
    "    print(f\"XXX Custom Metric: {USER_CUSTOM_METRIC}\")\n",
    "    print(f\"XXXX  Metric Function: {METRIC_FUNCTION.__name__}\")\n",
    "    print(f\"XXXXX  Direction: {METRIC_DIRECTION}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # ðŸ”¹ -------------Evaluating base model\n",
    "    # -------------------------------------------------------------\n",
    "    preds = get_or_request_training_predictions(base_model, dr.enums.DATA_SUBSET.ALL)\n",
    "    merged = train_df.merge(preds, on=\"row_id\", how=\"inner\")\n",
    "    cv = merged[merged[\"partition_id\"] != \"Holdout\"]\n",
    "\n",
    "    y_true = cv[target_name].values\n",
    "\n",
    "    # --- get_output auto-handles regression/classification\n",
    "    def get_output(df):\n",
    "        if project_type == \"binary\":\n",
    "            prob_col = \"class_1\" if \"class_1\" in df.columns else \"prediction\"\n",
    "            y_pred = df[prob_col].values\n",
    "            return (y_pred >= 0.5).astype(int) if METRIC_INPUT_TYPE == \"label\" else y_pred\n",
    "        elif project_type == \"regression\":\n",
    "            if \"prediction\" not in df.columns:\n",
    "                raise KeyError(\"xxxxxxxxxxx No 'prediction' column found for regression.\")\n",
    "            return df[\"prediction\"].values\n",
    "\n",
    "    y_pred = get_output(cv)\n",
    "    base_loss = float(METRIC_FUNCTION(y_true, y_pred))\n",
    "\n",
    "    print(f\"X Base {USER_CUSTOM_METRIC}: {base_loss:.6f}\")\n",
    "    BASE_METRICS = {\"metric\": base_loss}\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # ðŸ”¹ -----------Objective Function for HyperOpt\n",
    "    # -------------------------------------------------------------\n",
    "    def objective(params):\n",
    "        print(f\"*********** Trying params: {params}\")\n",
    "        try:\n",
    "            tune_session = base_model.start_advanced_tuning_session()\n",
    "            task_names = tune_session.get_task_names()\n",
    "\n",
    "            algo_task = [\n",
    "                t\n",
    "                for t in task_names\n",
    "                if any(k in t.lower() for k in [\"classifier\", \"regressor\", \"model\", \"prediction\"])\n",
    "            ]\n",
    "            algo_task = algo_task[-1] if algo_task else task_names[-1]\n",
    "\n",
    "            # --- ApplyING parameters safely\n",
    "            for param, value in params.items():\n",
    "                value = (\n",
    "                    int(value) if isinstance(value, float) and value.is_integer() else float(value)\n",
    "                )\n",
    "                try:\n",
    "                    tune_session.set_parameter(\n",
    "                        task_name=algo_task, parameter_name=param, value=value\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"XXXXXXXXXX Skipping param {param}: {e}\")\n",
    "\n",
    "            # --- Run tuning job\n",
    "            job = tune_session.run()\n",
    "            tuned_model = job.get_result_when_complete()\n",
    "\n",
    "            # --- Evaluate tuned model\n",
    "            preds_tuned = get_or_request_training_predictions(tuned_model, dr.enums.DATA_SUBSET.ALL)\n",
    "            merged_tuned = train_df.merge(preds_tuned, on=\"row_id\", how=\"inner\")\n",
    "            cv_tuned = merged_tuned[merged_tuned[\"partition_id\"] != \"Holdout\"].copy()\n",
    "\n",
    "            y_true_tuned = cv_tuned[target_name].values\n",
    "            y_pred_tuned = get_output(cv_tuned)\n",
    "            tuned_loss = float(METRIC_FUNCTION(y_true_tuned, y_pred_tuned))\n",
    "\n",
    "            # --- Compute delta\n",
    "            delta = tuned_loss - base_loss if METRIC_DIRECTION == \"max\" else base_loss - tuned_loss\n",
    "            print(f\"XXXXXXXXXXXXXX Tuned {USER_CUSTOM_METRIC}: {tuned_loss:.6f} | Î” = {delta:.6f}\")\n",
    "\n",
    "            return {\n",
    "                \"loss\": tuned_loss,  # required by HyperOpt\n",
    "                \"status\": STATUS_OK,\n",
    "                \"model_id\": tuned_model.id,\n",
    "                \"model_name\": base_model.model_type,\n",
    "                \"type\": \"Tuned\",\n",
    "                USER_CUSTOM_METRIC: tuned_loss,\n",
    "                \"delta\": delta,\n",
    "                **{f\"param_{k}\": v for k, v in params.items()},\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"XXXXXXXXXXXXX Error during tuning trial: {e}\")\n",
    "            return {\"loss\": 9999.0, \"status\": \"failed\", \"type\": \"Tuned\"}\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # ðŸ”¹ --------Running HyperOpt\n",
    "    # -------------------------------------------------------------\n",
    "    trials = Trials()\n",
    "    best = fmin(\n",
    "        fn=objective, space=search_space, algo=tpe.suggest, max_evals=max_evals, trials=trials\n",
    "    )\n",
    "    print(\"\\nxxxxxxxxxxxxxxx Best Params:\", best)\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # ðŸ”¹------------ Collecting all trial results\n",
    "    # -------------------------------------------------------------\n",
    "    results = []\n",
    "    for i, t in enumerate(trials.trials):\n",
    "        res = t[\"result\"]\n",
    "        if \"loss\" not in res or res[\"loss\"] == 9999.0:\n",
    "            continue\n",
    "        results.append(\n",
    "            {\n",
    "                \"trial\": i + 1,\n",
    "                \"model_id\": res.get(\"model_id\"),\n",
    "                \"model_name\": res.get(\"model_name\"),\n",
    "                \"type\": res.get(\"type\", \"Tuned\"),\n",
    "                USER_CUSTOM_METRIC: res.get(USER_CUSTOM_METRIC, res.get(\"loss\")),\n",
    "                \"delta\": res.get(\"delta\", 0.0),\n",
    "                \"status\": res.get(\"status\", \"ok\"),\n",
    "                **{k: v for k, v in res.items() if k.startswith(\"param_\")},\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df_tuned = pd.DataFrame(results)\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # ðŸ”¹----------------- Add Base Model Row\n",
    "    # -------------------------------------------------------------\n",
    "    base_row = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"trial\": 0,\n",
    "                \"model_id\": base_model.id,\n",
    "                \"model_name\": base_model.model_type,\n",
    "                \"type\": \"Original\",\n",
    "                USER_CUSTOM_METRIC: base_loss,\n",
    "                \"delta\": 0.0,\n",
    "                \"status\": \"ok\",\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # ðŸ”¹ -------------------Combine and Sort\n",
    "    # -------------------------------------------------------------\n",
    "    ascending = METRIC_DIRECTION == \"min\"\n",
    "    df_final = pd.concat([base_row, df_tuned], ignore_index=True)\n",
    "    df_final = df_final.sort_values(by=USER_CUSTOM_METRIC, ascending=ascending)\n",
    "    df_final.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"\\nXXXXXXXXXXXXX Final Comparison Created | Shape: {df_final.shape}\")\n",
    "    print(f\"xxxxxxxxxxxxxxx Best {USER_CUSTOM_METRIC}: {df_final.iloc[0][USER_CUSTOM_METRIC]:.6f}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656afbaf-8d97-4fbf-9aba-1dac4a8cc3bb",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb058b8-dcda-4d11-8e1c-3d9305ab792d",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "## Configuration and project validation\n",
    "\n",
    "This section sets up the environment, defines tuning parameters, and validates the project type before proceeding with model optimization. Set your parameters here.\n",
    "\n",
    "### DataRobot credentials\n",
    "\n",
    "- `DR_ENDPOINT`: The API endpoint for your DataRobot instance.  \n",
    "  Example: `'https://app.datarobot.com/api/v2'`\n",
    "- `DR_API_TOKEN`: Your personal API token for authenticating with DataRobot.  \n",
    "  Keep this secret and secure.\n",
    "\n",
    "### Project and data setup\n",
    "\n",
    "- `PROJECT_ID`: The unique identifier of your DataRobot project.  \n",
    "  Example: `'692d8ac9f3a7f8fff356745f'`\n",
    "- `FALLBACK_TRAINING_PATH`: Local CSV file path to load training data if the API-based fetch fails.  \n",
    "  Example: `'Regression_Data.csv'`\n",
    "\n",
    "### Model selection and sorting\n",
    "\n",
    "- `TOP_N_MODELS`: Number of top leaderboard models to select for tuning.  \n",
    "  Example: `5`\n",
    "- `PREFERRED_METRICS`: Default metrics used to sort models before tuning.  \n",
    "  For binary: `\"LogLoss\"` or `\"AUC\"`  \n",
    "  For regression: `\"RMSE\"`, `\"MAE\"`, or `\"R2\"`\n",
    "- `SORT_METRIC`: Optional override to sort models by a specific metric.  \n",
    "  Set to `None` to use defaults from `PREFERRED_METRICS`.\n",
    "\n",
    "### Custom metric configuration\n",
    "\n",
    "- `USER_CUSTOM_METRIC`: Name of the custom metric used for optimization.  \n",
    "  Example: `'clv_asymmetry_loss'`, `'my_cost_score'`\n",
    "- `METRIC_FUNCTION`: The actual Python function that computes the custom metric.  \n",
    "  Must be callable, e.g., `clv_asymmetry_loss`\n",
    "- `METRIC_DIRECTION`: Whether to minimize or maximize the metric.  \n",
    "  `\"min\"` for loss functions (e.g., RMSE, LogLoss)  \n",
    "  `\"max\"` for gain metrics (e.g., AUC, R2)\n",
    "- `METRIC_INPUT_TYPE`: Format of model predictions expected by the metric.  \n",
    "  `\"label\"`: Binary class labels (0 or 1)  \n",
    "  `\"proba\"`: Predicted probabilities for the positive class  \n",
    "  `\"numeric\"`: Continuous values (for regression)\n",
    "\n",
    "### Project validation\n",
    "\n",
    "- Connects to the DataRobot project using `PROJECT_ID`.\n",
    "- Detects the project type using `detect_project_type()`.\n",
    "- Ensures the project is either:\n",
    "  - `\"binary\"` for binary classification\n",
    "  - `\"regression\"` for regression tasks\n",
    "\n",
    "All configurations must be correctly set before proceeding. The notebook will raise errors if any required setting is missing or invalid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c77b6a6d-828a-4e1a-a580-78efdfd41716",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 268,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== CUSTOM METRIC CONFIGURATION =====\n",
      " Metric Function : clv_asymmetry_loss\n",
      " Direction       : min\n",
      " Input Type      : numeric\n",
      "========================================\n",
      "\n",
      "================================================================================\n",
      " SELECTING MODELS FOR OPTIMIZATION\n",
      "================================================================================\n",
      "\n",
      "â†’ Project ID: 692fd31ca5a8b5da9689a2a1\n",
      "â†’ Detected project type: regression\n",
      "\n",
      "âœ“ Project is valid for tuning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----- DataRobot Credentials:\n",
    "DR_ENDPOINT = \"https://app.datarobot.com/api/v2\"\n",
    "DR_API_TOKEN = (\n",
    "    \"NjkyZmJlOWNmMjgwNTdmMjI5ZGEyN2ZmOmJGZWVXclhTT2dPQytIa0oyd09aR2ZaWWlUak5DUTYraXhjTHd3UTJWKzA9\"\n",
    ")\n",
    "\n",
    "## ---------- Project Id :\n",
    "PROJECT_ID = \"692fd31ca5a8b5da9689a2a1\"\n",
    "\n",
    "dr.Client(endpoint=DR_ENDPOINT, token=DR_API_TOKEN)  ## End point and token-----\n",
    "\n",
    "\n",
    "# ----- Fallback Data Path (for API-created projects) ----- pass the training dataset path :\n",
    "# FALLBACK_TRAINING_PATH = \"DR_Demo_AML_Alert.csv\"\n",
    "FALLBACK_TRAINING_PATH = \"Regression_Data.csv\"\n",
    "\n",
    "\n",
    "# --------- How many top models to optimize\n",
    "TOP_N_MODELS = 3\n",
    "\n",
    "# ---------- Metric to sort models by (default: LogLoss for binary classification)\n",
    "PREFERRED_METRICS = {\n",
    "    \"binary\": \"LogLoss\",  # alternatives: \"LogLoss\" (lower better) or \"AUC\" (higher better)\n",
    "    \"regression\": \"RMSE\",  # alternatives: \"MAE\", \"R2\" (R2 higher is better)\n",
    "}\n",
    "\n",
    "\n",
    "SORT_METRIC = None  #  # sort your models based on metric\n",
    "\n",
    "# ------------HyperOpt budget: how many evaluations to try (increase for better tuning)\n",
    "MAX_EVALS = 2  # 3,4,5\n",
    "\n",
    "# USER_CUSTOM_METRIC = \"my_cost_score\"  # my_cost_score     # clv_asymmetry_loss\n",
    "USER_CUSTOM_METRIC = \"clv_asymmetry_loss\"\n",
    "\n",
    "# ---------------------\n",
    "# Metric direction map (minimize or maximize)\n",
    "# Use lower=better (\"min\") or higher=better (\"max\")\n",
    "# Add new metrics here as needed.\n",
    "# ---------------------\n",
    "METRIC_FUNCTION = clv_asymmetry_loss  # actual python function i.e  (CUSTOMN METRICS)\n",
    "METRIC_DIRECTION = \"min\"  # or \"max\"\n",
    "METRIC_INPUT_TYPE = \"numeric\"  # or \"label\" or \"numeric\"  , proba   # Regression - numeric\n",
    "\n",
    "\n",
    "##      ***********************************************************************************************************************************************************\n",
    "\n",
    "######  ********************************************   END OF Configuration  ******************************************\n",
    "\n",
    "if USER_CUSTOM_METRIC is None:\n",
    "    raise RuntimeError(\n",
    "        \"!!!!!!!!111 USER_CUSTOM_METRIC must be defined. Example:\\n\"\n",
    "        \"    USER_CUSTOM_METRIC = 'my_cost_score'\"\n",
    "    )\n",
    "\n",
    "if METRIC_FUNCTION is None or not callable(METRIC_FUNCTION):\n",
    "    raise RuntimeError(\n",
    "        \"!!!!!!!!!!!11 METRIC_FUNCTION is missing or not callable.\\n\"\n",
    "        \"Example:\\n\"\n",
    "        \"    METRIC_FUNCTION = my_cost_score\"\n",
    "    )\n",
    "\n",
    "if METRIC_DIRECTION not in [\"min\", \"max\"]:\n",
    "    raise ValueError(\"!!!!!!!!!!1111 METRIC_DIRECTION must be either 'min' or 'max'.\")\n",
    "\n",
    "if METRIC_INPUT_TYPE not in [\"label\", \"proba\", \"numeric\"]:\n",
    "    raise ValueError(\"!!!!!!!111 METRIC_INPUT_TYPE must be 'label', 'proba', or 'numeric'.\")\n",
    "\n",
    "print(\"\\n===== CUSTOM METRIC CONFIGURATION =====\")\n",
    "print(f\" Metric Function : {METRIC_FUNCTION.__name__}\")\n",
    "print(f\" Direction       : {METRIC_DIRECTION}\")\n",
    "print(f\" Input Type      : {METRIC_INPUT_TYPE}\")\n",
    "print(\"========================================\\n\")\n",
    "\n",
    "\n",
    "# ======================================\n",
    "#   ********************8  PROJECT VALIDATION (ONLY 2 TYPES)\n",
    "# ======================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\" SELECTING MODELS FOR OPTIMIZATION\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "proj = dr.Project.get(PROJECT_ID)\n",
    "print(f\"â†’ Project ID: {PROJECT_ID}\")\n",
    "\n",
    "project_type = detect_project_type(proj)\n",
    "print(f\"â†’ Detected project type: {project_type}\")\n",
    "\n",
    "\n",
    "#  multiclass not allowed now\n",
    "if project_type not in {\"binary\", \"regression\"}:\n",
    "    raise RuntimeError(\n",
    "        f\"............... Unsupported project type: {project_type}\\n\"\n",
    "        \"This notebook now supports **only binary classification and regression**.\\n\"\n",
    "        \"For multiclass, build a separate notebook.\"\n",
    "    )\n",
    "\n",
    "print(\"\\nâœ“ Project is valid for tuning.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c914dc95-08a4-49b6-b675-c1c920c0d439",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "The next 3 cells will:\n",
    "\n",
    "1. Select the top N models from your leaderboard\n",
    "2. Loop through top N models and output a table of their tunable hyperparameters\n",
    "3. Manually define a search space with 1. list of hyperparameters you would like to tune, and 2. their search spaces\n",
    "\n",
    "The search space can be customized: use the table output `filtered_df` and accordingly update the search space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5286ca-f57c-48da-bd7d-727659535748",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "# Select the top N models from the project Leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1136527a-f966-4b3e-b1f3-2d3387448110",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "## Model selection for optimization\n",
    "\n",
    "This section identifies and prepares the top-performing models from the DataRobot leaderboard for hyperparameter tuning.\n",
    "\n",
    "### Step-by-step breakdown\n",
    "\n",
    "1. **Project initialization**  \n",
    "   Loads the project using the `PROJECT_ID` defined earlier. Prints the project ID for confirmation.\n",
    "\n",
    "2. **Project type detection**  \n",
    "   Uses `detect_project_type()` to determine if the project is:\n",
    "   - `\"binary\"` for binary classification\n",
    "   - `\"regression\"` for regression\n",
    "   This helps in selecting the appropriate metric for sorting models.\n",
    "\n",
    "3. **Sorting metric selection**  \n",
    "   If `SORT_METRIC` is not explicitly set, it defaults to:\n",
    "   - `\"LogLoss\"` for binary classification\n",
    "   - `\"RMSE\"` for regression\n",
    "   This metric is used to rank models for tuning.\n",
    "\n",
    "4. **Recommended model retrieval**  \n",
    "   Attempts to fetch the recommended model for deployment using `ModelRecommendation`. If found, its ID is stored to exclude it from tuning (to avoid overwriting production-ready models). This avoids modifying models that are ready for deployment.\n",
    "\n",
    "5. **Leaderboard model fetching**  \n",
    "   Retrieves all models from the project leaderboard using `proj.get_models()`.\n",
    "\n",
    "6. **Top-N model selection**  \n",
    "   Filters out the recommended model (if any). Selects the top `TOP_N_MODELS` from the remaining list for tuning.\n",
    "\n",
    "7. **Model metadata extraction**  \n",
    "   For each selected model:\n",
    "   - Retrieves full model details\n",
    "   - Extracts:\n",
    "     - Model ID\n",
    "     - Model Name\n",
    "     - Validation and Holdout scores for the selected `SORT_METRIC`\n",
    "   - Stores this information in a DataFrame.\n",
    "\n",
    "8. **Sorting models by metric**  \n",
    "   Sorts the DataFrame by the selected validation metric (e.g., `Validation LogLoss`). If the metric is missing, sorting is skipped with a warning.\n",
    "\n",
    "9. **Final output**  \n",
    "   Displays the top models selected for tuning.\n",
    "\n",
    "### Why this matters\n",
    "\n",
    "This step ensures that only the most promising models are passed to the tuning phase, improving efficiency and focusing optimization on high-potential candidates. It also avoids modifying any model already recommended for deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ee6aee-161a-4e6d-a008-df77aa6dbd24",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 7607,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " SELECTING MODELS FOR OPTIMIZATION\n",
      "================================================================================\n",
      "\n",
      " ***************  >>>>    Project Id is:: 692fd31ca5a8b5da9689a2a1\n",
      " Detected project type: regression\n",
      "ðŸ”¹ Sorting models by: RMSE\n",
      "\n",
      " Recommended model for deployment: Light Gradient Boosting on ElasticNet Predictions  | ID: 692fd4f4d120ebaebc84bdd8\n",
      " Total models retrieved: 9\n",
      " Selected top 3 models for tuning.\n",
      "\n",
      ">>> Sorted models by: Validation RMSE\n",
      "\n",
      "!!!!!!!!!11 Final model list shape: (3, 4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.dataframe+json": {
       "columns": [
        {
         "name": "index",
         "type": "integer"
        },
        {
         "name": "Model ID",
         "type": "string"
        },
        {
         "name": "Model Name",
         "type": "string"
        },
        {
         "name": "Validation RMSE",
         "type": "number"
        },
        {
         "name": "Holdout RMSE",
         "type": "number"
        }
       ],
       "count": 3,
       "data": [
        {
         "Holdout RMSE": 133.21948,
         "Model ID": "692fd37102faa1b369c44af7",
         "Model Name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)",
         "Validation RMSE": 124.87085,
         "index": 0
        },
        {
         "Holdout RMSE": 121.59392,
         "Model ID": "692fd37102faa1b369c44afa",
         "Model Name": "Light Gradient Boosting on ElasticNet Predictions ",
         "Validation RMSE": 126.70173,
         "index": 1
        },
        {
         "Holdout RMSE": 132.64639,
         "Model ID": "692fd37102faa1b369c44af6",
         "Model Name": "Ridge Regressor",
         "Validation RMSE": 138.34444,
         "index": 2
        }
       ],
       "error": [],
       "indexKey": "index",
       "limit": 10,
       "offset": 0,
       "referenceId": 140548129482192,
       "sortedBy": "",
       "totalCount": 3
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model ID</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Validation RMSE</th>\n",
       "      <th>Holdout RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>692fd37102faa1b369c44af7</td>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>124.87085</td>\n",
       "      <td>133.21948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>126.70173</td>\n",
       "      <td>121.59392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>692fd37102faa1b369c44af6</td>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>138.34444</td>\n",
       "      <td>132.64639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model ID  \\\n",
       "0  692fd37102faa1b369c44af7   \n",
       "1  692fd37102faa1b369c44afa   \n",
       "2  692fd37102faa1b369c44af6   \n",
       "\n",
       "                                          Model Name  Validation RMSE  \\\n",
       "0  Elastic-Net Regressor (mixing alpha=0.5 / Leas...        124.87085   \n",
       "1  Light Gradient Boosting on ElasticNet Predicti...        126.70173   \n",
       "2                                    Ridge Regressor        138.34444   \n",
       "\n",
       "   Holdout RMSE  \n",
       "0     133.21948  \n",
       "1     121.59392  \n",
       "2     132.64639  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>>>>>>>>> Models successfully selected for optimization.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" SELECTING MODELS FOR OPTIMIZATION\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "# ---------- Define the project\n",
    "project_id = PROJECT_ID  # from configuration cell\n",
    "print(\" ***************  >>>>    Project Id is::\", project_id)\n",
    "proj = dr.Project.get(project_id)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----------- Detect Project Type (for auto metric selection)\n",
    "# --------------------------------------------------------------\n",
    "project_type = detect_project_type(proj)\n",
    "print(f\" Detected project type: {project_type}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# --------- Dynamically choose sorting metric\n",
    "# --------------------------------------------------------------\n",
    "if SORT_METRIC is None:\n",
    "    if project_type == \"binary\":\n",
    "        SORT_METRIC = PREFERRED_METRICS[\"binary\"]\n",
    "\n",
    "    else:\n",
    "        SORT_METRIC = PREFERRED_METRICS[\"regression\"]\n",
    "\n",
    "print(f\"Sorting models by: {SORT_METRIC}\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ------------Get recommended deployment model (if any)\n",
    "# --------------------------------------------------------------\n",
    "try:\n",
    "    recom_model = dr.ModelRecommendation.get(\n",
    "        proj.id, dr.enums.RECOMMENDED_MODEL_TYPE.RECOMMENDED_FOR_DEPLOYMENT\n",
    "    ).get_model()\n",
    "    recom_model_id = recom_model.id\n",
    "    print(f\" Recommended model for deployment: {recom_model.model_type} | ID: {recom_model_id}\")\n",
    "except Exception as e:\n",
    "    recom_model_id = None\n",
    "    print(\"No recommended model found or error occurred:\", e)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Fetch leaderboard models\n",
    "# --------------------------------------------------------------\n",
    "all_models = proj.get_models()\n",
    "print(f\" Total models retrieved: {len(all_models)}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Filter: top N models (excluding recommended)\n",
    "# --------------------------------------------------------------\n",
    "top_models = [m for m in all_models if m.id != recom_model_id][:TOP_N_MODELS]\n",
    "print(f\" Selected top {len(top_models)} models for tuning.\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Extract relevant details for DataFrame\n",
    "# --------------------------------------------------------------\n",
    "model_data = []\n",
    "for m in top_models:\n",
    "    try:\n",
    "        full_model = dr.Model.get(project_id, m.id)\n",
    "        model_data.append(\n",
    "            {\n",
    "                \"Model ID\": full_model.id,\n",
    "                \"Model Name\": full_model.model_type,\n",
    "                f\"Validation {SORT_METRIC}\": full_model.metrics.get(SORT_METRIC, {}).get(\n",
    "                    \"validation\"\n",
    "                ),\n",
    "                f\"Holdout {SORT_METRIC}\": full_model.metrics.get(SORT_METRIC, {}).get(\"holdout\"),\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\" >>>>>> Skipping {m.id} ({m.model_type}): {e}\")\n",
    "        continue\n",
    "\n",
    "df_models = pd.DataFrame(model_data)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Sort by chosen validation metric (if available)\n",
    "# --------------------------------------------------------------\n",
    "sort_col = f\"Validation {SORT_METRIC}\"\n",
    "if sort_col in df_models.columns:\n",
    "    df_models = df_models.sort_values(by=sort_col, ascending=True)\n",
    "    print(f\">>> Sorted models by: {sort_col}\")\n",
    "else:\n",
    "    print(f\">>>>> Sort metric '{SORT_METRIC}' not found in model metrics â€” skipping sort.\")\n",
    "\n",
    "print(f\"\\n!!!!!!!!!11 Final model list shape: {df_models.shape}\")\n",
    "display(df_models.head())\n",
    "\n",
    "if df_models.empty:\n",
    "    print(\"\\n!!!!!!!!!!!!! No successful tuning results found or no models available.\")\n",
    "else:\n",
    "    print(\"\\n>>>>>>>>>>>>> Models successfully selected for optimization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77540906-9c6f-470d-83ab-597f73e06ed2",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "## Fetch tunable parameters for top models\n",
    "\n",
    "This section extracts tunable hyperparameters from the top selected models to prepare for optimization.\n",
    "\n",
    "### Step-by-step breakdown\n",
    "\n",
    "1. **Initialization**  \n",
    "   Prints a header to indicate the start of parameter extraction. Detects the project type (`binary` or `regression`) for logging and consistency.\n",
    "\n",
    "2. **Loop through selected models**  \n",
    "   Iterates over each model in `df_models` (previously selected top models). For each model:\n",
    "   - Retrieves the full model object using its ID.\n",
    "   - Calls `get_current_hyperparams()` to extract tunable parameters.\n",
    "   - If parameters are found:\n",
    "     - Adds metadata like Model ID, Model Name, and Project Type.\n",
    "\n",
    "3. **Combine all parameters**  \n",
    "   Concatenates all individual parameter DataFrames into a single `df_all_params`.\n",
    "\n",
    "4. **Filter parameters by task name**  \n",
    "   Adds lowercase helper columns for `task_name` and `model_name` to enable case-insensitive filtering. Filters rows where the model name is found within the task name (to isolate relevant tuning steps).\n",
    "\n",
    "5. **Final output**  \n",
    "   Prints the shape of the final filtered DataFrame. Displays the filtered parameter set (`filtered_df`) which will be used for tuning.\n",
    "\n",
    "### Why this matters\n",
    "\n",
    "This step ensures that only the relevant and tunable parameters for each model are extracted and prepared for optimization. Filtering by task name ensures that parameters are correctly aligned with the model's core algorithm step (e.g., classifier or regressor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b56f2015-016a-465d-899d-a4a3c7c32e26",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 4084,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " FETCHING TUNABLE PARAMETERS FOR TOP MODELS\n",
      "================================================================================\n",
      "\n",
      "Detected project type: regression\n",
      "\n",
      ">>>>>>>>>>>>>>>> Fetching tunable parameters for Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss) (692fd37102faa1b369c44af7)...\n",
      "\n",
      ">>>>>>>>>>>>>>>> Fetching tunable parameters for Light Gradient Boosting on ElasticNet Predictions  (692fd37102faa1b369c44afa)...\n",
      "\n",
      ">>>>>>>>>>>>>>>> Fetching tunable parameters for Ridge Regressor (692fd37102faa1b369c44af6)...\n",
      "\n",
      " Final dataframe created with 58 rows and 11 columns.\n",
      " Filtered dataframe created with 42 rows (matching task_name â†” model_name).\n",
      "(42, 11)\n"
     ]
    },
    {
     "data": {
      "application/vnd.dataframe+json": {
       "columns": [
        {
         "name": "index",
         "type": "integer"
        },
        {
         "name": "task_name",
         "type": "string"
        },
        {
         "name": "parameter_name",
         "type": "string"
        },
        {
         "name": "parameter_name_type",
         "type": "string"
        },
        {
         "name": "current_value",
         "type": "string"
        },
        {
         "name": "default_value",
         "type": "string"
        },
        {
         "name": "param_type",
         "type": "string"
        },
        {
         "name": "min",
         "type": "number"
        },
        {
         "name": "max",
         "type": "number"
        },
        {
         "name": "Model ID",
         "type": "string"
        },
        {
         "name": "Model Name",
         "type": "string"
        },
        {
         "name": "Project Type",
         "type": "string"
        }
       ],
       "count": 10,
       "data": [
        {
         "Model ID": "692fd37102faa1b369c44af7",
         "Model Name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)",
         "Project Type": "regression",
         "current_value": 0.5,
         "default_value": 0.5,
         "index": 0,
         "max": null,
         "min": null,
         "param_type": "select",
         "parameter_name": "enet_alpha",
         "parameter_name_type": "enet_alpha_select",
         "task_name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)"
        },
        {
         "Model ID": "692fd37102faa1b369c44af7",
         "Model Name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)",
         "Project Type": "regression",
         "current_value": 0.0034738921,
         "default_value": 0.0034738921,
         "index": 1,
         "max": null,
         "min": null,
         "param_type": "select",
         "parameter_name": "enet_lambda",
         "parameter_name_type": "enet_lambda_select",
         "task_name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)"
        },
        {
         "Model ID": "692fd37102faa1b369c44af7",
         "Model Name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)",
         "Project Type": "regression",
         "current_value": "True",
         "default_value": "True",
         "index": 2,
         "max": null,
         "min": null,
         "param_type": "select",
         "parameter_name": "fit_alpha_scaler",
         "parameter_name_type": "fit_alpha_scaler_select",
         "task_name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)"
        },
        {
         "Model ID": "692fd37102faa1b369c44af7",
         "Model Name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)",
         "Project Type": "regression",
         "current_value": "True",
         "default_value": "True",
         "index": 3,
         "max": null,
         "min": null,
         "param_type": "select",
         "parameter_name": "fit_intercept",
         "parameter_name_type": "fit_intercept_select",
         "task_name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)"
        },
        {
         "Model ID": "692fd37102faa1b369c44af7",
         "Model Name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)",
         "Project Type": "regression",
         "current_value": "False",
         "default_value": "False",
         "index": 4,
         "max": null,
         "min": null,
         "param_type": "select",
         "parameter_name": "fit_tweedie_p",
         "parameter_name_type": "fit_tweedie_p_select",
         "task_name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)"
        },
        {
         "Model ID": "692fd37102faa1b369c44af7",
         "Model Name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)",
         "Project Type": "regression",
         "current_value": "squared",
         "default_value": "squared",
         "index": 5,
         "max": null,
         "min": null,
         "param_type": "select",
         "parameter_name": "loss",
         "parameter_name_type": "loss_select",
         "task_name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)"
        },
        {
         "Model ID": "692fd37102faa1b369c44af7",
         "Model Name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)",
         "Project Type": "regression",
         "current_value": 100,
         "default_value": 100,
         "index": 6,
         "max": 1000000,
         "min": 1,
         "param_type": "int",
         "parameter_name": "max_iter",
         "parameter_name_type": "max_iter_int",
         "task_name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)"
        },
        {
         "Model ID": "692fd37102faa1b369c44af7",
         "Model Name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)",
         "Project Type": "regression",
         "current_value": 1234,
         "default_value": 1234,
         "index": 7,
         "max": 1000000000,
         "min": 0,
         "param_type": "int",
         "parameter_name": "random_state",
         "parameter_name_type": "random_state_int",
         "task_name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)"
        },
        {
         "Model ID": "692fd37102faa1b369c44af7",
         "Model Name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)",
         "Project Type": "regression",
         "current_value": 0.0001,
         "default_value": 0.0001,
         "index": 8,
         "max": 10000000000,
         "min": 1e-10,
         "param_type": "float",
         "parameter_name": "tol",
         "parameter_name_type": "tol_float",
         "task_name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)"
        },
        {
         "Model ID": "692fd37102faa1b369c44af7",
         "Model Name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)",
         "Project Type": "regression",
         "current_value": 1.5,
         "default_value": 1.5,
         "index": 9,
         "max": 2,
         "min": 1,
         "param_type": "float",
         "parameter_name": "tweedie_p",
         "parameter_name_type": "tweedie_p_float",
         "task_name": "Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)"
        }
       ],
       "error": [],
       "indexKey": "index",
       "limit": 10,
       "offset": 0,
       "referenceId": 140548129655184,
       "sortedBy": "",
       "totalCount": 42
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>parameter_name_type</th>\n",
       "      <th>current_value</th>\n",
       "      <th>default_value</th>\n",
       "      <th>param_type</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>Model ID</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Project Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>enet_alpha</td>\n",
       "      <td>enet_alpha_select</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692fd37102faa1b369c44af7</td>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>enet_lambda</td>\n",
       "      <td>enet_lambda_select</td>\n",
       "      <td>0.003474</td>\n",
       "      <td>0.003474</td>\n",
       "      <td>select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692fd37102faa1b369c44af7</td>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>fit_alpha_scaler</td>\n",
       "      <td>fit_alpha_scaler_select</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692fd37102faa1b369c44af7</td>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>fit_intercept</td>\n",
       "      <td>fit_intercept_select</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692fd37102faa1b369c44af7</td>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>fit_tweedie_p</td>\n",
       "      <td>fit_tweedie_p_select</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692fd37102faa1b369c44af7</td>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>loss</td>\n",
       "      <td>loss_select</td>\n",
       "      <td>squared</td>\n",
       "      <td>squared</td>\n",
       "      <td>select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692fd37102faa1b369c44af7</td>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>max_iter</td>\n",
       "      <td>max_iter_int</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>int</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>692fd37102faa1b369c44af7</td>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>random_state</td>\n",
       "      <td>random_state_int</td>\n",
       "      <td>1234</td>\n",
       "      <td>1234</td>\n",
       "      <td>int</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>692fd37102faa1b369c44af7</td>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>tol</td>\n",
       "      <td>tol_float</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>float</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>692fd37102faa1b369c44af7</td>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>tweedie_p</td>\n",
       "      <td>tweedie_p_float</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>float</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>692fd37102faa1b369c44af7</td>\n",
       "      <td>Elastic-Net Regressor (mixing alpha=0.5 / Leas...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>boost_from_average</td>\n",
       "      <td>boost_from_average_select</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>subsample_for_bin</td>\n",
       "      <td>subsample_for_bin_int</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>int</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>subsample</td>\n",
       "      <td>subsample_float</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>float</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>reg_lambda</td>\n",
       "      <td>reg_lambda_float</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>float</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>reg_alpha</td>\n",
       "      <td>reg_alpha_float</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>float</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>objective</td>\n",
       "      <td>objective_select</td>\n",
       "      <td>regression_l2</td>\n",
       "      <td>regression_l2</td>\n",
       "      <td>select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>num_leaves_int</td>\n",
       "      <td>[2, 4, 16]</td>\n",
       "      <td>2</td>\n",
       "      <td>int</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>n_estimators</td>\n",
       "      <td>n_estimators_int</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>int</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>min_split_gain</td>\n",
       "      <td>min_split_gain_float</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>float</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>min_child_weight</td>\n",
       "      <td>min_child_weight_int</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>int</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>min_child_samples</td>\n",
       "      <td>min_child_samples_int</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>int</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>subsample_freq</td>\n",
       "      <td>subsample_freq_select</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>tweedie_p</td>\n",
       "      <td>tweedie_p_float</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>float</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>max_depth</td>\n",
       "      <td>max_depth_select</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>max_delta_step</td>\n",
       "      <td>max_delta_step_float</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>float</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>max_bin</td>\n",
       "      <td>max_bin_int</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>int</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>link_transform</td>\n",
       "      <td>link_transform_select</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>learning_rate</td>\n",
       "      <td>learning_rate_float</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>float</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>huber_delta</td>\n",
       "      <td>huber_delta_float</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>float</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>fair_c</td>\n",
       "      <td>fair_c_float</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>float</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>early_stopping_rounds</td>\n",
       "      <td>early_stopping_rounds_int</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>int</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>colsample_bytree</td>\n",
       "      <td>colsample_bytree_float</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>float</td>\n",
       "      <td>2.000000e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>enet_alpha</td>\n",
       "      <td>enet_alpha_select</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692fd37102faa1b369c44af6</td>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>enet_lambda</td>\n",
       "      <td>enet_lambda_select</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692fd37102faa1b369c44af6</td>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>fit_alpha_scaler</td>\n",
       "      <td>fit_alpha_scaler_select</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692fd37102faa1b369c44af6</td>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>fit_intercept</td>\n",
       "      <td>fit_intercept_select</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692fd37102faa1b369c44af6</td>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>fit_tweedie_p</td>\n",
       "      <td>fit_tweedie_p_select</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692fd37102faa1b369c44af6</td>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>loss</td>\n",
       "      <td>loss_select</td>\n",
       "      <td>squared</td>\n",
       "      <td>squared</td>\n",
       "      <td>select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692fd37102faa1b369c44af6</td>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>max_iter</td>\n",
       "      <td>max_iter_int</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>int</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>692fd37102faa1b369c44af6</td>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>random_state</td>\n",
       "      <td>random_state_int</td>\n",
       "      <td>1234</td>\n",
       "      <td>1234</td>\n",
       "      <td>int</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>692fd37102faa1b369c44af6</td>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>tol</td>\n",
       "      <td>tol_float</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>float</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>692fd37102faa1b369c44af6</td>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>tweedie_p</td>\n",
       "      <td>tweedie_p_float</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>float</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>692fd37102faa1b369c44af6</td>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            task_name         parameter_name  \\\n",
       "0   Elastic-Net Regressor (mixing alpha=0.5 / Leas...             enet_alpha   \n",
       "1   Elastic-Net Regressor (mixing alpha=0.5 / Leas...            enet_lambda   \n",
       "2   Elastic-Net Regressor (mixing alpha=0.5 / Leas...       fit_alpha_scaler   \n",
       "3   Elastic-Net Regressor (mixing alpha=0.5 / Leas...          fit_intercept   \n",
       "4   Elastic-Net Regressor (mixing alpha=0.5 / Leas...          fit_tweedie_p   \n",
       "5   Elastic-Net Regressor (mixing alpha=0.5 / Leas...                   loss   \n",
       "6   Elastic-Net Regressor (mixing alpha=0.5 / Leas...               max_iter   \n",
       "7   Elastic-Net Regressor (mixing alpha=0.5 / Leas...           random_state   \n",
       "8   Elastic-Net Regressor (mixing alpha=0.5 / Leas...                    tol   \n",
       "9   Elastic-Net Regressor (mixing alpha=0.5 / Leas...              tweedie_p   \n",
       "16  Light Gradient Boosting on ElasticNet Predicti...     boost_from_average   \n",
       "17  Light Gradient Boosting on ElasticNet Predicti...      subsample_for_bin   \n",
       "18  Light Gradient Boosting on ElasticNet Predicti...              subsample   \n",
       "19  Light Gradient Boosting on ElasticNet Predicti...             reg_lambda   \n",
       "20  Light Gradient Boosting on ElasticNet Predicti...              reg_alpha   \n",
       "21  Light Gradient Boosting on ElasticNet Predicti...              objective   \n",
       "22  Light Gradient Boosting on ElasticNet Predicti...             num_leaves   \n",
       "23  Light Gradient Boosting on ElasticNet Predicti...           n_estimators   \n",
       "24  Light Gradient Boosting on ElasticNet Predicti...         min_split_gain   \n",
       "25  Light Gradient Boosting on ElasticNet Predicti...       min_child_weight   \n",
       "26  Light Gradient Boosting on ElasticNet Predicti...      min_child_samples   \n",
       "27  Light Gradient Boosting on ElasticNet Predicti...         subsample_freq   \n",
       "28  Light Gradient Boosting on ElasticNet Predicti...              tweedie_p   \n",
       "29  Light Gradient Boosting on ElasticNet Predicti...              max_depth   \n",
       "30  Light Gradient Boosting on ElasticNet Predicti...         max_delta_step   \n",
       "31  Light Gradient Boosting on ElasticNet Predicti...                max_bin   \n",
       "32  Light Gradient Boosting on ElasticNet Predicti...         link_transform   \n",
       "33  Light Gradient Boosting on ElasticNet Predicti...          learning_rate   \n",
       "34  Light Gradient Boosting on ElasticNet Predicti...            huber_delta   \n",
       "35  Light Gradient Boosting on ElasticNet Predicti...                 fair_c   \n",
       "36  Light Gradient Boosting on ElasticNet Predicti...  early_stopping_rounds   \n",
       "37  Light Gradient Boosting on ElasticNet Predicti...       colsample_bytree   \n",
       "44                                    Ridge Regressor             enet_alpha   \n",
       "45                                    Ridge Regressor            enet_lambda   \n",
       "46                                    Ridge Regressor       fit_alpha_scaler   \n",
       "47                                    Ridge Regressor          fit_intercept   \n",
       "48                                    Ridge Regressor          fit_tweedie_p   \n",
       "49                                    Ridge Regressor                   loss   \n",
       "50                                    Ridge Regressor               max_iter   \n",
       "51                                    Ridge Regressor           random_state   \n",
       "52                                    Ridge Regressor                    tol   \n",
       "53                                    Ridge Regressor              tweedie_p   \n",
       "\n",
       "          parameter_name_type  current_value  default_value param_type  \\\n",
       "0           enet_alpha_select            0.5            0.5     select   \n",
       "1          enet_lambda_select       0.003474       0.003474     select   \n",
       "2     fit_alpha_scaler_select           True           True     select   \n",
       "3        fit_intercept_select           True           True     select   \n",
       "4        fit_tweedie_p_select          False          False     select   \n",
       "5                 loss_select        squared        squared     select   \n",
       "6                max_iter_int            100            100        int   \n",
       "7            random_state_int           1234           1234        int   \n",
       "8                   tol_float         0.0001         0.0001      float   \n",
       "9             tweedie_p_float            1.5            1.5      float   \n",
       "16  boost_from_average_select           True           True     select   \n",
       "17      subsample_for_bin_int          50000          50000        int   \n",
       "18            subsample_float              1              1      float   \n",
       "19           reg_lambda_float              0              0      float   \n",
       "20            reg_alpha_float              0              0      float   \n",
       "21           objective_select  regression_l2  regression_l2     select   \n",
       "22             num_leaves_int     [2, 4, 16]              2        int   \n",
       "23           n_estimators_int           1000           1000        int   \n",
       "24       min_split_gain_float              0              0      float   \n",
       "25       min_child_weight_int              5              5        int   \n",
       "26      min_child_samples_int             10             10        int   \n",
       "27      subsample_freq_select              1              1     select   \n",
       "28            tweedie_p_float            1.5            1.5      float   \n",
       "29           max_depth_select           none           none     select   \n",
       "30       max_delta_step_float            0.7            0.7      float   \n",
       "31                max_bin_int            255            255        int   \n",
       "32      link_transform_select          False          False     select   \n",
       "33        learning_rate_float           0.05           0.05      float   \n",
       "34          huber_delta_float              1              1      float   \n",
       "35               fair_c_float              1              1      float   \n",
       "36  early_stopping_rounds_int            200            200        int   \n",
       "37     colsample_bytree_float            0.3            0.3      float   \n",
       "44          enet_alpha_select              0              0     select   \n",
       "45         enet_lambda_select       0.004605       0.004605     select   \n",
       "46    fit_alpha_scaler_select           True           True     select   \n",
       "47       fit_intercept_select           True           True     select   \n",
       "48       fit_tweedie_p_select          False          False     select   \n",
       "49                loss_select        squared        squared     select   \n",
       "50               max_iter_int            100            100        int   \n",
       "51           random_state_int           1234           1234        int   \n",
       "52                  tol_float         0.0001         0.0001      float   \n",
       "53            tweedie_p_float            1.5            1.5      float   \n",
       "\n",
       "             min           max                  Model ID  \\\n",
       "0            NaN           NaN  692fd37102faa1b369c44af7   \n",
       "1            NaN           NaN  692fd37102faa1b369c44af7   \n",
       "2            NaN           NaN  692fd37102faa1b369c44af7   \n",
       "3            NaN           NaN  692fd37102faa1b369c44af7   \n",
       "4            NaN           NaN  692fd37102faa1b369c44af7   \n",
       "5            NaN           NaN  692fd37102faa1b369c44af7   \n",
       "6   1.000000e+00  1.000000e+06  692fd37102faa1b369c44af7   \n",
       "7   0.000000e+00  1.000000e+09  692fd37102faa1b369c44af7   \n",
       "8   1.000000e-10  1.000000e+10  692fd37102faa1b369c44af7   \n",
       "9   1.000000e+00  2.000000e+00  692fd37102faa1b369c44af7   \n",
       "16           NaN           NaN  692fd37102faa1b369c44afa   \n",
       "17  1.000000e+00  1.000000e+06  692fd37102faa1b369c44afa   \n",
       "18  1.000000e-02  1.000000e+00  692fd37102faa1b369c44afa   \n",
       "19  0.000000e+00  1.000000e+06  692fd37102faa1b369c44afa   \n",
       "20  0.000000e+00  1.000000e+06  692fd37102faa1b369c44afa   \n",
       "21           NaN           NaN  692fd37102faa1b369c44afa   \n",
       "22  2.000000e+00  1.000000e+04  692fd37102faa1b369c44afa   \n",
       "23  1.000000e+00  2.500000e+05  692fd37102faa1b369c44afa   \n",
       "24  0.000000e+00  1.000000e+02  692fd37102faa1b369c44afa   \n",
       "25  0.000000e+00  1.000000e+02  692fd37102faa1b369c44afa   \n",
       "26  0.000000e+00  1.000000e+03  692fd37102faa1b369c44afa   \n",
       "27           NaN           NaN  692fd37102faa1b369c44afa   \n",
       "28  1.000000e+00  2.000000e+00  692fd37102faa1b369c44afa   \n",
       "29           NaN           NaN  692fd37102faa1b369c44afa   \n",
       "30  0.000000e+00  1.000000e+03  692fd37102faa1b369c44afa   \n",
       "31  3.000000e+00  1.000000e+04  692fd37102faa1b369c44afa   \n",
       "32           NaN           NaN  692fd37102faa1b369c44afa   \n",
       "33  1.000000e-07  1.000000e+02  692fd37102faa1b369c44afa   \n",
       "34  0.000000e+00  1.000000e+03  692fd37102faa1b369c44afa   \n",
       "35  0.000000e+00  1.000000e+03  692fd37102faa1b369c44afa   \n",
       "36  0.000000e+00  1.000000e+03  692fd37102faa1b369c44afa   \n",
       "37  2.000000e-02  1.000000e+00  692fd37102faa1b369c44afa   \n",
       "44           NaN           NaN  692fd37102faa1b369c44af6   \n",
       "45           NaN           NaN  692fd37102faa1b369c44af6   \n",
       "46           NaN           NaN  692fd37102faa1b369c44af6   \n",
       "47           NaN           NaN  692fd37102faa1b369c44af6   \n",
       "48           NaN           NaN  692fd37102faa1b369c44af6   \n",
       "49           NaN           NaN  692fd37102faa1b369c44af6   \n",
       "50  1.000000e+00  1.000000e+06  692fd37102faa1b369c44af6   \n",
       "51  0.000000e+00  1.000000e+09  692fd37102faa1b369c44af6   \n",
       "52  1.000000e-10  1.000000e+10  692fd37102faa1b369c44af6   \n",
       "53  1.000000e+00  2.000000e+00  692fd37102faa1b369c44af6   \n",
       "\n",
       "                                           Model Name Project Type  \n",
       "0   Elastic-Net Regressor (mixing alpha=0.5 / Leas...   regression  \n",
       "1   Elastic-Net Regressor (mixing alpha=0.5 / Leas...   regression  \n",
       "2   Elastic-Net Regressor (mixing alpha=0.5 / Leas...   regression  \n",
       "3   Elastic-Net Regressor (mixing alpha=0.5 / Leas...   regression  \n",
       "4   Elastic-Net Regressor (mixing alpha=0.5 / Leas...   regression  \n",
       "5   Elastic-Net Regressor (mixing alpha=0.5 / Leas...   regression  \n",
       "6   Elastic-Net Regressor (mixing alpha=0.5 / Leas...   regression  \n",
       "7   Elastic-Net Regressor (mixing alpha=0.5 / Leas...   regression  \n",
       "8   Elastic-Net Regressor (mixing alpha=0.5 / Leas...   regression  \n",
       "9   Elastic-Net Regressor (mixing alpha=0.5 / Leas...   regression  \n",
       "16  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "17  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "18  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "19  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "20  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "21  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "22  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "23  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "24  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "25  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "26  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "27  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "28  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "29  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "30  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "31  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "32  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "33  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "34  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "35  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "36  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "37  Light Gradient Boosting on ElasticNet Predicti...   regression  \n",
       "44                                    Ridge Regressor   regression  \n",
       "45                                    Ridge Regressor   regression  \n",
       "46                                    Ridge Regressor   regression  \n",
       "47                                    Ridge Regressor   regression  \n",
       "48                                    Ridge Regressor   regression  \n",
       "49                                    Ridge Regressor   regression  \n",
       "50                                    Ridge Regressor   regression  \n",
       "51                                    Ridge Regressor   regression  \n",
       "52                                    Ridge Regressor   regression  \n",
       "53                                    Ridge Regressor   regression  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" FETCHING TUNABLE PARAMETERS FOR TOP MODELS\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "all_param_data = []\n",
    "\n",
    "# Detect once (for logging / awareness)\n",
    "project_type = detect_project_type(proj)\n",
    "print(f\"Detected project type: {project_type}\")\n",
    "\n",
    "for _, row in df_models.iterrows():\n",
    "    model_id = row[\"Model ID\"]\n",
    "    model_name = row[\"Model Name\"]\n",
    "\n",
    "    print(f\"\\n>>>>>>>>>>>>>>>> Fetching tunable parameters for {model_name} ({model_id})...\")\n",
    "    try:\n",
    "        model = dr.Model.get(proj.id, model_id)\n",
    "        params_df = get_current_hyperparams(model)\n",
    "\n",
    "        if not params_df.empty:\n",
    "            # ---------------Add model metadata\n",
    "            params_df[\"Model ID\"] = model_id\n",
    "            params_df[\"Model Name\"] = model_name\n",
    "            params_df[\"Project Type\"] = project_type\n",
    "            all_param_data.append(params_df)\n",
    "        else:\n",
    "            print(f\" !!!!!!!!!!!111 No tunable parameters found for {model_name} ({model_id}).\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" !!!!!!!!!!!!!!!! Skipping model {model_id} ({model_name}): {e}\")\n",
    "        continue\n",
    "\n",
    "# ----------Combining all parameter data into one dataframe\n",
    "\n",
    "if all_param_data:\n",
    "    df_all_params = pd.concat(all_param_data, ignore_index=True)\n",
    "else:\n",
    "    df_all_params = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"Model ID\",\n",
    "            \"Model Name\",\n",
    "            \"Project Type\",\n",
    "            \"task_name\",\n",
    "            \"parameter_name\",\n",
    "            \"parameter_name_type\",\n",
    "            \"current_value\",\n",
    "            \"default_value\",\n",
    "            \"param_type\",\n",
    "            \"min\",\n",
    "            \"max\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"\\n Final dataframe created with {df_all_params.shape[0]} rows and {df_all_params.shape[1]} columns.\"\n",
    ")\n",
    "\n",
    "# ---------- Helper lowercase columns for filtering\n",
    "df_all_params[\"task_name_lower\"] = df_all_params[\"task_name\"].str.lower()\n",
    "df_all_params[\"model_name_lower\"] = df_all_params[\"Model Name\"].str.lower()\n",
    "\n",
    "# ----------Apply contains-based filter (same logic)\n",
    "filtered_df = df_all_params[\n",
    "    df_all_params.apply(lambda x: x[\"model_name_lower\"] in x[\"task_name_lower\"], axis=1)\n",
    "].copy()\n",
    "\n",
    "# ----------Drop helper columns\n",
    "filtered_df.drop(columns=[\"task_name_lower\", \"model_name_lower\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "print(\n",
    "    f\" Filtered dataframe created with {filtered_df.shape[0]} rows (matching task_name â†” model_name).\"\n",
    ")\n",
    "print(filtered_df.shape)\n",
    "display(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "537a021d-9827-42cd-9d84-8709182957bd",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 2,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## optional\n",
    "\n",
    "## Saving the\n",
    "filtered_df.to_csv(\n",
    "    \"/home/notebooks/storage/Regression_search_space/Regression_search_space_2.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcdcdea-b450-452d-b7dc-72b6b65f9093",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "## Custom search space definitions for model tuning\n",
    "\n",
    "This section defines the hyperparameter search spaces for various classification and regression models supported in DataRobot. These search spaces are used by the HyperOpt tuner to explore optimal hyperparameter combinations during model optimization.\n",
    "\n",
    "### What is `SEARCH_SPACES`?\n",
    "\n",
    "- `SEARCH_SPACES` is a dictionary where:\n",
    "  - **Keys** = Exact model names as they appear in DataRobot (e.g., `\"RandomForest Classifier (Gini)\"`)\n",
    "  - **Values** = Hyperparameter search definitions using `hyperopt` functions like:\n",
    "    - `hp.uniform()` for continuous ranges\n",
    "    - `hp.quniform()` for discrete ranges\n",
    "    - `hp.choice()` for categorical options\n",
    "    - `hp.loguniform()` for log-scaled values\n",
    "\n",
    "### Saving the filtered search space\n",
    "\n",
    "After extracting tunable parameters from the top models, the filtered DataFrame (`filtered_df`) is saved to disk for reference or reuse. Go through the file `filtered_df` and understand the hyperparameters and update the search space with model name and its hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e92fc996-372a-4b93-9292-9b283085cf88",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 9,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# start modifying the search space overe here:\n",
    "\n",
    "SEARCH_SPACES = {\n",
    "    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Random Forest:\n",
    "    \"RandomForest Classifier (Gini)\": {\n",
    "        \"n_estimators\": hp.quniform(\"n_estimators\", 100, 800, 50),\n",
    "        \"min_samples_split\": hp.quniform(\"min_samples_split\", 2, 20, 1),\n",
    "        \"min_samples_leaf\": hp.quniform(\"min_samples_leaf\", 1, 15, 1),\n",
    "    },\n",
    "    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> eXtreme Gradient Boosted Trees:\n",
    "    \"eXtreme Gradient Boosted Trees Classifier with Early Stopping\": {\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.3),\n",
    "        \"min_child_weight\": hp.quniform(\"min_child_weight\", 1, 6, 1),\n",
    "        \"subsample\": hp.uniform(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"n_estimators\": hp.quniform(\"n_estimators\", 100, 800, 50),\n",
    "    },\n",
    "    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> RuleFit Classifier:\n",
    "    \"RuleFit Classifier\": {\n",
    "        \"max_depth\": hp.quniform(\"max_depth\", 2, 10, 1),\n",
    "        \"n_estimators\": hp.quniform(\"n_estimators\", 100, 800, 50),\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.3),\n",
    "        \"min_samples_leaf\": hp.quniform(\"min_samples_leaf\", 1, 5, 1),\n",
    "    },\n",
    "    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Generalized Additive2 Model:\n",
    "    \"Generalized Additive2 Model\": {\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": hp.quniform(\"max_depth\", 2, 10, 1),\n",
    "        \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"n_estimators\": hp.quniform(\"n_estimators\", 100, 800, 50),\n",
    "        \"min_child_weight\": hp.quniform(\"min_child_weight\", 1, 6, 1),\n",
    "    },\n",
    "    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Light Gradient Boosted Trees:\n",
    "    \"Light Gradient Boosted Trees Classifier with Early Stopping\": {\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": hp.quniform(\"num_leaves\", 20, 120, 10),\n",
    "        \"max_depth\": hp.quniform(\"max_depth\", 3, 10, 1),\n",
    "        \"min_child_samples\": hp.quniform(\"min_child_samples\", 5, 50, 5),\n",
    "        \"min_child_weight\": hp.quniform(\"min_child_weight\", 1, 6, 1),\n",
    "        \"n_estimators\": hp.quniform(\"n_estimators\", 100, 800, 50),\n",
    "    },\n",
    "    ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Elastic Net:\n",
    "    # \"ElasticNet\": {\n",
    "    #   \"enet_alpha\": hp.loguniform(\"enet_alpha\", -9.2, 0.0),\n",
    "    #  \"enet_lambda\": hp.uniform(\"enet_lambda\", 0.0, 1.0)\n",
    "    # },\n",
    "    ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  RandomForest Classifier (Entropy):\n",
    "    \"RandomForest Classifier (Entropy)\": {\n",
    "        \"n_estimators\": hp.quniform(\"n_estimators\", 100, 800, 50),\n",
    "        \"min_samples_split\": hp.quniform(\"min_samples_split\", 2, 20, 1),\n",
    "        \"min_samples_leaf\": hp.quniform(\"min_samples_leaf\", 1, 15, 1),\n",
    "    },\n",
    "    ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   Keras:\n",
    "    \"Keras\": {\n",
    "        \"learning_rate\": hp.loguniform(\"learning_rate\", -9.2, -2.3),\n",
    "        \"batch_size\": hp.choice(\"batch_size\", [16, 32, 64, 128]),\n",
    "        \"activation\": hp.choice(\"activation\", [\"relu\", \"elu\", \"selu\"]),\n",
    "    },\n",
    "    ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>> GAM:\n",
    "    \"GAM\": {\n",
    "        \"learning_rate\": hp.loguniform(\"learning_rate\", -6.9, -2.3),  # LOG-SCALE: 0.001 to 0.1\n",
    "        \"max_bins\": hp.quniform(\"max_bins\", 128, 512, 64),\n",
    "    },\n",
    "    ## >>>>>>>>>>>>>>>>>>>>>> Keras Slim Residual:\n",
    "    \"Keras Slim Residual\": {\n",
    "        \"learning_rate\": hp.loguniform(\"learning_rate\", -9.2, -2.3),  # LOG-SCALE: 0.0001 to 0.1\n",
    "        \"batch_size\": hp.choice(\"batch_size\", [16, 32, 64, 128]),\n",
    "        \"epoch\": hp.quniform(\"num_residual_blocks\", 2, 100, 1),\n",
    "    },\n",
    "    ##  ##########################################   Regression Model :\n",
    "    ## Elastic-Net Regressor :\n",
    "    \"Elastic-Net Regressor\": {\n",
    "        \"enet_alpha\": hp.loguniform(\"enet_alpha\", -9.2, 0.0),\n",
    "        \"enet_lambda\": hp.uniform(\"enet_lambda\", 0.0, 1.0),\n",
    "    },\n",
    "    \"Light Gradient Boosting on ElasticNet Predictions\": {\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": hp.quniform(\"num_leaves\", 20, 120, 10),\n",
    "        \"max_depth\": hp.quniform(\"max_depth\", 3, 10, 1),\n",
    "        \"n_estimators\": hp.quniform(\"n_estimators\", 100, 800, 50),\n",
    "    },\n",
    "    \"eXtreme Gradient Boosted Trees Regressor\": {\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.3),\n",
    "        \"min_child_weight\": hp.quniform(\"min_child_weight\", 1, 6, 1),\n",
    "        \"subsample\": hp.uniform(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"n_estimators\": hp.quniform(\"n_estimators\", 100, 800, 50),\n",
    "    },\n",
    "    \"Ridge Regressor\": {\"tweedie_p\": hp.quniform(\"tweedie_p\", 1.0, 2.0, 0.1)},\n",
    "    \"RuleFit Regressor\": {\n",
    "        \"max_depth\": hp.quniform(\"max_depth\", 2, 10, 1),\n",
    "        \"n_estimators\": hp.quniform(\"n_estimators\", 100, 800, 50),\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.3),\n",
    "        \"min_samples_leaf\": hp.quniform(\"min_samples_leaf\", 1, 5, 1),\n",
    "    },\n",
    "    \"Light Gradient Boosted Trees Regressor with Early Stopping\": {\n",
    "        \"num_leaves\": hp.quniform(\"num_leaves\", 2, 1000, 50),\n",
    "        \"n_estimators\": hp.quniform(\"n_estimators\", 100, 800, 50),\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.3),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688a558f-a94c-4a79-8a4f-d5d5700f478f",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "# Print top N models to be tuned, and their available search spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896e442b-121b-4eba-a3ac-6971ee8b313a",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 3,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Allowed Search Spaces for Top X Models\n",
      "================================================================================\n",
      "\n",
      "\n",
      "---------------------------------------\n",
      " Model: Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)\n",
      " Search space found for model: Elastic-Net Regressor\n",
      " Search Space Keys: ['enet_alpha', 'enet_lambda']\n",
      "\n",
      "---------------------------------------\n",
      " Model: Light Gradient Boosting on ElasticNet Predictions \n",
      " Search space found for model: Light Gradient Boosting on ElasticNet Predictions\n",
      " Search Space Keys: ['learning_rate', 'num_leaves', 'max_depth', 'n_estimators']\n",
      "\n",
      "---------------------------------------\n",
      " Model: Ridge Regressor\n",
      " Search space found for model: Ridge Regressor\n",
      " Search Space Keys: ['tweedie_p']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Allowed search spaces for top X models\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "for _, row in df_models.iterrows():\n",
    "    model_name = row[\"Model Name\"]\n",
    "    print(\"\\n---------------------------------------\")\n",
    "    print(f\" Model: {model_name}\")\n",
    "    space = get_search_space(model_name)\n",
    "    print(f\" Search Space Keys: {list(space.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ecca4f-d857-4ebd-bbe8-6521797bf51f",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "# Get training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a940119d-eab0-44d8-85d8-81ac2759b788",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "## `get_training_data()`\n",
    "\n",
    "This function retrieves the training dataset for a given DataRobot project, supporting both UI-created and API-created projects across classification and regression types.\n",
    "\n",
    "---\n",
    "\n",
    "###  Function purpose\n",
    "\n",
    "- Attempts to load the training dataset directly from the DataRobot backend.\n",
    "- If the dataset cannot be fetched (e.g., for API-created projects), it falls back to a local CSV file.\n",
    "- Ensures the target column exists in the dataset and logs helpful messages throughout.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "###  Example Use Case\n",
    "\n",
    "This function is especially useful when:\n",
    "- Projects are created via the API and donâ€™t have a linked dataset.\n",
    "- You want to ensure robustness in notebooks that may run across different environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a4b4cdbc-8e13-44f1-83ef-f3ed46747dfb",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 4,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_training_data(proj, fallback_path=None):\n",
    "    \"\"\"\n",
    "    Safely fetch project training data as a pandas DataFrame.\n",
    "    Works for both UI-created and API-created projects.\n",
    "    Supports both regression and classification.\n",
    "    \"\"\"\n",
    "\n",
    "    df = None\n",
    "    project_type = detect_project_type(proj)\n",
    "    target_name = proj.target\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\" FETCHING TRAINING DATA  (Project Type: {project_type})\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    # ----------------- Try pulling directly from DataRobot -----------------\n",
    "    try:\n",
    "        dataset_func = getattr(proj, \"get_dataset\", None)\n",
    "        if callable(dataset_func):\n",
    "            dataset_obj = dataset_func()\n",
    "            if dataset_obj is not None:\n",
    "                df = dataset_obj.get_as_dataframe()\n",
    "                print(f\">> Loaded dataset from DataRobot backend. Shape: {df.shape}\")\n",
    "\n",
    "                if target_name in df.columns:\n",
    "                    print(f\">>>> Target column '{target_name}' found in dataset.\")\n",
    "                else:\n",
    "                    print(f\">>>>>> Target column '{target_name}' not found in dataset!\")\n",
    "\n",
    "                return df\n",
    "    except Exception as e:\n",
    "        print(f\">>>>>>>>> Could not fetch dataset from DataRobot backend: {e}\")\n",
    "\n",
    "    # ----------------- Fallback to local CSV -----------------\n",
    "    if fallback_path:\n",
    "        if os.path.exists(fallback_path):\n",
    "            try:\n",
    "                df = pd.read_csv(fallback_path)\n",
    "                print(\n",
    "                    f\">>>>>>> Loaded fallback dataset from local file: {fallback_path} | Shape: {df.shape}\"\n",
    "                )\n",
    "\n",
    "                if target_name in df.columns:\n",
    "                    print(f\">>>>>>>>>>> Target column '{target_name}' found in fallback dataset.\")\n",
    "                else:\n",
    "                    print(\n",
    "                        f\">>>>>>>>>>>>>>>>>>>>>>>>> Target column '{target_name}' not found in fallback dataset!\"\n",
    "                    )\n",
    "\n",
    "                return df\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"âŒ Failed to load fallback CSV ({fallback_path}): {e}\")\n",
    "        else:\n",
    "            print(f\"!!!!!!!!!!!!!!!!! Fallback path not found: {fallback_path}\")\n",
    "\n",
    "    # ----------------- If all fails -----------------\n",
    "    raise RuntimeError(\n",
    "        \"âŒ Could not load dataset from DataRobot or fallback path.\\n\"\n",
    "        \"If project was created via API (Project.create), provide fallback_path to local CSV.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0bb959-ef79-4ac1-b4d6-77f2d298a53b",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db39681-88c7-4159-9e99-8f8e8e2a0536",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "## Model optimization loop\n",
    "\n",
    "This section performs the core optimization process by tuning each selected model using the defined custom metric and search space.\n",
    "\n",
    "### Step-by-step breakdown\n",
    "\n",
    "#### 1. Project type validation\n",
    "- Detects the project type using `detect_project_type(proj)`.\n",
    "- Ensures the project is either:\n",
    "  - `\"binary\"` for binary classification\n",
    "  - `\"regression\"` for regression\n",
    "\n",
    "#### 2. Model tuning loop\n",
    "For each model in the `df_models` DataFrame:\n",
    "- Logs the model name and ID.\n",
    "- Retrieves the appropriate hyperparameter `search_space` using `get_search_space(model_name)`.\n",
    "- Records the start time for runtime tracking.\n",
    "- Calls `tune_and_compare_model()` to:\n",
    "  - Run HyperOpt tuning using the custom metric\n",
    "  - Evaluate performance improvements\n",
    "  - Return a DataFrame of tuning results\n",
    "\n",
    "#### 3. Combine and summarize results\n",
    "- After all models are processed:\n",
    "  - Calculates total runtime for the entire optimization loop.\n",
    "  - Logs the total time taken.\n",
    "  - The `all_results` list now contains performance comparisons for each tuned model.\n",
    "\n",
    "### Why this matters\n",
    "\n",
    "This loop automates the process of:\n",
    "- Selecting models\n",
    "- Applying custom metric-driven tuning\n",
    "- Tracking performance improvements\n",
    "- Collecting results for final analysis\n",
    "\n",
    "It ensures consistent, scalable, and efficient optimization across multiple models in a DataRobot project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "91cd1853-fd54-473c-9f43-8f4a5e4274ab",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 556351,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " STARTING OPTIMIZATION LOOP\n",
      "================================================================================\n",
      "\n",
      "Detected project type: regression\n",
      " >>>>>>>>>>> Optimization will use custom metric: clv_asymmetry_loss\n",
      "================================================================================\n",
      "\n",
      "========================================================================================================================\n",
      " [1/3] Tuning model: Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss) | ID: 692fd37102faa1b369c44af7\n",
      "========================================================================================================================\n",
      " Search space found for model: Elastic-Net Regressor\n",
      "\n",
      "================================================================================\n",
      " FETCHING TRAINING DATA  (Project Type: regression)\n",
      "================================================================================\n",
      ">> Loaded dataset from DataRobot backend. Shape: (850, 96)\n",
      ">>>> Target column 'CLV_2' found in dataset.\n",
      "1. Training data shape: (850, 96)\n",
      "2. Target variable: CLV_2\n",
      "3. Project Type: regression\n",
      "================================================================================\n",
      "XX Starting tuning for: Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss) | ID: 692fd37102faa1b369c44af7\n",
      "XXX Custom Metric: clv_asymmetry_loss\n",
      "XXXX  Metric Function: clv_asymmetry_loss\n",
      "XXXXX  Direction: min\n",
      "================================================================================\n",
      "X Base clv_asymmetry_loss: 187.571906\n",
      "*********** Trying params: {'enet_alpha': 0.21140153624993946, 'enet_lambda': 0.09839430298593588}\n",
      "XXXXXXXXXXXXXX Tuned clv_asymmetry_loss: 280.625171 | Î” = -93.053265\n",
      "*********** Trying params: {'enet_alpha': 0.12025019720618965, 'enet_lambda': 0.4711005517785799}\n",
      "XXXXXXXXXXXXXX Tuned clv_asymmetry_loss: 459.572638 | Î” = -272.000732         \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [02:36<00:00, 78.04s/trial, best loss: 280.6251709822832]\n",
      "\n",
      "xxxxxxxxxxxxxxx Best Params: {'enet_alpha': 0.21140153624993946, 'enet_lambda': 0.09839430298593588}\n",
      "\n",
      "XXXXXXXXXXXXX Final Comparison Created | Shape: (3, 9)\n",
      "xxxxxxxxxxxxxxx Best clv_asymmetry_loss: 187.571906\n",
      "================================================================================\n",
      "âœ” Completed tuning for Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss) in 3.04 minutes\n",
      "\n",
      "========================================================================================================================\n",
      " [2/3] Tuning model: Light Gradient Boosting on ElasticNet Predictions  | ID: 692fd37102faa1b369c44afa\n",
      "========================================================================================================================\n",
      " Search space found for model: Light Gradient Boosting on ElasticNet Predictions\n",
      "\n",
      "================================================================================\n",
      " FETCHING TRAINING DATA  (Project Type: regression)\n",
      "================================================================================\n",
      ">> Loaded dataset from DataRobot backend. Shape: (850, 96)\n",
      ">>>> Target column 'CLV_2' found in dataset.\n",
      "1. Training data shape: (850, 96)\n",
      "2. Target variable: CLV_2\n",
      "3. Project Type: regression\n",
      "================================================================================\n",
      "XX Starting tuning for: Light Gradient Boosting on ElasticNet Predictions  | ID: 692fd37102faa1b369c44afa\n",
      "XXX Custom Metric: clv_asymmetry_loss\n",
      "XXXX  Metric Function: clv_asymmetry_loss\n",
      "XXXXX  Direction: min\n",
      "================================================================================\n",
      "X Base clv_asymmetry_loss: 168.560443\n",
      "*********** Trying params: {'learning_rate': 0.03295739827261283, 'max_depth': 6.0, 'n_estimators': 250.0, 'num_leaves': 80.0}\n",
      "XXXXXXXXXXXXXX Tuned clv_asymmetry_loss: 169.924455 | Î” = -1.364012\n",
      "*********** Trying params: {'learning_rate': 0.04976241015493183, 'max_depth': 7.0, 'n_estimators': 650.0, 'num_leaves': 30.0}\n",
      "XXXXXXXXXXXXXX Tuned clv_asymmetry_loss: 169.809753 | Î” = -1.249310            \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [02:41<00:00, 80.62s/trial, best loss: 169.80975297608012]\n",
      "\n",
      "xxxxxxxxxxxxxxx Best Params: {'learning_rate': 0.04976241015493183, 'max_depth': 7.0, 'n_estimators': 650.0, 'num_leaves': 30.0}\n",
      "\n",
      "XXXXXXXXXXXXX Final Comparison Created | Shape: (3, 11)\n",
      "xxxxxxxxxxxxxxx Best clv_asymmetry_loss: 168.560443\n",
      "================================================================================\n",
      "âœ” Completed tuning for Light Gradient Boosting on ElasticNet Predictions  in 3.1 minutes\n",
      "\n",
      "========================================================================================================================\n",
      " [3/3] Tuning model: Ridge Regressor | ID: 692fd37102faa1b369c44af6\n",
      "========================================================================================================================\n",
      " Search space found for model: Ridge Regressor\n",
      "\n",
      "================================================================================\n",
      " FETCHING TRAINING DATA  (Project Type: regression)\n",
      "================================================================================\n",
      ">> Loaded dataset from DataRobot backend. Shape: (850, 96)\n",
      ">>>> Target column 'CLV_2' found in dataset.\n",
      "1. Training data shape: (850, 96)\n",
      "2. Target variable: CLV_2\n",
      "3. Project Type: regression\n",
      "================================================================================\n",
      "XX Starting tuning for: Ridge Regressor | ID: 692fd37102faa1b369c44af6\n",
      "XXX Custom Metric: clv_asymmetry_loss\n",
      "XXXX  Metric Function: clv_asymmetry_loss\n",
      "XXXXX  Direction: min\n",
      "================================================================================\n",
      "X Base clv_asymmetry_loss: 186.539415\n",
      "*********** Trying params: {'tweedie_p': 1.4000000000000001}\n",
      "XXXXXXXXXXXXXX Tuned clv_asymmetry_loss: 186.539415 | Î” = 0.000000\n",
      "*********** Trying params: {'tweedie_p': 1.6}                                 \n",
      "XXXXXXXXXXXXXX Tuned clv_asymmetry_loss: 186.539415 | Î” = 0.000000            \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [02:41<00:00, 80.81s/trial, best loss: 186.5394154314289]\n",
      "\n",
      "xxxxxxxxxxxxxxx Best Params: {'tweedie_p': 1.4000000000000001}\n",
      "\n",
      "XXXXXXXXXXXXX Final Comparison Created | Shape: (3, 8)\n",
      "xxxxxxxxxxxxxxx Best clv_asymmetry_loss: 186.539415\n",
      "================================================================================\n",
      "âœ” Completed tuning for Ridge Regressor in 3.14 minutes\n",
      "\n",
      "================================================================================\n",
      " COMPLETED ENTIRE OPTIMIZATION IN 9.27 MINUTES\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" STARTING OPTIMIZATION LOOP\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "all_results = []\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1. Detect project type (binary or regression only)\n",
    "# --------------------------------------------------------------\n",
    "project_type = detect_project_type(proj)\n",
    "print(f\"Detected project type: {project_type}\")\n",
    "\n",
    "if project_type not in {\"binary\", \"regression\"}:\n",
    "    raise RuntimeError(\n",
    "        f\"XXXXX  Unsupported project type '{project_type}'. \"\n",
    "        \"This notebook only supports binary classification & regression.\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\" >>>>>>>>>>> Optimization will use custom metric: {METRIC_FUNCTION.__name__}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2. Tuning Loop\n",
    "# --------------------------------------------------------------\n",
    "for idx, row in df_models.iterrows():\n",
    "    model_id = row[\"Model ID\"]\n",
    "    model_name = row[\"Model Name\"]\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 120)\n",
    "    print(f\" [{idx+1}/{len(df_models)}] Tuning model: {model_name} | ID: {model_id}\")\n",
    "    print(\"=\" * 120)\n",
    "\n",
    "    search_space = get_search_space(model_name)\n",
    "    model_start = time.time()\n",
    "\n",
    "    try:\n",
    "        # ---- Run tuning ----\n",
    "        df_result = tune_and_compare_model(\n",
    "            proj=proj,\n",
    "            base_model_id=model_id,\n",
    "            search_space=search_space,\n",
    "            max_evals=MAX_EVALS,\n",
    "            fallback_path=FALLBACK_TRAINING_PATH,\n",
    "        )\n",
    "\n",
    "        # ---- Add metadata ----\n",
    "        df_result[\"Model ID\"] = model_id\n",
    "        df_result[\"Model Name\"] = model_name\n",
    "        df_result[\"Project Type\"] = project_type\n",
    "        df_result[\"Metric Used\"] = USER_CUSTOM_METRIC\n",
    "        df_result[\"Runtime (min)\"] = round((time.time() - model_start) / 60, 2)\n",
    "\n",
    "        all_results.append(df_result)\n",
    "\n",
    "        print(\n",
    "            f\"âœ” Completed tuning for {model_name} \"\n",
    "            f\"in {df_result['Runtime (min)'].iloc[0]} minutes\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"XXXX Skipping {model_name} due to error: {e}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3. Combine all results\n",
    "# --------------------------------------------------------------\n",
    "end_time = time.time()\n",
    "total_time = round((end_time - start_time) / 60, 2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\" COMPLETED ENTIRE OPTIMIZATION IN {total_time} MINUTES\")\n",
    "print(\"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe4daf-4407-48d2-b29b-144face1abc0",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "# Result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "baa18b42-a95a-4fac-b709-c789d95002d9",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 18,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Combined tuning results created successfully. Shape: (9, 19)\n",
      "\n",
      "  Results sorted by 'clv_asymmetry_loss' (lower=better).\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "###  Results Column Definitions\n",
       "\n",
       "| Column | Description |\n",
       "|---------|-------------|\n",
       "| **trial_number** | Sequential number of the tuning trial (0 = baseline/original model). |\n",
       "| **model_id** | DataRobot model identifier. |\n",
       "| **model_name** | Model type (e.g., RandomForest, XGBoost). |\n",
       "| **type** | Indicates whether the row is Original (baseline) or Tuned. |\n",
       "| **clv_asymmetry_loss** | Final optimization metric value (lower=better). |\n",
       "| **delta_clv_asymmetry_loss** | Difference between baseline and tuned model metric.<br>ðŸŸ¢ Positive â†’ improvement (tuned model better).<br>ðŸ”´ Negative or zero â†’ no gain or degradation. |\n",
       "| **parameters** | Model tuning hyperparameters used in that trial. |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***************************** RESULTS SUMMARY *****************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_964a9_row0_col4 {\n",
       "  background-color: #006837;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_964a9_row0_col5, #T_964a9_row3_col5, #T_964a9_row4_col5, #T_964a9_row5_col5, #T_964a9_row6_col5 {\n",
       "  background-color: #fe9829;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_964a9_row1_col4, #T_964a9_row2_col4 {\n",
       "  background-color: #016a38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_964a9_row1_col5, #T_964a9_row2_col5, #T_964a9_row7_col5, #T_964a9_row8_col5 {\n",
       "  background-color: #ffffe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_964a9_row3_col4, #T_964a9_row4_col4, #T_964a9_row5_col4 {\n",
       "  background-color: #0f8446;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_964a9_row6_col4 {\n",
       "  background-color: #108647;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_964a9_row7_col4 {\n",
       "  background-color: #d1ec86;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_964a9_row8_col4 {\n",
       "  background-color: #a50026;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_964a9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_964a9_level0_col0\" class=\"col_heading level0 col0\" >trial</th>\n",
       "      <th id=\"T_964a9_level0_col1\" class=\"col_heading level0 col1\" >model_id</th>\n",
       "      <th id=\"T_964a9_level0_col2\" class=\"col_heading level0 col2\" >model_name</th>\n",
       "      <th id=\"T_964a9_level0_col3\" class=\"col_heading level0 col3\" >type</th>\n",
       "      <th id=\"T_964a9_level0_col4\" class=\"col_heading level0 col4\" >clv_asymmetry_loss</th>\n",
       "      <th id=\"T_964a9_level0_col5\" class=\"col_heading level0 col5\" >delta</th>\n",
       "      <th id=\"T_964a9_level0_col6\" class=\"col_heading level0 col6\" >status</th>\n",
       "      <th id=\"T_964a9_level0_col7\" class=\"col_heading level0 col7\" >param_enet_alpha</th>\n",
       "      <th id=\"T_964a9_level0_col8\" class=\"col_heading level0 col8\" >param_enet_lambda</th>\n",
       "      <th id=\"T_964a9_level0_col9\" class=\"col_heading level0 col9\" >Model ID</th>\n",
       "      <th id=\"T_964a9_level0_col10\" class=\"col_heading level0 col10\" >Model Name</th>\n",
       "      <th id=\"T_964a9_level0_col11\" class=\"col_heading level0 col11\" >Project Type</th>\n",
       "      <th id=\"T_964a9_level0_col12\" class=\"col_heading level0 col12\" >Metric Used</th>\n",
       "      <th id=\"T_964a9_level0_col13\" class=\"col_heading level0 col13\" >Runtime (min)</th>\n",
       "      <th id=\"T_964a9_level0_col14\" class=\"col_heading level0 col14\" >param_learning_rate</th>\n",
       "      <th id=\"T_964a9_level0_col15\" class=\"col_heading level0 col15\" >param_max_depth</th>\n",
       "      <th id=\"T_964a9_level0_col16\" class=\"col_heading level0 col16\" >param_n_estimators</th>\n",
       "      <th id=\"T_964a9_level0_col17\" class=\"col_heading level0 col17\" >param_num_leaves</th>\n",
       "      <th id=\"T_964a9_level0_col18\" class=\"col_heading level0 col18\" >param_tweedie_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_964a9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_964a9_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_964a9_row0_col1\" class=\"data row0 col1\" >692fd37102faa1b369c44afa</td>\n",
       "      <td id=\"T_964a9_row0_col2\" class=\"data row0 col2\" >Light Gradient Boosting on ElasticNet Predictions </td>\n",
       "      <td id=\"T_964a9_row0_col3\" class=\"data row0 col3\" >Original</td>\n",
       "      <td id=\"T_964a9_row0_col4\" class=\"data row0 col4\" >168.560443</td>\n",
       "      <td id=\"T_964a9_row0_col5\" class=\"data row0 col5\" >0.000000</td>\n",
       "      <td id=\"T_964a9_row0_col6\" class=\"data row0 col6\" >ok</td>\n",
       "      <td id=\"T_964a9_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "      <td id=\"T_964a9_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
       "      <td id=\"T_964a9_row0_col9\" class=\"data row0 col9\" >692fd37102faa1b369c44afa</td>\n",
       "      <td id=\"T_964a9_row0_col10\" class=\"data row0 col10\" >Light Gradient Boosting on ElasticNet Predictions </td>\n",
       "      <td id=\"T_964a9_row0_col11\" class=\"data row0 col11\" >regression</td>\n",
       "      <td id=\"T_964a9_row0_col12\" class=\"data row0 col12\" >clv_asymmetry_loss</td>\n",
       "      <td id=\"T_964a9_row0_col13\" class=\"data row0 col13\" >3.100000</td>\n",
       "      <td id=\"T_964a9_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_964a9_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_964a9_row0_col16\" class=\"data row0 col16\" >nan</td>\n",
       "      <td id=\"T_964a9_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "      <td id=\"T_964a9_row0_col18\" class=\"data row0 col18\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_964a9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_964a9_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_964a9_row1_col1\" class=\"data row1 col1\" >692fd952ad0f5df96189a0b3</td>\n",
       "      <td id=\"T_964a9_row1_col2\" class=\"data row1 col2\" >Light Gradient Boosting on ElasticNet Predictions </td>\n",
       "      <td id=\"T_964a9_row1_col3\" class=\"data row1 col3\" >Tuned</td>\n",
       "      <td id=\"T_964a9_row1_col4\" class=\"data row1 col4\" >169.809753</td>\n",
       "      <td id=\"T_964a9_row1_col5\" class=\"data row1 col5\" >-1.249310</td>\n",
       "      <td id=\"T_964a9_row1_col6\" class=\"data row1 col6\" >ok</td>\n",
       "      <td id=\"T_964a9_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_964a9_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_964a9_row1_col9\" class=\"data row1 col9\" >692fd37102faa1b369c44afa</td>\n",
       "      <td id=\"T_964a9_row1_col10\" class=\"data row1 col10\" >Light Gradient Boosting on ElasticNet Predictions </td>\n",
       "      <td id=\"T_964a9_row1_col11\" class=\"data row1 col11\" >regression</td>\n",
       "      <td id=\"T_964a9_row1_col12\" class=\"data row1 col12\" >clv_asymmetry_loss</td>\n",
       "      <td id=\"T_964a9_row1_col13\" class=\"data row1 col13\" >3.100000</td>\n",
       "      <td id=\"T_964a9_row1_col14\" class=\"data row1 col14\" >0.049762</td>\n",
       "      <td id=\"T_964a9_row1_col15\" class=\"data row1 col15\" >7.000000</td>\n",
       "      <td id=\"T_964a9_row1_col16\" class=\"data row1 col16\" >650.000000</td>\n",
       "      <td id=\"T_964a9_row1_col17\" class=\"data row1 col17\" >30.000000</td>\n",
       "      <td id=\"T_964a9_row1_col18\" class=\"data row1 col18\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_964a9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_964a9_row2_col0\" class=\"data row2 col0\" >1</td>\n",
       "      <td id=\"T_964a9_row2_col1\" class=\"data row2 col1\" >692fd8fe58440a870d56724c</td>\n",
       "      <td id=\"T_964a9_row2_col2\" class=\"data row2 col2\" >Light Gradient Boosting on ElasticNet Predictions </td>\n",
       "      <td id=\"T_964a9_row2_col3\" class=\"data row2 col3\" >Tuned</td>\n",
       "      <td id=\"T_964a9_row2_col4\" class=\"data row2 col4\" >169.924455</td>\n",
       "      <td id=\"T_964a9_row2_col5\" class=\"data row2 col5\" >-1.364012</td>\n",
       "      <td id=\"T_964a9_row2_col6\" class=\"data row2 col6\" >ok</td>\n",
       "      <td id=\"T_964a9_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_964a9_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
       "      <td id=\"T_964a9_row2_col9\" class=\"data row2 col9\" >692fd37102faa1b369c44afa</td>\n",
       "      <td id=\"T_964a9_row2_col10\" class=\"data row2 col10\" >Light Gradient Boosting on ElasticNet Predictions </td>\n",
       "      <td id=\"T_964a9_row2_col11\" class=\"data row2 col11\" >regression</td>\n",
       "      <td id=\"T_964a9_row2_col12\" class=\"data row2 col12\" >clv_asymmetry_loss</td>\n",
       "      <td id=\"T_964a9_row2_col13\" class=\"data row2 col13\" >3.100000</td>\n",
       "      <td id=\"T_964a9_row2_col14\" class=\"data row2 col14\" >0.032957</td>\n",
       "      <td id=\"T_964a9_row2_col15\" class=\"data row2 col15\" >6.000000</td>\n",
       "      <td id=\"T_964a9_row2_col16\" class=\"data row2 col16\" >250.000000</td>\n",
       "      <td id=\"T_964a9_row2_col17\" class=\"data row2 col17\" >80.000000</td>\n",
       "      <td id=\"T_964a9_row2_col18\" class=\"data row2 col18\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_964a9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_964a9_row3_col0\" class=\"data row3 col0\" >0</td>\n",
       "      <td id=\"T_964a9_row3_col1\" class=\"data row3 col1\" >692fd37102faa1b369c44af6</td>\n",
       "      <td id=\"T_964a9_row3_col2\" class=\"data row3 col2\" >Ridge Regressor</td>\n",
       "      <td id=\"T_964a9_row3_col3\" class=\"data row3 col3\" >Original</td>\n",
       "      <td id=\"T_964a9_row3_col4\" class=\"data row3 col4\" >186.539415</td>\n",
       "      <td id=\"T_964a9_row3_col5\" class=\"data row3 col5\" >0.000000</td>\n",
       "      <td id=\"T_964a9_row3_col6\" class=\"data row3 col6\" >ok</td>\n",
       "      <td id=\"T_964a9_row3_col7\" class=\"data row3 col7\" >nan</td>\n",
       "      <td id=\"T_964a9_row3_col8\" class=\"data row3 col8\" >nan</td>\n",
       "      <td id=\"T_964a9_row3_col9\" class=\"data row3 col9\" >692fd37102faa1b369c44af6</td>\n",
       "      <td id=\"T_964a9_row3_col10\" class=\"data row3 col10\" >Ridge Regressor</td>\n",
       "      <td id=\"T_964a9_row3_col11\" class=\"data row3 col11\" >regression</td>\n",
       "      <td id=\"T_964a9_row3_col12\" class=\"data row3 col12\" >clv_asymmetry_loss</td>\n",
       "      <td id=\"T_964a9_row3_col13\" class=\"data row3 col13\" >3.140000</td>\n",
       "      <td id=\"T_964a9_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_964a9_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_964a9_row3_col16\" class=\"data row3 col16\" >nan</td>\n",
       "      <td id=\"T_964a9_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "      <td id=\"T_964a9_row3_col18\" class=\"data row3 col18\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_964a9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_964a9_row4_col0\" class=\"data row4 col0\" >1</td>\n",
       "      <td id=\"T_964a9_row4_col1\" class=\"data row4 col1\" >692fd9bad89a0b04b789a1b8</td>\n",
       "      <td id=\"T_964a9_row4_col2\" class=\"data row4 col2\" >Ridge Regressor</td>\n",
       "      <td id=\"T_964a9_row4_col3\" class=\"data row4 col3\" >Tuned</td>\n",
       "      <td id=\"T_964a9_row4_col4\" class=\"data row4 col4\" >186.539415</td>\n",
       "      <td id=\"T_964a9_row4_col5\" class=\"data row4 col5\" >0.000000</td>\n",
       "      <td id=\"T_964a9_row4_col6\" class=\"data row4 col6\" >ok</td>\n",
       "      <td id=\"T_964a9_row4_col7\" class=\"data row4 col7\" >nan</td>\n",
       "      <td id=\"T_964a9_row4_col8\" class=\"data row4 col8\" >nan</td>\n",
       "      <td id=\"T_964a9_row4_col9\" class=\"data row4 col9\" >692fd37102faa1b369c44af6</td>\n",
       "      <td id=\"T_964a9_row4_col10\" class=\"data row4 col10\" >Ridge Regressor</td>\n",
       "      <td id=\"T_964a9_row4_col11\" class=\"data row4 col11\" >regression</td>\n",
       "      <td id=\"T_964a9_row4_col12\" class=\"data row4 col12\" >clv_asymmetry_loss</td>\n",
       "      <td id=\"T_964a9_row4_col13\" class=\"data row4 col13\" >3.140000</td>\n",
       "      <td id=\"T_964a9_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_964a9_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_964a9_row4_col16\" class=\"data row4 col16\" >nan</td>\n",
       "      <td id=\"T_964a9_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "      <td id=\"T_964a9_row4_col18\" class=\"data row4 col18\" >1.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_964a9_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_964a9_row5_col0\" class=\"data row5 col0\" >2</td>\n",
       "      <td id=\"T_964a9_row5_col1\" class=\"data row5 col1\" >692fda094a11aecc4189aecc</td>\n",
       "      <td id=\"T_964a9_row5_col2\" class=\"data row5 col2\" >Ridge Regressor</td>\n",
       "      <td id=\"T_964a9_row5_col3\" class=\"data row5 col3\" >Tuned</td>\n",
       "      <td id=\"T_964a9_row5_col4\" class=\"data row5 col4\" >186.539415</td>\n",
       "      <td id=\"T_964a9_row5_col5\" class=\"data row5 col5\" >0.000000</td>\n",
       "      <td id=\"T_964a9_row5_col6\" class=\"data row5 col6\" >ok</td>\n",
       "      <td id=\"T_964a9_row5_col7\" class=\"data row5 col7\" >nan</td>\n",
       "      <td id=\"T_964a9_row5_col8\" class=\"data row5 col8\" >nan</td>\n",
       "      <td id=\"T_964a9_row5_col9\" class=\"data row5 col9\" >692fd37102faa1b369c44af6</td>\n",
       "      <td id=\"T_964a9_row5_col10\" class=\"data row5 col10\" >Ridge Regressor</td>\n",
       "      <td id=\"T_964a9_row5_col11\" class=\"data row5 col11\" >regression</td>\n",
       "      <td id=\"T_964a9_row5_col12\" class=\"data row5 col12\" >clv_asymmetry_loss</td>\n",
       "      <td id=\"T_964a9_row5_col13\" class=\"data row5 col13\" >3.140000</td>\n",
       "      <td id=\"T_964a9_row5_col14\" class=\"data row5 col14\" >nan</td>\n",
       "      <td id=\"T_964a9_row5_col15\" class=\"data row5 col15\" >nan</td>\n",
       "      <td id=\"T_964a9_row5_col16\" class=\"data row5 col16\" >nan</td>\n",
       "      <td id=\"T_964a9_row5_col17\" class=\"data row5 col17\" >nan</td>\n",
       "      <td id=\"T_964a9_row5_col18\" class=\"data row5 col18\" >1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_964a9_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_964a9_row6_col0\" class=\"data row6 col0\" >0</td>\n",
       "      <td id=\"T_964a9_row6_col1\" class=\"data row6 col1\" >692fd37102faa1b369c44af7</td>\n",
       "      <td id=\"T_964a9_row6_col2\" class=\"data row6 col2\" >Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)</td>\n",
       "      <td id=\"T_964a9_row6_col3\" class=\"data row6 col3\" >Original</td>\n",
       "      <td id=\"T_964a9_row6_col4\" class=\"data row6 col4\" >187.571906</td>\n",
       "      <td id=\"T_964a9_row6_col5\" class=\"data row6 col5\" >0.000000</td>\n",
       "      <td id=\"T_964a9_row6_col6\" class=\"data row6 col6\" >ok</td>\n",
       "      <td id=\"T_964a9_row6_col7\" class=\"data row6 col7\" >nan</td>\n",
       "      <td id=\"T_964a9_row6_col8\" class=\"data row6 col8\" >nan</td>\n",
       "      <td id=\"T_964a9_row6_col9\" class=\"data row6 col9\" >692fd37102faa1b369c44af7</td>\n",
       "      <td id=\"T_964a9_row6_col10\" class=\"data row6 col10\" >Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)</td>\n",
       "      <td id=\"T_964a9_row6_col11\" class=\"data row6 col11\" >regression</td>\n",
       "      <td id=\"T_964a9_row6_col12\" class=\"data row6 col12\" >clv_asymmetry_loss</td>\n",
       "      <td id=\"T_964a9_row6_col13\" class=\"data row6 col13\" >3.040000</td>\n",
       "      <td id=\"T_964a9_row6_col14\" class=\"data row6 col14\" >nan</td>\n",
       "      <td id=\"T_964a9_row6_col15\" class=\"data row6 col15\" >nan</td>\n",
       "      <td id=\"T_964a9_row6_col16\" class=\"data row6 col16\" >nan</td>\n",
       "      <td id=\"T_964a9_row6_col17\" class=\"data row6 col17\" >nan</td>\n",
       "      <td id=\"T_964a9_row6_col18\" class=\"data row6 col18\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_964a9_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_964a9_row7_col0\" class=\"data row7 col0\" >1</td>\n",
       "      <td id=\"T_964a9_row7_col1\" class=\"data row7 col1\" >692fd84aa56e28f6f8567ec8</td>\n",
       "      <td id=\"T_964a9_row7_col2\" class=\"data row7 col2\" >Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)</td>\n",
       "      <td id=\"T_964a9_row7_col3\" class=\"data row7 col3\" >Tuned</td>\n",
       "      <td id=\"T_964a9_row7_col4\" class=\"data row7 col4\" >280.625171</td>\n",
       "      <td id=\"T_964a9_row7_col5\" class=\"data row7 col5\" >-93.053265</td>\n",
       "      <td id=\"T_964a9_row7_col6\" class=\"data row7 col6\" >ok</td>\n",
       "      <td id=\"T_964a9_row7_col7\" class=\"data row7 col7\" >0.211402</td>\n",
       "      <td id=\"T_964a9_row7_col8\" class=\"data row7 col8\" >0.098394</td>\n",
       "      <td id=\"T_964a9_row7_col9\" class=\"data row7 col9\" >692fd37102faa1b369c44af7</td>\n",
       "      <td id=\"T_964a9_row7_col10\" class=\"data row7 col10\" >Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)</td>\n",
       "      <td id=\"T_964a9_row7_col11\" class=\"data row7 col11\" >regression</td>\n",
       "      <td id=\"T_964a9_row7_col12\" class=\"data row7 col12\" >clv_asymmetry_loss</td>\n",
       "      <td id=\"T_964a9_row7_col13\" class=\"data row7 col13\" >3.040000</td>\n",
       "      <td id=\"T_964a9_row7_col14\" class=\"data row7 col14\" >nan</td>\n",
       "      <td id=\"T_964a9_row7_col15\" class=\"data row7 col15\" >nan</td>\n",
       "      <td id=\"T_964a9_row7_col16\" class=\"data row7 col16\" >nan</td>\n",
       "      <td id=\"T_964a9_row7_col17\" class=\"data row7 col17\" >nan</td>\n",
       "      <td id=\"T_964a9_row7_col18\" class=\"data row7 col18\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_964a9_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_964a9_row8_col0\" class=\"data row8 col0\" >2</td>\n",
       "      <td id=\"T_964a9_row8_col1\" class=\"data row8 col1\" >692fd898532032b903567405</td>\n",
       "      <td id=\"T_964a9_row8_col2\" class=\"data row8 col2\" >Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)</td>\n",
       "      <td id=\"T_964a9_row8_col3\" class=\"data row8 col3\" >Tuned</td>\n",
       "      <td id=\"T_964a9_row8_col4\" class=\"data row8 col4\" >459.572638</td>\n",
       "      <td id=\"T_964a9_row8_col5\" class=\"data row8 col5\" >-272.000732</td>\n",
       "      <td id=\"T_964a9_row8_col6\" class=\"data row8 col6\" >ok</td>\n",
       "      <td id=\"T_964a9_row8_col7\" class=\"data row8 col7\" >0.120250</td>\n",
       "      <td id=\"T_964a9_row8_col8\" class=\"data row8 col8\" >0.471101</td>\n",
       "      <td id=\"T_964a9_row8_col9\" class=\"data row8 col9\" >692fd37102faa1b369c44af7</td>\n",
       "      <td id=\"T_964a9_row8_col10\" class=\"data row8 col10\" >Elastic-Net Regressor (mixing alpha=0.5 / Least-Squares Loss)</td>\n",
       "      <td id=\"T_964a9_row8_col11\" class=\"data row8 col11\" >regression</td>\n",
       "      <td id=\"T_964a9_row8_col12\" class=\"data row8 col12\" >clv_asymmetry_loss</td>\n",
       "      <td id=\"T_964a9_row8_col13\" class=\"data row8 col13\" >3.040000</td>\n",
       "      <td id=\"T_964a9_row8_col14\" class=\"data row8 col14\" >nan</td>\n",
       "      <td id=\"T_964a9_row8_col15\" class=\"data row8 col15\" >nan</td>\n",
       "      <td id=\"T_964a9_row8_col16\" class=\"data row8 col16\" >nan</td>\n",
       "      <td id=\"T_964a9_row8_col17\" class=\"data row8 col17\" >nan</td>\n",
       "      <td id=\"T_964a9_row8_col18\" class=\"data row8 col18\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd4d855f210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ ********************** BEST MODEL (Based on Metric) **********************\n",
      "\n",
      "trial                                                                  0\n",
      "model_id                                        692fd37102faa1b369c44afa\n",
      "model_name             Light Gradient Boosting on ElasticNet Predicti...\n",
      "type                                                            Original\n",
      "clv_asymmetry_loss                                            168.560443\n",
      "delta                                                                0.0\n",
      "status                                                                ok\n",
      "param_enet_alpha                                                     NaN\n",
      "param_enet_lambda                                                    NaN\n",
      "Model ID                                        692fd37102faa1b369c44afa\n",
      "Model Name             Light Gradient Boosting on ElasticNet Predicti...\n",
      "Project Type                                                  regression\n",
      "Metric Used                                           clv_asymmetry_loss\n",
      "Runtime (min)                                                        3.1\n",
      "param_learning_rate                                                  NaN\n",
      "param_max_depth                                                      NaN\n",
      "param_n_estimators                                                   NaN\n",
      "param_num_leaves                                                     NaN\n",
      "param_tweedie_p                                                      NaN\n",
      "Name: 0, dtype: object\n",
      "\n",
      "==========================================================================\n",
      "\n",
      "\n",
      " Total time taken: 9.27 seconds (0.15 minutes)\n",
      "***************************** OPTIMIZATION COMPLETE *****************************\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "#  ----------FINAL AGGREGATION AND RESULT VISUALIZATION\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# ---- Combine all results ----\n",
    "if all_results:\n",
    "    df_all_results = pd.concat(all_results, ignore_index=True)\n",
    "    print(f\"\\n Combined tuning results created successfully. Shape: {df_all_results.shape}\")\n",
    "else:\n",
    "    df_all_results = pd.DataFrame()\n",
    "    print(\">>>>>>>>>  No results collected â€” all models failed or were skipped.\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ------ Identify metric key and sorting direction dynamically\n",
    "# --------------------------------------------------------------\n",
    "metric_key = USER_CUSTOM_METRIC if \"USER_CUSTOM_METRIC\" in globals() else \"metric\"\n",
    "\n",
    "if metric_key not in df_all_results.columns:\n",
    "    metric_key = \"metric\"  # fallback\n",
    "    print(f\">>>>>>>>>>> Metric '{USER_CUSTOM_METRIC}' not found â€” using 'metric' column instead.\")\n",
    "\n",
    "direction = (\n",
    "    METRIC_DIRECTION\n",
    "    if isinstance(METRIC_DIRECTION, str)\n",
    "    else METRIC_DIRECTION.get(metric_key, \"min\")\n",
    ")\n",
    "ascending = True if direction == \"min\" else False\n",
    "direction_label = \"lower=better\" if ascending else \"higher=better\"\n",
    "\n",
    "# ---- Sort results ----\n",
    "df_all_results = df_all_results.sort_values(by=metric_key, ascending=ascending)\n",
    "df_all_results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"\\n  Results sorted by '{metric_key}' ({direction_label}).\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# --------- Apply Heatmap Styling\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Use redâ†’green gradient for cost (or metric) column\n",
    "styled_results = df_all_results.style.background_gradient(\n",
    "    subset=[metric_key],\n",
    "    cmap=\"RdYlGn_r\" if ascending else \"RdYlGn\",  # green = better, red = worse\n",
    ")\n",
    "\n",
    "# Add gradient to delta columns if available\n",
    "for delta_col in [\"delta_cost\", \"delta_metric\", f\"delta_{metric_key}\", \"delta\"]:\n",
    "    if delta_col in df_all_results.columns:\n",
    "        try:\n",
    "            styled_results = styled_results.background_gradient(\n",
    "                subset=[delta_col], cmap=\"YlOrBr\", vmin=-0.1, vmax=0.1\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"XXXX Could not apply gradient to {delta_col}: {e}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# >>>>>>>>>>>>> Display Column Definitions (Markdown)\n",
    "# --------------------------------------------------------------\n",
    "display(\n",
    "    Markdown(\n",
    "        f\"\"\"\n",
    "###  Results Column Definitions\n",
    "\n",
    "| Column | Description |\n",
    "|---------|-------------|\n",
    "| **trial_number** | Sequential number of the tuning trial (0 = baseline/original model). |\n",
    "| **model_id** | DataRobot model identifier. |\n",
    "| **model_name** | Model type (e.g., RandomForest, XGBoost). |\n",
    "| **type** | Indicates whether the row is Original (baseline) or Tuned. |\n",
    "| **{metric_key}** | Final optimization metric value ({direction_label}). |\n",
    "| **delta_{metric_key}** | Difference between baseline and tuned model metric.<br>ðŸŸ¢ Positive â†’ improvement (tuned model better).<br>ðŸ”´ Negative or zero â†’ no gain or degradation. |\n",
    "| **parameters** | Model tuning hyperparameters used in that trial. |\n",
    "\"\"\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----------- Display Styled Results\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\n\")\n",
    "print(\"***************************** RESULTS SUMMARY *****************************\\n\")\n",
    "display(styled_results)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ------------ Identify and Display Best Model\n",
    "# --------------------------------------------------------------\n",
    "if not df_all_results.empty:\n",
    "    best_model = (\n",
    "        df_all_results.loc[df_all_results[metric_key].idxmin()]\n",
    "        if ascending\n",
    "        else df_all_results.loc[df_all_results[metric_key].idxmax()]\n",
    "    )\n",
    "\n",
    "    print(\"\\n------ ********************** BEST MODEL (Based on Metric) **********************\\n\")\n",
    "    print(best_model)\n",
    "    print(\"\\n==========================================================================\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ------------- Display Total Time\n",
    "# --------------------------------------------------------------\n",
    "print(f\"\\n Total time taken: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
    "print(\"***************************** OPTIMIZATION COMPLETE *****************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e7929a9c-800d-4dbf-809e-953b4c49580e",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 2,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 19)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea997d26-26d7-4b42-85b1-4cbfa8cba1ae",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, you:\n",
    "\n",
    "- Loaded the training dataset and detected project type automatically\n",
    "- Defined business-driven custom metrics for both classification and regression\n",
    "- Performed Bayesian hyperparameter optimization (HyperOpt)\n",
    "- Compared tuned models against baseline using the custom metric\n",
    "- Selected the best-performing models dynamically. The models will be reflected in the UI.\n",
    "- Optionally predicted the scoring dataset with top 5 models (tuned/original). This section is below this cell.\n",
    "\n",
    "This workflow ensures that models are aligned with business objectives rather than generic ML metrics. The same structure can be reused for:\n",
    "- CLV prediction\n",
    "- Fraud detection\n",
    "- Churn modeling\n",
    "- Insurance risk modeling\n",
    "- Any metric-sensitive domain requiring asymmetric cost functions\n",
    "\n",
    "By integrating custom loss functions with DataRobot tuning capabilities, you achieve a model optimization process that is transparent, repeatable, and business-driven.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d528d983-0fcc-4c38-857b-8dac00b3804b",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "# Optional\n",
    "\n",
    "Prediction for scoring dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a391791-79b8-4a17-9b2a-233f39459d2c",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "## Model scoring pipeline (regression + classification)\n",
    "\n",
    "This section scores the top 5 tuned models on a new dataset and generates predictions for the scoring dataset so that you can compare the performance of the model with the actuals later.\n",
    "\n",
    "### 1: Load scoring dataset\n",
    "\n",
    "- Reads the scoring dataset from a local CSV file.\n",
    "- Uploads the dataset to the DataRobot project using `proj.upload_dataset()`.\n",
    "- Detects the project type (`binary` or `regression`) for downstream logic.\n",
    "\n",
    "### 2: Select top 5 models\n",
    "\n",
    "- Sorts the `df_all_results` DataFrame by the custom metric (`USER_CUSTOM_METRIC`).\n",
    "- Uses the metric direction (`min` or `max`) to determine sorting order.\n",
    "- Selects the top 5 models for scoring and displays their metadata.\n",
    "\n",
    "### 3: Generate predictions\n",
    "\n",
    "For each of the top 5 models:\n",
    "- Loads the model using its ID.\n",
    "- Requests predictions on the uploaded scoring dataset.\n",
    "- Based on the project type:\n",
    "  - **Binary classification**:\n",
    "    - Extracts the probability column (e.g., `class_1`, `positive_probability`, or `prediction`).\n",
    "    - Applies a threshold (default = 0.5) to convert probabilities into binary predictions.\n",
    "    - Stores both probabilities and predicted labels.\n",
    "  - **Regression**:\n",
    "    - Extracts the `prediction` column directly.\n",
    "- Adds prediction columns to the `predsAll` DataFrame with model-specific prefixes.\n",
    "\n",
    "### 4: Create final output\n",
    "\n",
    "- Builds a summary table (`scoring_summary_df`) mapping each model to its corresponding prediction column.\n",
    "- Saves the full prediction dataset (`predsAll`) to the results folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce11c2a-426a-4802-a7fc-acccbe2926e8",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 27491,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Id --- 692fd31ca5a8b5da9689a2a1\n",
      "\n",
      "================================================================================\n",
      " Total shape of the Scoring dataset is - (136, 96)\n"
     ]
    }
   ],
   "source": [
    "## Read scoring data\n",
    "\n",
    "filename = \"Regression_scoring_dataset_2.csv\"\n",
    "# filename= \"DR_Demo_AML_Alert_SCORING.csv\"\n",
    "proj = dr.Project.get(project_id)\n",
    "print(f\"Project ID: {project_id}\")\n",
    "test = pd.read_csv(filename, encoding=\"ISO-8859-1\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "print(f\"Total shape of the scoring dataset: {test.shape}\")\n",
    "\n",
    "dataset = proj.upload_dataset(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab1ddd59-2312-447d-bf3a-09fd8583cb8f",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 10424,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================ SCORING PHASE STARTED ============================\n",
      "\n",
      "> Loaded scoring dataset successfully. Shape: (136, 96)\n",
      "*** Detected Project Type: regression\n",
      "\n",
      ">>>> Selected Top 5 Models based on clv_asymmetry_loss (lower=better)\n"
     ]
    },
    {
     "data": {
      "application/vnd.dataframe+json": {
       "columns": [
        {
         "name": "index",
         "type": "integer"
        },
        {
         "name": "model_id",
         "type": "string"
        },
        {
         "name": "model_name",
         "type": "string"
        },
        {
         "name": "type",
         "type": "string"
        },
        {
         "name": "clv_asymmetry_loss",
         "type": "number"
        }
       ],
       "count": 5,
       "data": [
        {
         "clv_asymmetry_loss": 168.5604429477,
         "index": 0,
         "model_id": "692fd37102faa1b369c44afa",
         "model_name": "Light Gradient Boosting on ElasticNet Predictions ",
         "type": "Original"
        },
        {
         "clv_asymmetry_loss": 169.8097529761,
         "index": 1,
         "model_id": "692fd952ad0f5df96189a0b3",
         "model_name": "Light Gradient Boosting on ElasticNet Predictions ",
         "type": "Tuned"
        },
        {
         "clv_asymmetry_loss": 169.9244549749,
         "index": 2,
         "model_id": "692fd8fe58440a870d56724c",
         "model_name": "Light Gradient Boosting on ElasticNet Predictions ",
         "type": "Tuned"
        },
        {
         "clv_asymmetry_loss": 186.5394154314,
         "index": 3,
         "model_id": "692fd37102faa1b369c44af6",
         "model_name": "Ridge Regressor",
         "type": "Original"
        },
        {
         "clv_asymmetry_loss": 186.5394154314,
         "index": 4,
         "model_id": "692fd9bad89a0b04b789a1b8",
         "model_name": "Ridge Regressor",
         "type": "Tuned"
        }
       ],
       "error": [],
       "indexKey": "index",
       "limit": 10,
       "offset": 0,
       "referenceId": 140548129227856,
       "sortedBy": "",
       "totalCount": 5
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>type</th>\n",
       "      <th>clv_asymmetry_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>Original</td>\n",
       "      <td>168.560443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>692fd952ad0f5df96189a0b3</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>Tuned</td>\n",
       "      <td>169.809753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>692fd8fe58440a870d56724c</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>Tuned</td>\n",
       "      <td>169.924455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>692fd37102faa1b369c44af6</td>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>Original</td>\n",
       "      <td>186.539415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>692fd9bad89a0b04b789a1b8</td>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>Tuned</td>\n",
       "      <td>186.539415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model_id  \\\n",
       "0  692fd37102faa1b369c44afa   \n",
       "1  692fd952ad0f5df96189a0b3   \n",
       "2  692fd8fe58440a870d56724c   \n",
       "3  692fd37102faa1b369c44af6   \n",
       "4  692fd9bad89a0b04b789a1b8   \n",
       "\n",
       "                                          model_name      type  \\\n",
       "0  Light Gradient Boosting on ElasticNet Predicti...  Original   \n",
       "1  Light Gradient Boosting on ElasticNet Predicti...     Tuned   \n",
       "2  Light Gradient Boosting on ElasticNet Predicti...     Tuned   \n",
       "3                                    Ridge Regressor  Original   \n",
       "4                                    Ridge Regressor     Tuned   \n",
       "\n",
       "   clv_asymmetry_loss  \n",
       "0          168.560443  \n",
       "1          169.809753  \n",
       "2          169.924455  \n",
       "3          186.539415  \n",
       "4          186.539415  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Predicting with Model 692fd37102faa1b369c44afa (Original)\n",
      "> Predictions added for c44afa_Original\n",
      "\n",
      " Predicting with Model 692fd952ad0f5df96189a0b3 (Tuned)\n",
      "> Predictions added for 89a0b3_Tuned\n",
      "\n",
      " Predicting with Model 692fd8fe58440a870d56724c (Tuned)\n",
      "> Predictions added for 56724c_Tuned\n",
      "\n",
      " Predicting with Model 692fd37102faa1b369c44af6 (Original)\n",
      "> Predictions added for c44af6_Original\n",
      "\n",
      " Predicting with Model 692fd9bad89a0b04b789a1b8 (Tuned)\n",
      "> Predictions added for 89a1b8_Tuned\n",
      "\n",
      " MODELâ€“PREDICTION COLUMN MAP:\n"
     ]
    },
    {
     "data": {
      "application/vnd.dataframe+json": {
       "columns": [
        {
         "name": "index",
         "type": "integer"
        },
        {
         "name": "model_id",
         "type": "string"
        },
        {
         "name": "model_name",
         "type": "string"
        },
        {
         "name": "type",
         "type": "string"
        },
        {
         "name": "prediction_column",
         "type": "string"
        }
       ],
       "count": 5,
       "data": [
        {
         "index": 0,
         "model_id": "692fd37102faa1b369c44afa",
         "model_name": "Light Gradient Boosting on ElasticNet Predictions ",
         "prediction_column": "c44afa_Original_pred",
         "type": "Original"
        },
        {
         "index": 1,
         "model_id": "692fd952ad0f5df96189a0b3",
         "model_name": "Light Gradient Boosting on ElasticNet Predictions ",
         "prediction_column": "89a0b3_Tuned_pred",
         "type": "Tuned"
        },
        {
         "index": 2,
         "model_id": "692fd8fe58440a870d56724c",
         "model_name": "Light Gradient Boosting on ElasticNet Predictions ",
         "prediction_column": "56724c_Tuned_pred",
         "type": "Tuned"
        },
        {
         "index": 3,
         "model_id": "692fd37102faa1b369c44af6",
         "model_name": "Ridge Regressor",
         "prediction_column": "c44af6_Original_pred",
         "type": "Original"
        },
        {
         "index": 4,
         "model_id": "692fd9bad89a0b04b789a1b8",
         "model_name": "Ridge Regressor",
         "prediction_column": "89a1b8_Tuned_pred",
         "type": "Tuned"
        }
       ],
       "error": [],
       "indexKey": "index",
       "limit": 10,
       "offset": 0,
       "referenceId": 140552139302416,
       "sortedBy": "",
       "totalCount": 5
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>type</th>\n",
       "      <th>prediction_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>692fd37102faa1b369c44afa</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>Original</td>\n",
       "      <td>c44afa_Original_pred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>692fd952ad0f5df96189a0b3</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>Tuned</td>\n",
       "      <td>89a0b3_Tuned_pred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>692fd8fe58440a870d56724c</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>Tuned</td>\n",
       "      <td>56724c_Tuned_pred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>692fd37102faa1b369c44af6</td>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>Original</td>\n",
       "      <td>c44af6_Original_pred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>692fd9bad89a0b04b789a1b8</td>\n",
       "      <td>Ridge Regressor</td>\n",
       "      <td>Tuned</td>\n",
       "      <td>89a1b8_Tuned_pred</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model_id  \\\n",
       "0  692fd37102faa1b369c44afa   \n",
       "1  692fd952ad0f5df96189a0b3   \n",
       "2  692fd8fe58440a870d56724c   \n",
       "3  692fd37102faa1b369c44af6   \n",
       "4  692fd9bad89a0b04b789a1b8   \n",
       "\n",
       "                                          model_name      type  \\\n",
       "0  Light Gradient Boosting on ElasticNet Predicti...  Original   \n",
       "1  Light Gradient Boosting on ElasticNet Predicti...     Tuned   \n",
       "2  Light Gradient Boosting on ElasticNet Predicti...     Tuned   \n",
       "3                                    Ridge Regressor  Original   \n",
       "4                                    Ridge Regressor     Tuned   \n",
       "\n",
       "      prediction_column  \n",
       "0  c44afa_Original_pred  \n",
       "1     89a0b3_Tuned_pred  \n",
       "2     56724c_Tuned_pred  \n",
       "3  c44af6_Original_pred  \n",
       "4     89a1b8_Tuned_pred  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Final predictions saved to: /home/notebooks/storage/Results/Final_Scoring_Top5.csv\n",
      "\n",
      "============================ SCORING PHASE COMPLETE ============================\n",
      "\n",
      "\n",
      " Prediction columns generated:\n",
      "\n",
      "['c44afa_Original_pred', '89a0b3_Tuned_pred', '56724c_Tuned_pred', 'c44af6_Original_pred', '89a1b8_Tuned_pred']\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================================================\n",
    "# ------------ UNIVERSAL MODEL SCORING PIPELINE (Regression + Classification)\n",
    "# =====================================================================================================\n",
    "\n",
    "print(\"\\n============================ SCORING PHASE STARTED ============================\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1ï¸) Load Scoring Dataset\n",
    "# --------------------------------------------------------------\n",
    "try:\n",
    "    predsAll = test.copy()\n",
    "    print(f\"> Loaded scoring dataset successfully. Shape: {predsAll.shape}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"X Please load your scoring dataset as `test`. Error: {e}\")\n",
    "\n",
    "target_name = proj.target\n",
    "if target_name in predsAll.columns:\n",
    "    predsAll.rename(columns={target_name: \"actuals\"}, inplace=True)\n",
    "else:\n",
    "    predsAll[\"actuals\"] = np.nan\n",
    "\n",
    "project_type = detect_project_type(proj)\n",
    "print(f\"*** Detected Project Type: {project_type}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2) Select Top 5 Models Based on Custom Metric\n",
    "# --------------------------------------------------------------\n",
    "metric_key = USER_CUSTOM_METRIC if USER_CUSTOM_METRIC in df_all_results.columns else \"metric\"\n",
    "direction = (\n",
    "    METRIC_DIRECTION\n",
    "    if isinstance(METRIC_DIRECTION, str)\n",
    "    else METRIC_DIRECTION.get(metric_key, \"min\")\n",
    ")\n",
    "ascending = True if direction == \"min\" else False\n",
    "\n",
    "df_top_models = (\n",
    "    df_all_results.sort_values(by=metric_key, ascending=ascending).head(5).reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\n>>>> Selected Top 5 Models based on {metric_key} ({'lower=better' if ascending else 'higher=better'})\"\n",
    ")\n",
    "display(df_top_models[[\"model_id\", \"model_name\", \"type\", metric_key]])\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3ï¸) Generate Predictions for Each Model\n",
    "# --------------------------------------------------------------\n",
    "for idx, row in df_top_models.iterrows():\n",
    "    model_id = row[\"model_id\"]\n",
    "    model_name = row.get(\"model_name\", \"Unknown\")\n",
    "    model_type = row.get(\"type\", \"Tuned\")\n",
    "\n",
    "    print(f\"\\n Predicting with Model {model_id} ({model_type})\")\n",
    "    model = dr.Model.get(proj.id, model_id)\n",
    "\n",
    "    # ------------ Request predictions\n",
    "    pred_job = model.request_predictions(dataset.id)\n",
    "    preds = pred_job.get_result_when_complete()\n",
    "\n",
    "    model_prefix = f\"{model_id[-6:]}_{model_type}\"\n",
    "\n",
    "    # ----- Binary Classification -----\n",
    "    if project_type == \"binary\":\n",
    "        # Detect probability column\n",
    "        prob_col = None\n",
    "        for c in preds.columns:\n",
    "            if c.lower() in [\"class_1\", \"positive_probability\", \"prediction\"]:\n",
    "                prob_col = c\n",
    "                break\n",
    "\n",
    "        if not prob_col:\n",
    "            raise KeyError(f\"X No positive probability column found for model {model_id}\")\n",
    "\n",
    "        threshold = row.get(\"threshold\", 0.5)\n",
    "\n",
    "        # ----Save columns\n",
    "        predsAll[f\"{model_prefix}_prob\"] = preds[prob_col]\n",
    "        predsAll[f\"{model_prefix}_pred\"] = (preds[prob_col] >= threshold).astype(int)\n",
    "        predsAll[f\"{model_prefix}_threshold\"] = threshold\n",
    "\n",
    "    # ----- Regression -----\n",
    "    elif project_type == \"regression\":\n",
    "        if \"prediction\" not in preds.columns:\n",
    "            raise KeyError(f\"X Missing prediction column for model {model_id}\")\n",
    "\n",
    "        predsAll[f\"{model_prefix}_pred\"] = preds[\"prediction\"]\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError(\"X Unsupported project type for scoring.\")\n",
    "\n",
    "    print(f\"> Predictions added for {model_prefix}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4ï¸) Create Final Output (ONLY predictions + metadata)\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# -=-------------- BuildING structured results (one row per model)\n",
    "scoring_summary = []\n",
    "\n",
    "for idx, row in df_top_models.iterrows():\n",
    "    model_id = row[\"model_id\"]\n",
    "    model_name = row.get(\"model_name\", \"Unknown\")\n",
    "    model_type = row.get(\"type\", \"Tuned\")\n",
    "    model_prefix = f\"{model_id[-6:]}_{model_type}\"\n",
    "\n",
    "    scoring_summary.append(\n",
    "        {\n",
    "            \"model_id\": model_id,\n",
    "            \"model_name\": model_name,\n",
    "            \"type\": model_type,\n",
    "            \"prediction_column\": f\"{model_prefix}_pred\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "scoring_summary_df = pd.DataFrame(scoring_summary)\n",
    "print(\"\\n MODELâ€“PREDICTION COLUMN MAP:\")\n",
    "display(scoring_summary_df)\n",
    "\n",
    "# -----------Save scoring dataset\n",
    "output_file = \"/home/notebooks/storage/Results/Final_Scoring_Top5.csv\"\n",
    "predsAll.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n Final predictions saved to: {output_file}\")\n",
    "print(\"\\n============================ SCORING PHASE COMPLETE ============================\\n\")\n",
    "\n",
    "# Show prediction columns\n",
    "pred_cols = [c for c in predsAll.columns if c.endswith(\"_pred\")]\n",
    "print(\"\\n Prediction columns generated:\\n\")\n",
    "print(pred_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e7193ab4-b66d-44ac-ac9c-e6e93977f822",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 37,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.dataframe+json": {
       "columns": [
        {
         "name": "index",
         "type": "integer"
        },
        {
         "name": "Apolice",
         "type": "integer"
        },
        {
         "name": "ID_entidade",
         "type": "integer"
        },
        {
         "name": "data_cotacao",
         "type": "string"
        },
        {
         "name": "Data_tarifacao",
         "type": "string"
        },
        {
         "name": "Data_Anulacao",
         "type": "string"
        },
        {
         "name": "Flag_Covid",
         "type": "integer"
        },
        {
         "name": "canal",
         "type": "string"
        },
        {
         "name": "HAS_DECO",
         "type": "integer"
        },
        {
         "name": "Tipo_Fraccionamento",
         "type": "string"
        },
        {
         "name": "Meio_Outros_Pag",
         "type": "string"
        },
        {
         "name": "Idade",
         "type": "integer"
        },
        {
         "name": "Antiguidade_Cliente",
         "type": "integer"
        },
        {
         "name": "TS_latitude",
         "type": "number"
        },
        {
         "name": "TS_longitude",
         "type": "number"
        },
        {
         "name": "TS_Distrito",
         "type": "string"
        },
        {
         "name": "TS_NUTS1",
         "type": "string"
        },
        {
         "name": "TS_NUTS2",
         "type": "string"
        },
        {
         "name": "TS_NUTS3",
         "type": "string"
        },
        {
         "name": "TS_regiao_marktest",
         "type": "string"
        },
        {
         "name": "TS_Interior_litoral",
         "type": "string"
        },
        {
         "name": "TS_Rural_urbano",
         "type": "string"
        },
        {
         "name": "Premio_apresentado_apolice",
         "type": "number"
        },
        {
         "name": "Produto",
         "type": "string"
        },
        {
         "name": "Idade_Viatura",
         "type": "integer"
        },
        {
         "name": "Flag_Importado_RU",
         "type": "integer"
        },
        {
         "name": "Marca_Viatura",
         "type": "string"
        },
        {
         "name": "Segmento",
         "type": "string"
        },
        {
         "name": "cc",
         "type": "integer"
        },
        {
         "name": "netpower",
         "type": "integer"
        },
        {
         "name": "combust",
         "type": "string"
        },
        {
         "name": "PP",
         "type": "number"
        },
        {
         "name": "Valor_Viatura",
         "type": "integer"
        },
        {
         "name": "pnovo",
         "type": "integer"
        },
        {
         "name": "Flag_reboque",
         "type": "integer"
        },
        {
         "name": "Flag_garagem",
         "type": "integer"
        },
        {
         "name": "AC_latitude",
         "type": "number"
        },
        {
         "name": "AC_longitude",
         "type": "number"
        },
        {
         "name": "AC_Distrito",
         "type": "string"
        },
        {
         "name": "AC_NUTS1",
         "type": "string"
        },
        {
         "name": "AC_NUTS2",
         "type": "string"
        },
        {
         "name": "AC_NUTS3",
         "type": "string"
        },
        {
         "name": "AC_regiao_marktest",
         "type": "string"
        },
        {
         "name": "AC_Interior_litoral",
         "type": "string"
        },
        {
         "name": "AC_Rural_urbano",
         "type": "string"
        },
        {
         "name": "Flag_Proprietario_viat",
         "type": "number"
        },
        {
         "name": "CH_Idade",
         "type": "integer"
        },
        {
         "name": "Anos_Carta",
         "type": "integer"
        },
        {
         "name": "Flag_Companhias_Directas",
         "type": "integer"
        },
        {
         "name": "Flag_Companhias_Tradicionais",
         "type": "integer"
        },
        {
         "name": "NCD",
         "type": "integer"
        },
        {
         "name": "N_sinistros_ultimos_3anos",
         "type": "integer"
        },
        {
         "name": "Capital_AV",
         "type": "string"
        },
        {
         "name": "QIV",
         "type": "integer"
        },
        {
         "name": "CCC",
         "type": "integer"
        },
        {
         "name": "Count_Coberturas",
         "type": "integer"
        },
        {
         "name": "Receitas_Historicos_AU",
         "type": "number"
        },
        {
         "name": "Custo_Historicos_AU",
         "type": "number"
        },
        {
         "name": "Saldo_AU",
         "type": "number"
        },
        {
         "name": "Max_Maturidade_AU",
         "type": "integer"
        },
        {
         "name": "Count_Apl_Vigor_AU",
         "type": "integer"
        },
        {
         "name": "Count_Apl_Anuladas_AU",
         "type": "integer"
        },
        {
         "name": "Meses_desde_ult_sin_AU",
         "type": "number"
        },
        {
         "name": "Receitas_Historicos_MRH",
         "type": "number"
        },
        {
         "name": "Custo_Historicos_MRH",
         "type": "integer"
        },
        {
         "name": "Saldo_MRH",
         "type": "number"
        },
        {
         "name": "Max_Maturidade_MRH",
         "type": "integer"
        },
        {
         "name": "Count_Apl_Vigor_MRH",
         "type": "integer"
        },
        {
         "name": "Count_Apl_Anuladas_MRH",
         "type": "integer"
        },
        {
         "name": "Meses_desde_ult_sin_MRH",
         "type": "number"
        },
        {
         "name": "Cotacoes_1m",
         "type": "integer"
        },
        {
         "name": "Cotacoes_3m",
         "type": "integer"
        },
        {
         "name": "Cotacoes_12m",
         "type": "integer"
        },
        {
         "name": "Avg_annual_quotes",
         "type": "number"
        },
        {
         "name": "Online_quote_ratio",
         "type": "number"
        },
        {
         "name": "Meses_desde_ult_cot",
         "type": "number"
        },
        {
         "name": "Viaturas_Distintas",
         "type": "number"
        },
        {
         "name": "Inbound_calls_atend_1m",
         "type": "integer"
        },
        {
         "name": "Inbound_calls_atend_3m",
         "type": "integer"
        },
        {
         "name": "Inbound_calls_atend_12m",
         "type": "integer"
        },
        {
         "name": "Avg_inbound_yr_calls",
         "type": "number"
        },
        {
         "name": "Outbound_calls_atend_1m",
         "type": "integer"
        },
        {
         "name": "Outbound_calls_atend_3m",
         "type": "integer"
        },
        {
         "name": "Outbound_calls_atend_12m",
         "type": "integer"
        },
        {
         "name": "Avg_outbound_yr_calls",
         "type": "number"
        },
        {
         "name": "Receitas_1",
         "type": "string"
        },
        {
         "name": "Receitas_2",
         "type": "string"
        },
        {
         "name": "Custos_acquisition_1",
         "type": "number"
        },
        {
         "name": "Custos_vouchers_1",
         "type": "number"
        },
        {
         "name": "Custos_claims_1",
         "type": "string"
        },
        {
         "name": "Custos_claims_2",
         "type": "string"
        },
        {
         "name": "Custos_cares_1",
         "type": "string"
        },
        {
         "name": "Custos_cares_2",
         "type": "string"
        },
        {
         "name": "Custos_1",
         "type": "number"
        },
        {
         "name": "Custos_2",
         "type": "number"
        },
        {
         "name": "CLV_1",
         "type": "number"
        },
        {
         "name": "actuals",
         "type": "number"
        },
        {
         "name": "c44afa_Original_pred",
         "type": "number"
        },
        {
         "name": "89a0b3_Tuned_pred",
         "type": "number"
        },
        {
         "name": "56724c_Tuned_pred",
         "type": "number"
        },
        {
         "name": "c44af6_Original_pred",
         "type": "number"
        },
        {
         "name": "89a1b8_Tuned_pred",
         "type": "number"
        }
       ],
       "count": 5,
       "data": [
        {
         "56724c_Tuned_pred": -440.8274112414,
         "89a0b3_Tuned_pred": -443.7339204488,
         "89a1b8_Tuned_pred": -24.6612210721,
         "AC_Distrito": "LISBOA",
         "AC_Interior_litoral": "LITORAL",
         "AC_NUTS1": "PORTUGAL CONTINENTAL",
         "AC_NUTS2": "REGI?ÂŸO DE LISBOA",
         "AC_NUTS3": "?ÂREA METROPOLITANA DE LISBOA",
         "AC_Rural_urbano": "?ÂREA PREDOMINANTEMENTE URBANA",
         "AC_latitude": 38.72082,
         "AC_longitude": -9.35069,
         "AC_regiao_marktest": "REGI?ÂŸO DA GRANDE LISBOA",
         "Anos_Carta": 23,
         "Antiguidade_Cliente": 9,
         "Apolice": 960488739,
         "Avg_annual_quotes": 1,
         "Avg_inbound_yr_calls": 0,
         "Avg_outbound_yr_calls": 4,
         "CCC": 0,
         "CH_Idade": 43,
         "CLV_1": 28.27,
         "Capital_AV": "ok 2",
         "Cotacoes_12m": 1,
         "Cotacoes_1m": 1,
         "Cotacoes_3m": 1,
         "Count_Apl_Anuladas_AU": 2,
         "Count_Apl_Anuladas_MRH": 0,
         "Count_Apl_Vigor_AU": 0,
         "Count_Apl_Vigor_MRH": 0,
         "Count_Coberturas": 0,
         "Custo_Historicos_AU": 0,
         "Custo_Historicos_MRH": 0,
         "Custos_1": 38.19,
         "Custos_2": null,
         "Custos_acquisition_1": 38.19,
         "Custos_cares_1": null,
         "Custos_cares_2": null,
         "Custos_claims_1": null,
         "Custos_claims_2": null,
         "Custos_vouchers_1": null,
         "Data_Anulacao": "24-09-2020",
         "Data_tarifacao": "28-04-2020",
         "Flag_Companhias_Directas": 1,
         "Flag_Companhias_Tradicionais": 1,
         "Flag_Covid": 1,
         "Flag_Importado_RU": 1,
         "Flag_Proprietario_viat": 1,
         "Flag_garagem": 0,
         "Flag_reboque": 0,
         "HAS_DECO": 0,
         "ID_entidade": 4001124058,
         "Idade": 43,
         "Idade_Viatura": 7,
         "Inbound_calls_atend_12m": 0,
         "Inbound_calls_atend_1m": 0,
         "Inbound_calls_atend_3m": 0,
         "Marca_Viatura": "SEAT",
         "Max_Maturidade_AU": 2,
         "Max_Maturidade_MRH": 0,
         "Meio_Outros_Pag": "Multibanco",
         "Meses_desde_ult_cot": 0,
         "Meses_desde_ult_sin_AU": null,
         "Meses_desde_ult_sin_MRH": null,
         "NCD": 18,
         "N_sinistros_ultimos_3anos": 0,
         "Online_quote_ratio": 1,
         "Outbound_calls_atend_12m": 4,
         "Outbound_calls_atend_1m": 4,
         "Outbound_calls_atend_3m": 4,
         "PP": 15.13,
         "Premio_apresentado_apolice": 180.83,
         "Produto": "SAFE",
         "QIV": 0,
         "Receitas_1": "66,46",
         "Receitas_2": null,
         "Receitas_Historicos_AU": 401.62,
         "Receitas_Historicos_MRH": 0,
         "Saldo_AU": 401.62,
         "Saldo_MRH": 0,
         "Segmento": "LIGEIRO",
         "TS_Distrito": "LISBOA",
         "TS_Interior_litoral": "LITORAL",
         "TS_NUTS1": "PORTUGAL CONTINENTAL",
         "TS_NUTS2": "REGI?ÂŸO DE LISBOA",
         "TS_NUTS3": "?ÂREA METROPOLITANA DE LISBOA",
         "TS_Rural_urbano": "?ÂREA PREDOMINANTEMENTE URBANA",
         "TS_latitude": 38.72082,
         "TS_longitude": -9.35069,
         "TS_regiao_marktest": "REGI?ÂŸO DA GRANDE LISBOA",
         "Tipo_Fraccionamento": "Trimestral",
         "Valor_Viatura": 7550,
         "Viaturas_Distintas": 1,
         "actuals": 28.27,
         "c44af6_Original_pred": -24.6612210721,
         "c44afa_Original_pred": -441.534250344,
         "canal": "CALL CENTER",
         "cc": 1199,
         "combust": "D",
         "data_cotacao": "27-04-2020",
         "index": 0,
         "netpower": 55,
         "pnovo": 17617
        },
        {
         "56724c_Tuned_pred": -2040.3938663162,
         "89a0b3_Tuned_pred": -2041.408141301,
         "89a1b8_Tuned_pred": -1640.2592868434,
         "AC_Distrito": "LISBOA",
         "AC_Interior_litoral": "INTERIOR",
         "AC_NUTS1": "PORTUGAL CONTINENTAL",
         "AC_NUTS2": "REGI?ÂŸO DE LISBOA",
         "AC_NUTS3": "?ÂREA METROPOLITANA DE LISBOA",
         "AC_Rural_urbano": "?ÂREA PREDOMINANTEMENTE URBANA",
         "AC_latitude": 38.81883,
         "AC_longitude": -9.12226,
         "AC_regiao_marktest": "REGI?ÂŸO DA GRANDE LISBOA",
         "Anos_Carta": 12,
         "Antiguidade_Cliente": 0,
         "Apolice": 960432583,
         "Avg_annual_quotes": 2,
         "Avg_inbound_yr_calls": 0,
         "Avg_outbound_yr_calls": 4,
         "CCC": 0,
         "CH_Idade": 36,
         "CLV_1": -1632.08,
         "Capital_AV": "ok 2",
         "Cotacoes_12m": 2,
         "Cotacoes_1m": 2,
         "Cotacoes_3m": 2,
         "Count_Apl_Anuladas_AU": 0,
         "Count_Apl_Anuladas_MRH": 0,
         "Count_Apl_Vigor_AU": 0,
         "Count_Apl_Vigor_MRH": 0,
         "Count_Coberturas": 0,
         "Custo_Historicos_AU": 0,
         "Custo_Historicos_MRH": 0,
         "Custos_1": 1859.6,
         "Custos_2": null,
         "Custos_acquisition_1": 38.19,
         "Custos_cares_1": "59,11",
         "Custos_cares_2": null,
         "Custos_claims_1": "1.762,30",
         "Custos_claims_2": null,
         "Custos_vouchers_1": null,
         "Data_Anulacao": "23-02-2020",
         "Data_tarifacao": "23-02-2019",
         "Flag_Companhias_Directas": 1,
         "Flag_Companhias_Tradicionais": 0,
         "Flag_Covid": 0,
         "Flag_Importado_RU": 0,
         "Flag_Proprietario_viat": 0,
         "Flag_garagem": 0,
         "Flag_reboque": 0,
         "HAS_DECO": 0,
         "ID_entidade": 4001404194,
         "Idade": 36,
         "Idade_Viatura": 20,
         "Inbound_calls_atend_12m": 0,
         "Inbound_calls_atend_1m": 0,
         "Inbound_calls_atend_3m": 0,
         "Marca_Viatura": "RENAULT",
         "Max_Maturidade_AU": 0,
         "Max_Maturidade_MRH": 0,
         "Meio_Outros_Pag": "D??bito Direto",
         "Meses_desde_ult_cot": 0,
         "Meses_desde_ult_sin_AU": null,
         "Meses_desde_ult_sin_MRH": null,
         "NCD": 12,
         "N_sinistros_ultimos_3anos": 0,
         "Online_quote_ratio": 1,
         "Outbound_calls_atend_12m": 4,
         "Outbound_calls_atend_1m": 4,
         "Outbound_calls_atend_3m": 4,
         "PP": 14.67,
         "Premio_apresentado_apolice": 257.33,
         "Produto": "SAFE",
         "QIV": 0,
         "Receitas_1": "227,52",
         "Receitas_2": null,
         "Receitas_Historicos_AU": 0,
         "Receitas_Historicos_MRH": 0,
         "Saldo_AU": 0,
         "Saldo_MRH": 0,
         "Segmento": "LIGEIRO",
         "TS_Distrito": "LISBOA",
         "TS_Interior_litoral": "INTERIOR",
         "TS_NUTS1": "PORTUGAL CONTINENTAL",
         "TS_NUTS2": "REGI?ÂŸO DE LISBOA",
         "TS_NUTS3": "?ÂREA METROPOLITANA DE LISBOA",
         "TS_Rural_urbano": "?ÂREA PREDOMINANTEMENTE URBANA",
         "TS_latitude": 38.81883,
         "TS_longitude": -9.12226,
         "TS_regiao_marktest": "REGI?ÂŸO DA GRANDE LISBOA",
         "Tipo_Fraccionamento": "Trimestral",
         "Valor_Viatura": 0,
         "Viaturas_Distintas": 1,
         "actuals": -1632.08,
         "c44af6_Original_pred": -1640.2592868434,
         "c44afa_Original_pred": -2049.5505060266,
         "canal": "CALL CENTER",
         "cc": 1149,
         "combust": "G",
         "data_cotacao": "22-02-2019",
         "index": 1,
         "netpower": 43,
         "pnovo": 9896
        },
        {
         "56724c_Tuned_pred": 362.9687474081,
         "89a0b3_Tuned_pred": 358.5516554951,
         "89a1b8_Tuned_pred": 800.6454900466,
         "AC_Distrito": "PORTO",
         "AC_Interior_litoral": "INTERIOR",
         "AC_NUTS1": "PORTUGAL CONTINENTAL",
         "AC_NUTS2": "REGI?ÂŸO DO NORTE",
         "AC_NUTS3": "?ÂREA METROPOLITANA DO PORTO",
         "AC_Rural_urbano": "?ÂREA PREDOMINANTEMENTE URBANA",
         "AC_latitude": 41.22965,
         "AC_longitude": -8.37874,
         "AC_regiao_marktest": "REGI?ÂŸO DO INTERIOR NORTE",
         "Anos_Carta": 51,
         "Antiguidade_Cliente": 0,
         "Apolice": 960521014,
         "Avg_annual_quotes": 1,
         "Avg_inbound_yr_calls": 0,
         "Avg_outbound_yr_calls": 0,
         "CCC": 1,
         "CH_Idade": 73,
         "CLV_1": 453.13,
         "Capital_AV": "ok 2",
         "Cotacoes_12m": 1,
         "Cotacoes_1m": 1,
         "Cotacoes_3m": 1,
         "Count_Apl_Anuladas_AU": 0,
         "Count_Apl_Anuladas_MRH": 0,
         "Count_Apl_Vigor_AU": 0,
         "Count_Apl_Vigor_MRH": 0,
         "Count_Coberturas": 5,
         "Custo_Historicos_AU": 0,
         "Custo_Historicos_MRH": 0,
         "Custos_1": 26.25,
         "Custos_2": null,
         "Custos_acquisition_1": 26.25,
         "Custos_cares_1": null,
         "Custos_cares_2": null,
         "Custos_claims_1": null,
         "Custos_claims_2": null,
         "Custos_vouchers_1": null,
         "Data_Anulacao": "02-12-2025",
         "Data_tarifacao": "02-12-2020",
         "Flag_Companhias_Directas": 0,
         "Flag_Companhias_Tradicionais": 1,
         "Flag_Covid": 1,
         "Flag_Importado_RU": 0,
         "Flag_Proprietario_viat": 1,
         "Flag_garagem": 1,
         "Flag_reboque": 0,
         "HAS_DECO": 0,
         "ID_entidade": 4001472749,
         "Idade": 73,
         "Idade_Viatura": 9,
         "Inbound_calls_atend_12m": 0,
         "Inbound_calls_atend_1m": 0,
         "Inbound_calls_atend_3m": 0,
         "Marca_Viatura": "MERCEDES-BENZ",
         "Max_Maturidade_AU": 0,
         "Max_Maturidade_MRH": 0,
         "Meio_Outros_Pag": "D??bito Direto",
         "Meses_desde_ult_cot": 0,
         "Meses_desde_ult_sin_AU": null,
         "Meses_desde_ult_sin_MRH": null,
         "NCD": 18,
         "N_sinistros_ultimos_3anos": 0,
         "Online_quote_ratio": 1,
         "Outbound_calls_atend_12m": 0,
         "Outbound_calls_atend_1m": 0,
         "Outbound_calls_atend_3m": 0,
         "PP": 8.5,
         "Premio_apresentado_apolice": 538.12,
         "Produto": "PREMIUM",
         "QIV": 1,
         "Receitas_1": "479,38",
         "Receitas_2": "476,69",
         "Receitas_Historicos_AU": 0,
         "Receitas_Historicos_MRH": 0,
         "Saldo_AU": 0,
         "Saldo_MRH": 0,
         "Segmento": "LIGEIRO",
         "TS_Distrito": "PORTO",
         "TS_Interior_litoral": "INTERIOR",
         "TS_NUTS1": "PORTUGAL CONTINENTAL",
         "TS_NUTS2": "REGI?ÂŸO DO NORTE",
         "TS_NUTS3": "?ÂREA METROPOLITANA DO PORTO",
         "TS_Rural_urbano": "?ÂREA PREDOMINANTEMENTE URBANA",
         "TS_latitude": 41.22965,
         "TS_longitude": -8.37874,
         "TS_regiao_marktest": "REGI?ÂŸO DO INTERIOR NORTE",
         "Tipo_Fraccionamento": "Anual",
         "Valor_Viatura": 19600,
         "Viaturas_Distintas": 1,
         "actuals": 929.82,
         "c44af6_Original_pred": 800.6454900466,
         "c44afa_Original_pred": 346.6247652905,
         "canal": "INTERNET",
         "cc": 2143,
         "combust": "D",
         "data_cotacao": "24-11-2020",
         "index": 2,
         "netpower": 150,
         "pnovo": 58989
        },
        {
         "56724c_Tuned_pred": -206.0072519866,
         "89a0b3_Tuned_pred": -205.5371231281,
         "89a1b8_Tuned_pred": 223.0705992656,
         "AC_Distrito": "LISBOA",
         "AC_Interior_litoral": "INTERIOR",
         "AC_NUTS1": "PORTUGAL CONTINENTAL",
         "AC_NUTS2": "REGI?ÂŸO DE LISBOA",
         "AC_NUTS3": "?ÂREA METROPOLITANA DE LISBOA",
         "AC_Rural_urbano": "?ÂREA MEDIAMENTE URBANA",
         "AC_latitude": 38.91713,
         "AC_longitude": -9.03103,
         "AC_regiao_marktest": "REGI?ÂŸO DO LITORAL CENTRO",
         "Anos_Carta": 22,
         "Antiguidade_Cliente": 7,
         "Apolice": 960468477,
         "Avg_annual_quotes": 1.5,
         "Avg_inbound_yr_calls": 0,
         "Avg_outbound_yr_calls": 0,
         "CCC": 1,
         "CH_Idade": 42,
         "CLV_1": 109.54,
         "Capital_AV": "ok 3",
         "Cotacoes_12m": 2,
         "Cotacoes_1m": 0,
         "Cotacoes_3m": 0,
         "Count_Apl_Anuladas_AU": 4,
         "Count_Apl_Anuladas_MRH": 0,
         "Count_Apl_Vigor_AU": 0,
         "Count_Apl_Vigor_MRH": 0,
         "Count_Coberturas": 6,
         "Custo_Historicos_AU": 162.99,
         "Custo_Historicos_MRH": 0,
         "Custos_1": 230.46,
         "Custos_2": 190.18,
         "Custos_acquisition_1": 38.19,
         "Custos_cares_1": "192,27",
         "Custos_cares_2": "190,18",
         "Custos_claims_1": null,
         "Custos_claims_2": null,
         "Custos_vouchers_1": null,
         "Data_Anulacao": "13-06-2023",
         "Data_tarifacao": "18-11-2019",
         "Flag_Companhias_Directas": 1,
         "Flag_Companhias_Tradicionais": 0,
         "Flag_Covid": 0,
         "Flag_Importado_RU": 1,
         "Flag_Proprietario_viat": 1,
         "Flag_garagem": 1,
         "Flag_reboque": 0,
         "HAS_DECO": 0,
         "ID_entidade": 4001161881,
         "Idade": 42,
         "Idade_Viatura": 7,
         "Inbound_calls_atend_12m": 0,
         "Inbound_calls_atend_1m": 0,
         "Inbound_calls_atend_3m": 0,
         "Marca_Viatura": "PEUGEOT",
         "Max_Maturidade_AU": 3,
         "Max_Maturidade_MRH": 0,
         "Meio_Outros_Pag": "Multibanco",
         "Meses_desde_ult_cot": 9,
         "Meses_desde_ult_sin_AU": 10,
         "Meses_desde_ult_sin_MRH": null,
         "NCD": 18,
         "N_sinistros_ultimos_3anos": 0,
         "Online_quote_ratio": 1,
         "Outbound_calls_atend_12m": 0,
         "Outbound_calls_atend_1m": 0,
         "Outbound_calls_atend_3m": 0,
         "PP": 8.85,
         "Premio_apresentado_apolice": 381.36,
         "Produto": "PREMIUM",
         "QIV": 1,
         "Receitas_1": "340,00",
         "Receitas_2": "340,47",
         "Receitas_Historicos_AU": 1270.76,
         "Receitas_Historicos_MRH": 0,
         "Saldo_AU": 1107.77,
         "Saldo_MRH": 0,
         "Segmento": "STATIONWAGON",
         "TS_Distrito": "LISBOA",
         "TS_Interior_litoral": "INTERIOR",
         "TS_NUTS1": "PORTUGAL CONTINENTAL",
         "TS_NUTS2": "REGI?ÂŸO DE LISBOA",
         "TS_NUTS3": "?ÂREA METROPOLITANA DE LISBOA",
         "TS_Rural_urbano": "?ÂREA MEDIAMENTE URBANA",
         "TS_latitude": 38.91609,
         "TS_longitude": -9.02767,
         "TS_regiao_marktest": "REGI?ÂŸO DO LITORAL CENTRO",
         "Tipo_Fraccionamento": "Trimestral",
         "Valor_Viatura": 14150,
         "Viaturas_Distintas": 1,
         "actuals": 259.83,
         "c44af6_Original_pred": 223.0705992656,
         "c44afa_Original_pred": -199.3166099715,
         "canal": "CALL CENTER",
         "cc": 1997,
         "combust": "D",
         "data_cotacao": "18-11-2019",
         "index": 3,
         "netpower": 147,
         "pnovo": 43928
        },
        {
         "56724c_Tuned_pred": -227.2697974849,
         "89a0b3_Tuned_pred": -226.8708701376,
         "89a1b8_Tuned_pred": 183.2595448412,
         "AC_Distrito": "LISBOA",
         "AC_Interior_litoral": "LITORAL",
         "AC_NUTS1": "PORTUGAL CONTINENTAL",
         "AC_NUTS2": "REGI?ÂŸO DE LISBOA",
         "AC_NUTS3": "?ÂREA METROPOLITANA DE LISBOA",
         "AC_Rural_urbano": "?ÂREA PREDOMINANTEMENTE URBANA",
         "AC_latitude": 38.7104,
         "AC_longitude": -9.16984,
         "AC_regiao_marktest": "REGI?ÂŸO DA GRANDE LISBOA",
         "Anos_Carta": 28,
         "Antiguidade_Cliente": 2,
         "Apolice": 960526710,
         "Avg_annual_quotes": 2,
         "Avg_inbound_yr_calls": 2.5,
         "Avg_outbound_yr_calls": 1,
         "CCC": 0,
         "CH_Idade": 49,
         "CLV_1": 112.72,
         "Capital_AV": "ok 2",
         "Cotacoes_12m": 2,
         "Cotacoes_1m": 1,
         "Cotacoes_3m": 1,
         "Count_Apl_Anuladas_AU": 1,
         "Count_Apl_Anuladas_MRH": 0,
         "Count_Apl_Vigor_AU": 1,
         "Count_Apl_Vigor_MRH": 0,
         "Count_Coberturas": 1,
         "Custo_Historicos_AU": 81.82,
         "Custo_Historicos_MRH": 0,
         "Custos_1": 38.19,
         "Custos_2": null,
         "Custos_acquisition_1": 38.19,
         "Custos_cares_1": null,
         "Custos_cares_2": null,
         "Custos_claims_1": null,
         "Custos_claims_2": null,
         "Custos_vouchers_1": null,
         "Data_Anulacao": "11-01-2026",
         "Data_tarifacao": "11-01-2021",
         "Flag_Companhias_Directas": 1,
         "Flag_Companhias_Tradicionais": 1,
         "Flag_Covid": 1,
         "Flag_Importado_RU": 0,
         "Flag_Proprietario_viat": 1,
         "Flag_garagem": 1,
         "Flag_reboque": 0,
         "HAS_DECO": 0,
         "ID_entidade": 4001367107,
         "Idade": 49,
         "Idade_Viatura": 9,
         "Inbound_calls_atend_12m": 4,
         "Inbound_calls_atend_1m": 2,
         "Inbound_calls_atend_3m": 2,
         "Marca_Viatura": "SMART",
         "Max_Maturidade_AU": 3,
         "Max_Maturidade_MRH": 0,
         "Meio_Outros_Pag": "D??bito Direto",
         "Meses_desde_ult_cot": 0,
         "Meses_desde_ult_sin_AU": 16,
         "Meses_desde_ult_sin_MRH": null,
         "NCD": 18,
         "N_sinistros_ultimos_3anos": 0,
         "Online_quote_ratio": 0.3,
         "Outbound_calls_atend_12m": 1,
         "Outbound_calls_atend_1m": 1,
         "Outbound_calls_atend_3m": 1,
         "PP": 14.26,
         "Premio_apresentado_apolice": 170.37,
         "Produto": "SAFE",
         "QIV": 0,
         "Receitas_1": "150,91",
         "Receitas_2": "145,55",
         "Receitas_Historicos_AU": 806.59,
         "Receitas_Historicos_MRH": 0,
         "Saldo_AU": 724.77,
         "Saldo_MRH": 0,
         "Segmento": "LIGEIRO",
         "TS_Distrito": "LISBOA",
         "TS_Interior_litoral": "LITORAL",
         "TS_NUTS1": "PORTUGAL CONTINENTAL",
         "TS_NUTS2": "REGI?ÂŸO DE LISBOA",
         "TS_NUTS3": "?ÂREA METROPOLITANA DE LISBOA",
         "TS_Rural_urbano": "?ÂREA PREDOMINANTEMENTE URBANA",
         "TS_latitude": 38.7104,
         "TS_longitude": -9.16984,
         "TS_regiao_marktest": "REGI?ÂŸO DA GRANDE LISBOA",
         "Tipo_Fraccionamento": "Anual",
         "Valor_Viatura": 6900,
         "Viaturas_Distintas": 3,
         "actuals": 258.27,
         "c44af6_Original_pred": 183.2595448412,
         "c44afa_Original_pred": -225.4717696394,
         "canal": "CALL CENTER",
         "cc": 799,
         "combust": "D",
         "data_cotacao": "08-01-2021",
         "index": 4,
         "netpower": 39,
         "pnovo": 14795
        }
       ],
       "error": [],
       "indexKey": "index",
       "limit": 10,
       "offset": 0,
       "referenceId": 140548121742096,
       "sortedBy": "",
       "totalCount": 5
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apolice</th>\n",
       "      <th>ID_entidade</th>\n",
       "      <th>data_cotacao</th>\n",
       "      <th>Data_tarifacao</th>\n",
       "      <th>Data_Anulacao</th>\n",
       "      <th>Flag_Covid</th>\n",
       "      <th>canal</th>\n",
       "      <th>HAS_DECO</th>\n",
       "      <th>Tipo_Fraccionamento</th>\n",
       "      <th>Meio_Outros_Pag</th>\n",
       "      <th>Idade</th>\n",
       "      <th>Antiguidade_Cliente</th>\n",
       "      <th>TS_latitude</th>\n",
       "      <th>TS_longitude</th>\n",
       "      <th>TS_Distrito</th>\n",
       "      <th>TS_NUTS1</th>\n",
       "      <th>TS_NUTS2</th>\n",
       "      <th>TS_NUTS3</th>\n",
       "      <th>TS_regiao_marktest</th>\n",
       "      <th>TS_Interior_litoral</th>\n",
       "      <th>TS_Rural_urbano</th>\n",
       "      <th>Premio_apresentado_apolice</th>\n",
       "      <th>Produto</th>\n",
       "      <th>Idade_Viatura</th>\n",
       "      <th>Flag_Importado_RU</th>\n",
       "      <th>Marca_Viatura</th>\n",
       "      <th>Segmento</th>\n",
       "      <th>cc</th>\n",
       "      <th>netpower</th>\n",
       "      <th>combust</th>\n",
       "      <th>PP</th>\n",
       "      <th>Valor_Viatura</th>\n",
       "      <th>pnovo</th>\n",
       "      <th>Flag_reboque</th>\n",
       "      <th>Flag_garagem</th>\n",
       "      <th>AC_latitude</th>\n",
       "      <th>AC_longitude</th>\n",
       "      <th>AC_Distrito</th>\n",
       "      <th>AC_NUTS1</th>\n",
       "      <th>AC_NUTS2</th>\n",
       "      <th>AC_NUTS3</th>\n",
       "      <th>AC_regiao_marktest</th>\n",
       "      <th>AC_Interior_litoral</th>\n",
       "      <th>AC_Rural_urbano</th>\n",
       "      <th>Flag_Proprietario_viat</th>\n",
       "      <th>CH_Idade</th>\n",
       "      <th>Anos_Carta</th>\n",
       "      <th>Flag_Companhias_Directas</th>\n",
       "      <th>Flag_Companhias_Tradicionais</th>\n",
       "      <th>NCD</th>\n",
       "      <th>N_sinistros_ultimos_3anos</th>\n",
       "      <th>Capital_AV</th>\n",
       "      <th>QIV</th>\n",
       "      <th>CCC</th>\n",
       "      <th>Count_Coberturas</th>\n",
       "      <th>Receitas_Historicos_AU</th>\n",
       "      <th>Custo_Historicos_AU</th>\n",
       "      <th>Saldo_AU</th>\n",
       "      <th>Max_Maturidade_AU</th>\n",
       "      <th>Count_Apl_Vigor_AU</th>\n",
       "      <th>Count_Apl_Anuladas_AU</th>\n",
       "      <th>Meses_desde_ult_sin_AU</th>\n",
       "      <th>Receitas_Historicos_MRH</th>\n",
       "      <th>Custo_Historicos_MRH</th>\n",
       "      <th>Saldo_MRH</th>\n",
       "      <th>Max_Maturidade_MRH</th>\n",
       "      <th>Count_Apl_Vigor_MRH</th>\n",
       "      <th>Count_Apl_Anuladas_MRH</th>\n",
       "      <th>Meses_desde_ult_sin_MRH</th>\n",
       "      <th>Cotacoes_1m</th>\n",
       "      <th>Cotacoes_3m</th>\n",
       "      <th>Cotacoes_12m</th>\n",
       "      <th>Avg_annual_quotes</th>\n",
       "      <th>Online_quote_ratio</th>\n",
       "      <th>Meses_desde_ult_cot</th>\n",
       "      <th>Viaturas_Distintas</th>\n",
       "      <th>Inbound_calls_atend_1m</th>\n",
       "      <th>Inbound_calls_atend_3m</th>\n",
       "      <th>Inbound_calls_atend_12m</th>\n",
       "      <th>Avg_inbound_yr_calls</th>\n",
       "      <th>Outbound_calls_atend_1m</th>\n",
       "      <th>Outbound_calls_atend_3m</th>\n",
       "      <th>Outbound_calls_atend_12m</th>\n",
       "      <th>Avg_outbound_yr_calls</th>\n",
       "      <th>Receitas_1</th>\n",
       "      <th>Receitas_2</th>\n",
       "      <th>Custos_acquisition_1</th>\n",
       "      <th>Custos_vouchers_1</th>\n",
       "      <th>Custos_claims_1</th>\n",
       "      <th>Custos_claims_2</th>\n",
       "      <th>Custos_cares_1</th>\n",
       "      <th>Custos_cares_2</th>\n",
       "      <th>Custos_1</th>\n",
       "      <th>Custos_2</th>\n",
       "      <th>CLV_1</th>\n",
       "      <th>actuals</th>\n",
       "      <th>c44afa_Original_pred</th>\n",
       "      <th>89a0b3_Tuned_pred</th>\n",
       "      <th>56724c_Tuned_pred</th>\n",
       "      <th>c44af6_Original_pred</th>\n",
       "      <th>89a1b8_Tuned_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>960488739</td>\n",
       "      <td>4001124058</td>\n",
       "      <td>27-04-2020</td>\n",
       "      <td>28-04-2020</td>\n",
       "      <td>24-09-2020</td>\n",
       "      <td>1</td>\n",
       "      <td>CALL CENTER</td>\n",
       "      <td>0</td>\n",
       "      <td>Trimestral</td>\n",
       "      <td>Multibanco</td>\n",
       "      <td>43</td>\n",
       "      <td>9</td>\n",
       "      <td>38.72082</td>\n",
       "      <td>-9.35069</td>\n",
       "      <td>LISBOA</td>\n",
       "      <td>PORTUGAL CONTINENTAL</td>\n",
       "      <td>REGI?ÂŸO DE LISBOA</td>\n",
       "      <td>?ÂREA METROPOLITANA DE LISBOA</td>\n",
       "      <td>REGI?ÂŸO DA GRANDE LISBOA</td>\n",
       "      <td>LITORAL</td>\n",
       "      <td>?ÂREA PREDOMINANTEMENTE URBANA</td>\n",
       "      <td>180.83</td>\n",
       "      <td>SAFE</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>SEAT</td>\n",
       "      <td>LIGEIRO</td>\n",
       "      <td>1199</td>\n",
       "      <td>55</td>\n",
       "      <td>D</td>\n",
       "      <td>15.13</td>\n",
       "      <td>7550</td>\n",
       "      <td>17617</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.72082</td>\n",
       "      <td>-9.35069</td>\n",
       "      <td>LISBOA</td>\n",
       "      <td>PORTUGAL CONTINENTAL</td>\n",
       "      <td>REGI?ÂŸO DE LISBOA</td>\n",
       "      <td>?ÂREA METROPOLITANA DE LISBOA</td>\n",
       "      <td>REGI?ÂŸO DA GRANDE LISBOA</td>\n",
       "      <td>LITORAL</td>\n",
       "      <td>?ÂREA PREDOMINANTEMENTE URBANA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>ok 2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>401.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>401.62</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66,46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.27</td>\n",
       "      <td>28.27</td>\n",
       "      <td>-441.534250</td>\n",
       "      <td>-443.733920</td>\n",
       "      <td>-440.827411</td>\n",
       "      <td>-24.661221</td>\n",
       "      <td>-24.661221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>960432583</td>\n",
       "      <td>4001404194</td>\n",
       "      <td>22-02-2019</td>\n",
       "      <td>23-02-2019</td>\n",
       "      <td>23-02-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>CALL CENTER</td>\n",
       "      <td>0</td>\n",
       "      <td>Trimestral</td>\n",
       "      <td>D??bito Direto</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>38.81883</td>\n",
       "      <td>-9.12226</td>\n",
       "      <td>LISBOA</td>\n",
       "      <td>PORTUGAL CONTINENTAL</td>\n",
       "      <td>REGI?ÂŸO DE LISBOA</td>\n",
       "      <td>?ÂREA METROPOLITANA DE LISBOA</td>\n",
       "      <td>REGI?ÂŸO DA GRANDE LISBOA</td>\n",
       "      <td>INTERIOR</td>\n",
       "      <td>?ÂREA PREDOMINANTEMENTE URBANA</td>\n",
       "      <td>257.33</td>\n",
       "      <td>SAFE</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>RENAULT</td>\n",
       "      <td>LIGEIRO</td>\n",
       "      <td>1149</td>\n",
       "      <td>43</td>\n",
       "      <td>G</td>\n",
       "      <td>14.67</td>\n",
       "      <td>0</td>\n",
       "      <td>9896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.81883</td>\n",
       "      <td>-9.12226</td>\n",
       "      <td>LISBOA</td>\n",
       "      <td>PORTUGAL CONTINENTAL</td>\n",
       "      <td>REGI?ÂŸO DE LISBOA</td>\n",
       "      <td>?ÂREA METROPOLITANA DE LISBOA</td>\n",
       "      <td>REGI?ÂŸO DA GRANDE LISBOA</td>\n",
       "      <td>INTERIOR</td>\n",
       "      <td>?ÂREA PREDOMINANTEMENTE URBANA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>ok 2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>227,52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.762,30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59,11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1859.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1632.08</td>\n",
       "      <td>-1632.08</td>\n",
       "      <td>-2049.550506</td>\n",
       "      <td>-2041.408141</td>\n",
       "      <td>-2040.393866</td>\n",
       "      <td>-1640.259287</td>\n",
       "      <td>-1640.259287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>960521014</td>\n",
       "      <td>4001472749</td>\n",
       "      <td>24-11-2020</td>\n",
       "      <td>02-12-2020</td>\n",
       "      <td>02-12-2025</td>\n",
       "      <td>1</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0</td>\n",
       "      <td>Anual</td>\n",
       "      <td>D??bito Direto</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>41.22965</td>\n",
       "      <td>-8.37874</td>\n",
       "      <td>PORTO</td>\n",
       "      <td>PORTUGAL CONTINENTAL</td>\n",
       "      <td>REGI?ÂŸO DO NORTE</td>\n",
       "      <td>?ÂREA METROPOLITANA DO PORTO</td>\n",
       "      <td>REGI?ÂŸO DO INTERIOR NORTE</td>\n",
       "      <td>INTERIOR</td>\n",
       "      <td>?ÂREA PREDOMINANTEMENTE URBANA</td>\n",
       "      <td>538.12</td>\n",
       "      <td>PREMIUM</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>MERCEDES-BENZ</td>\n",
       "      <td>LIGEIRO</td>\n",
       "      <td>2143</td>\n",
       "      <td>150</td>\n",
       "      <td>D</td>\n",
       "      <td>8.50</td>\n",
       "      <td>19600</td>\n",
       "      <td>58989</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.22965</td>\n",
       "      <td>-8.37874</td>\n",
       "      <td>PORTO</td>\n",
       "      <td>PORTUGAL CONTINENTAL</td>\n",
       "      <td>REGI?ÂŸO DO NORTE</td>\n",
       "      <td>?ÂREA METROPOLITANA DO PORTO</td>\n",
       "      <td>REGI?ÂŸO DO INTERIOR NORTE</td>\n",
       "      <td>INTERIOR</td>\n",
       "      <td>?ÂREA PREDOMINANTEMENTE URBANA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>ok 2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>479,38</td>\n",
       "      <td>476,69</td>\n",
       "      <td>26.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>453.13</td>\n",
       "      <td>929.82</td>\n",
       "      <td>346.624765</td>\n",
       "      <td>358.551655</td>\n",
       "      <td>362.968747</td>\n",
       "      <td>800.645490</td>\n",
       "      <td>800.645490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>960468477</td>\n",
       "      <td>4001161881</td>\n",
       "      <td>18-11-2019</td>\n",
       "      <td>18-11-2019</td>\n",
       "      <td>13-06-2023</td>\n",
       "      <td>0</td>\n",
       "      <td>CALL CENTER</td>\n",
       "      <td>0</td>\n",
       "      <td>Trimestral</td>\n",
       "      <td>Multibanco</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>38.91609</td>\n",
       "      <td>-9.02767</td>\n",
       "      <td>LISBOA</td>\n",
       "      <td>PORTUGAL CONTINENTAL</td>\n",
       "      <td>REGI?ÂŸO DE LISBOA</td>\n",
       "      <td>?ÂREA METROPOLITANA DE LISBOA</td>\n",
       "      <td>REGI?ÂŸO DO LITORAL CENTRO</td>\n",
       "      <td>INTERIOR</td>\n",
       "      <td>?ÂREA MEDIAMENTE URBANA</td>\n",
       "      <td>381.36</td>\n",
       "      <td>PREMIUM</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>PEUGEOT</td>\n",
       "      <td>STATIONWAGON</td>\n",
       "      <td>1997</td>\n",
       "      <td>147</td>\n",
       "      <td>D</td>\n",
       "      <td>8.85</td>\n",
       "      <td>14150</td>\n",
       "      <td>43928</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.91713</td>\n",
       "      <td>-9.03103</td>\n",
       "      <td>LISBOA</td>\n",
       "      <td>PORTUGAL CONTINENTAL</td>\n",
       "      <td>REGI?ÂŸO DE LISBOA</td>\n",
       "      <td>?ÂREA METROPOLITANA DE LISBOA</td>\n",
       "      <td>REGI?ÂŸO DO LITORAL CENTRO</td>\n",
       "      <td>INTERIOR</td>\n",
       "      <td>?ÂREA MEDIAMENTE URBANA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>ok 3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1270.76</td>\n",
       "      <td>162.99</td>\n",
       "      <td>1107.77</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>340,00</td>\n",
       "      <td>340,47</td>\n",
       "      <td>38.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192,27</td>\n",
       "      <td>190,18</td>\n",
       "      <td>230.46</td>\n",
       "      <td>190.18</td>\n",
       "      <td>109.54</td>\n",
       "      <td>259.83</td>\n",
       "      <td>-199.316610</td>\n",
       "      <td>-205.537123</td>\n",
       "      <td>-206.007252</td>\n",
       "      <td>223.070599</td>\n",
       "      <td>223.070599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>960526710</td>\n",
       "      <td>4001367107</td>\n",
       "      <td>08-01-2021</td>\n",
       "      <td>11-01-2021</td>\n",
       "      <td>11-01-2026</td>\n",
       "      <td>1</td>\n",
       "      <td>CALL CENTER</td>\n",
       "      <td>0</td>\n",
       "      <td>Anual</td>\n",
       "      <td>D??bito Direto</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>38.71040</td>\n",
       "      <td>-9.16984</td>\n",
       "      <td>LISBOA</td>\n",
       "      <td>PORTUGAL CONTINENTAL</td>\n",
       "      <td>REGI?ÂŸO DE LISBOA</td>\n",
       "      <td>?ÂREA METROPOLITANA DE LISBOA</td>\n",
       "      <td>REGI?ÂŸO DA GRANDE LISBOA</td>\n",
       "      <td>LITORAL</td>\n",
       "      <td>?ÂREA PREDOMINANTEMENTE URBANA</td>\n",
       "      <td>170.37</td>\n",
       "      <td>SAFE</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>SMART</td>\n",
       "      <td>LIGEIRO</td>\n",
       "      <td>799</td>\n",
       "      <td>39</td>\n",
       "      <td>D</td>\n",
       "      <td>14.26</td>\n",
       "      <td>6900</td>\n",
       "      <td>14795</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.71040</td>\n",
       "      <td>-9.16984</td>\n",
       "      <td>LISBOA</td>\n",
       "      <td>PORTUGAL CONTINENTAL</td>\n",
       "      <td>REGI?ÂŸO DE LISBOA</td>\n",
       "      <td>?ÂREA METROPOLITANA DE LISBOA</td>\n",
       "      <td>REGI?ÂŸO DA GRANDE LISBOA</td>\n",
       "      <td>LITORAL</td>\n",
       "      <td>?ÂREA PREDOMINANTEMENTE URBANA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>ok 2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>806.59</td>\n",
       "      <td>81.82</td>\n",
       "      <td>724.77</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150,91</td>\n",
       "      <td>145,55</td>\n",
       "      <td>38.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.72</td>\n",
       "      <td>258.27</td>\n",
       "      <td>-225.471770</td>\n",
       "      <td>-226.870870</td>\n",
       "      <td>-227.269797</td>\n",
       "      <td>183.259545</td>\n",
       "      <td>183.259545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Apolice  ID_entidade data_cotacao Data_tarifacao Data_Anulacao  \\\n",
       "0  960488739   4001124058   27-04-2020     28-04-2020    24-09-2020   \n",
       "1  960432583   4001404194   22-02-2019     23-02-2019    23-02-2020   \n",
       "2  960521014   4001472749   24-11-2020     02-12-2020    02-12-2025   \n",
       "3  960468477   4001161881   18-11-2019     18-11-2019    13-06-2023   \n",
       "4  960526710   4001367107   08-01-2021     11-01-2021    11-01-2026   \n",
       "\n",
       "   Flag_Covid        canal  HAS_DECO Tipo_Fraccionamento Meio_Outros_Pag  \\\n",
       "0           1  CALL CENTER         0          Trimestral      Multibanco   \n",
       "1           0  CALL CENTER         0          Trimestral  D??bito Direto   \n",
       "2           1     INTERNET         0               Anual  D??bito Direto   \n",
       "3           0  CALL CENTER         0          Trimestral      Multibanco   \n",
       "4           1  CALL CENTER         0               Anual  D??bito Direto   \n",
       "\n",
       "   Idade  Antiguidade_Cliente  TS_latitude  TS_longitude TS_Distrito  \\\n",
       "0     43                    9     38.72082      -9.35069      LISBOA   \n",
       "1     36                    0     38.81883      -9.12226      LISBOA   \n",
       "2     73                    0     41.22965      -8.37874       PORTO   \n",
       "3     42                    7     38.91609      -9.02767      LISBOA   \n",
       "4     49                    2     38.71040      -9.16984      LISBOA   \n",
       "\n",
       "               TS_NUTS1           TS_NUTS2                       TS_NUTS3  \\\n",
       "0  PORTUGAL CONTINENTAL  REGI?ÂŸO DE LISBOA  ?ÂREA METROPOLITANA DE LISBOA   \n",
       "1  PORTUGAL CONTINENTAL  REGI?ÂŸO DE LISBOA  ?ÂREA METROPOLITANA DE LISBOA   \n",
       "2  PORTUGAL CONTINENTAL   REGI?ÂŸO DO NORTE   ?ÂREA METROPOLITANA DO PORTO   \n",
       "3  PORTUGAL CONTINENTAL  REGI?ÂŸO DE LISBOA  ?ÂREA METROPOLITANA DE LISBOA   \n",
       "4  PORTUGAL CONTINENTAL  REGI?ÂŸO DE LISBOA  ?ÂREA METROPOLITANA DE LISBOA   \n",
       "\n",
       "          TS_regiao_marktest TS_Interior_litoral  \\\n",
       "0   REGI?ÂŸO DA GRANDE LISBOA             LITORAL   \n",
       "1   REGI?ÂŸO DA GRANDE LISBOA            INTERIOR   \n",
       "2  REGI?ÂŸO DO INTERIOR NORTE            INTERIOR   \n",
       "3  REGI?ÂŸO DO LITORAL CENTRO            INTERIOR   \n",
       "4   REGI?ÂŸO DA GRANDE LISBOA             LITORAL   \n",
       "\n",
       "                  TS_Rural_urbano  Premio_apresentado_apolice  Produto  \\\n",
       "0  ?ÂREA PREDOMINANTEMENTE URBANA                      180.83     SAFE   \n",
       "1  ?ÂREA PREDOMINANTEMENTE URBANA                      257.33     SAFE   \n",
       "2  ?ÂREA PREDOMINANTEMENTE URBANA                      538.12  PREMIUM   \n",
       "3         ?ÂREA MEDIAMENTE URBANA                      381.36  PREMIUM   \n",
       "4  ?ÂREA PREDOMINANTEMENTE URBANA                      170.37     SAFE   \n",
       "\n",
       "   Idade_Viatura  Flag_Importado_RU  Marca_Viatura      Segmento    cc  \\\n",
       "0              7                  1           SEAT       LIGEIRO  1199   \n",
       "1             20                  0        RENAULT       LIGEIRO  1149   \n",
       "2              9                  0  MERCEDES-BENZ       LIGEIRO  2143   \n",
       "3              7                  1        PEUGEOT  STATIONWAGON  1997   \n",
       "4              9                  0          SMART       LIGEIRO   799   \n",
       "\n",
       "   netpower combust     PP  Valor_Viatura  pnovo  Flag_reboque  Flag_garagem  \\\n",
       "0        55       D  15.13           7550  17617             0             0   \n",
       "1        43       G  14.67              0   9896             0             0   \n",
       "2       150       D   8.50          19600  58989             0             1   \n",
       "3       147       D   8.85          14150  43928             0             1   \n",
       "4        39       D  14.26           6900  14795             0             1   \n",
       "\n",
       "   AC_latitude  AC_longitude AC_Distrito              AC_NUTS1  \\\n",
       "0     38.72082      -9.35069      LISBOA  PORTUGAL CONTINENTAL   \n",
       "1     38.81883      -9.12226      LISBOA  PORTUGAL CONTINENTAL   \n",
       "2     41.22965      -8.37874       PORTO  PORTUGAL CONTINENTAL   \n",
       "3     38.91713      -9.03103      LISBOA  PORTUGAL CONTINENTAL   \n",
       "4     38.71040      -9.16984      LISBOA  PORTUGAL CONTINENTAL   \n",
       "\n",
       "            AC_NUTS2                       AC_NUTS3  \\\n",
       "0  REGI?ÂŸO DE LISBOA  ?ÂREA METROPOLITANA DE LISBOA   \n",
       "1  REGI?ÂŸO DE LISBOA  ?ÂREA METROPOLITANA DE LISBOA   \n",
       "2   REGI?ÂŸO DO NORTE   ?ÂREA METROPOLITANA DO PORTO   \n",
       "3  REGI?ÂŸO DE LISBOA  ?ÂREA METROPOLITANA DE LISBOA   \n",
       "4  REGI?ÂŸO DE LISBOA  ?ÂREA METROPOLITANA DE LISBOA   \n",
       "\n",
       "          AC_regiao_marktest AC_Interior_litoral  \\\n",
       "0   REGI?ÂŸO DA GRANDE LISBOA             LITORAL   \n",
       "1   REGI?ÂŸO DA GRANDE LISBOA            INTERIOR   \n",
       "2  REGI?ÂŸO DO INTERIOR NORTE            INTERIOR   \n",
       "3  REGI?ÂŸO DO LITORAL CENTRO            INTERIOR   \n",
       "4   REGI?ÂŸO DA GRANDE LISBOA             LITORAL   \n",
       "\n",
       "                  AC_Rural_urbano  Flag_Proprietario_viat  CH_Idade  \\\n",
       "0  ?ÂREA PREDOMINANTEMENTE URBANA                     1.0        43   \n",
       "1  ?ÂREA PREDOMINANTEMENTE URBANA                     0.0        36   \n",
       "2  ?ÂREA PREDOMINANTEMENTE URBANA                     1.0        73   \n",
       "3         ?ÂREA MEDIAMENTE URBANA                     1.0        42   \n",
       "4  ?ÂREA PREDOMINANTEMENTE URBANA                     1.0        49   \n",
       "\n",
       "   Anos_Carta  Flag_Companhias_Directas  Flag_Companhias_Tradicionais  NCD  \\\n",
       "0          23                         1                             1   18   \n",
       "1          12                         1                             0   12   \n",
       "2          51                         0                             1   18   \n",
       "3          22                         1                             0   18   \n",
       "4          28                         1                             1   18   \n",
       "\n",
       "   N_sinistros_ultimos_3anos Capital_AV  QIV  CCC  Count_Coberturas  \\\n",
       "0                          0       ok 2    0    0                 0   \n",
       "1                          0       ok 2    0    0                 0   \n",
       "2                          0       ok 2    1    1                 5   \n",
       "3                          0       ok 3    1    1                 6   \n",
       "4                          0       ok 2    0    0                 1   \n",
       "\n",
       "   Receitas_Historicos_AU  Custo_Historicos_AU  Saldo_AU  Max_Maturidade_AU  \\\n",
       "0                  401.62                 0.00    401.62                  2   \n",
       "1                    0.00                 0.00      0.00                  0   \n",
       "2                    0.00                 0.00      0.00                  0   \n",
       "3                 1270.76               162.99   1107.77                  3   \n",
       "4                  806.59                81.82    724.77                  3   \n",
       "\n",
       "   Count_Apl_Vigor_AU  Count_Apl_Anuladas_AU  Meses_desde_ult_sin_AU  \\\n",
       "0                   0                      2                     NaN   \n",
       "1                   0                      0                     NaN   \n",
       "2                   0                      0                     NaN   \n",
       "3                   0                      4                    10.0   \n",
       "4                   1                      1                    16.0   \n",
       "\n",
       "   Receitas_Historicos_MRH  Custo_Historicos_MRH  Saldo_MRH  \\\n",
       "0                      0.0                     0        0.0   \n",
       "1                      0.0                     0        0.0   \n",
       "2                      0.0                     0        0.0   \n",
       "3                      0.0                     0        0.0   \n",
       "4                      0.0                     0        0.0   \n",
       "\n",
       "   Max_Maturidade_MRH  Count_Apl_Vigor_MRH  Count_Apl_Anuladas_MRH  \\\n",
       "0                   0                    0                       0   \n",
       "1                   0                    0                       0   \n",
       "2                   0                    0                       0   \n",
       "3                   0                    0                       0   \n",
       "4                   0                    0                       0   \n",
       "\n",
       "   Meses_desde_ult_sin_MRH  Cotacoes_1m  Cotacoes_3m  Cotacoes_12m  \\\n",
       "0                      NaN            1            1             1   \n",
       "1                      NaN            2            2             2   \n",
       "2                      NaN            1            1             1   \n",
       "3                      NaN            0            0             2   \n",
       "4                      NaN            1            1             2   \n",
       "\n",
       "   Avg_annual_quotes  Online_quote_ratio  Meses_desde_ult_cot  \\\n",
       "0                1.0                 1.0                  0.0   \n",
       "1                2.0                 1.0                  0.0   \n",
       "2                1.0                 1.0                  0.0   \n",
       "3                1.5                 1.0                  9.0   \n",
       "4                2.0                 0.3                  0.0   \n",
       "\n",
       "   Viaturas_Distintas  Inbound_calls_atend_1m  Inbound_calls_atend_3m  \\\n",
       "0                 1.0                       0                       0   \n",
       "1                 1.0                       0                       0   \n",
       "2                 1.0                       0                       0   \n",
       "3                 1.0                       0                       0   \n",
       "4                 3.0                       2                       2   \n",
       "\n",
       "   Inbound_calls_atend_12m  Avg_inbound_yr_calls  Outbound_calls_atend_1m  \\\n",
       "0                        0                   0.0                        4   \n",
       "1                        0                   0.0                        4   \n",
       "2                        0                   0.0                        0   \n",
       "3                        0                   0.0                        0   \n",
       "4                        4                   2.5                        1   \n",
       "\n",
       "   Outbound_calls_atend_3m  Outbound_calls_atend_12m  Avg_outbound_yr_calls  \\\n",
       "0                        4                         4                    4.0   \n",
       "1                        4                         4                    4.0   \n",
       "2                        0                         0                    0.0   \n",
       "3                        0                         0                    0.0   \n",
       "4                        1                         1                    1.0   \n",
       "\n",
       "  Receitas_1 Receitas_2  Custos_acquisition_1  Custos_vouchers_1  \\\n",
       "0      66,46        NaN                 38.19                NaN   \n",
       "1     227,52        NaN                 38.19                NaN   \n",
       "2     479,38     476,69                 26.25                NaN   \n",
       "3     340,00     340,47                 38.19                NaN   \n",
       "4     150,91     145,55                 38.19                NaN   \n",
       "\n",
       "  Custos_claims_1 Custos_claims_2 Custos_cares_1 Custos_cares_2  Custos_1  \\\n",
       "0             NaN             NaN            NaN            NaN     38.19   \n",
       "1        1.762,30             NaN          59,11            NaN   1859.60   \n",
       "2             NaN             NaN            NaN            NaN     26.25   \n",
       "3             NaN             NaN         192,27         190,18    230.46   \n",
       "4             NaN             NaN            NaN            NaN     38.19   \n",
       "\n",
       "   Custos_2    CLV_1  actuals  c44afa_Original_pred  89a0b3_Tuned_pred  \\\n",
       "0       NaN    28.27    28.27           -441.534250        -443.733920   \n",
       "1       NaN -1632.08 -1632.08          -2049.550506       -2041.408141   \n",
       "2       NaN   453.13   929.82            346.624765         358.551655   \n",
       "3    190.18   109.54   259.83           -199.316610        -205.537123   \n",
       "4       NaN   112.72   258.27           -225.471770        -226.870870   \n",
       "\n",
       "   56724c_Tuned_pred  c44af6_Original_pred  89a1b8_Tuned_pred  \n",
       "0        -440.827411            -24.661221         -24.661221  \n",
       "1       -2040.393866          -1640.259287       -1640.259287  \n",
       "2         362.968747            800.645490         800.645490  \n",
       "3        -206.007252            223.070599         223.070599  \n",
       "4        -227.269797            183.259545         183.259545  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsAll.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
